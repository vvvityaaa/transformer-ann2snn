{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from spiking_models import DenseRNN, SpikingReLU, SpikingSigmoid, SpikingTanh, Accumulate\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(model, weights, x_test, y_test):\n",
    "    print(\"Converted model:\\n\" + \"-\"*32)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            print(\"Input Layer\")\n",
    "            inputs = tf.keras.Input(shape=(1, model.layers[0].input_shape[0][1]), batch_size=y_test.shape[0])\n",
    "            x = inputs        \n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            x = tf.keras.layers.Dense(layer.output_shape[1])(x)\n",
    "            # x = tf.keras.layers.RNN(DenseRNN(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            if layer.activation.__name__ == 'linear':\n",
    "                print(\"Dense Layer w/o activation\")\n",
    "                pass\n",
    "            elif layer.activation.__name__ == 'relu':\n",
    "                print(\"Dense Layer with SpikingReLU\")\n",
    "                x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'sigmoid':\n",
    "                print(\"Dense Layer with SpikingSigmoid\")\n",
    "                x = tf.keras.layers.RNN(SpikingSigmoid(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'tanh':\n",
    "                print(\"Dense Layer with SpikingTanh\")\n",
    "                x = tf.keras.layers.RNN(SpikingTanh(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            else:\n",
    "                print('[Info] Activation type', layer.activation.__name__, 'not implemented')\n",
    "        elif isinstance(layer, tf.keras.layers.ReLU):\n",
    "            print(\"SpikingReLU Layer\")\n",
    "            x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "        elif isinstance(layer, tf.keras.layers.Softmax):\n",
    "            print(\"Accumulate + Softmax Layer\")\n",
    "            print(layer.output_shape[1])\n",
    "            x = tf.keras.layers.RNN(Accumulate(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            x = tf.keras.layers.Softmax()(x)\n",
    "        else:\n",
    "            print(\"[Info] Layer type \", layer, \"not implemented\")\n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "\n",
    "    spiking.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_weights(model, x_test, percentile=100):\n",
    "    max_activation = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ReLU):\n",
    "            activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "            if np.percentile(activation, percentile) > max_activation:\n",
    "                max_activation = np.percentile(activation, percentile)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            if layer.activation.__name__ == 'relu':\n",
    "                activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "                if np.percentile(activation, percentile) > max_activation:\n",
    "                    max_activation = np.percentile(activation, percentile)\n",
    "\n",
    "    weights = model.get_weights()     \n",
    "    if max_activation == 0:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNo normalization\\n\" + \"-\"*32)\n",
    "    else:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNormalizing by\", max_activation, \"\\n\" + \"-\"*32)\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] /= (max_activation)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conversion(converted_model, original_model, x_test, y_test, testacc, timesteps=50):\n",
    "    for i in range(1, timesteps+1):\n",
    "        _, acc = converted_model.evaluate(x_test, y_test, batch_size=y_test.shape[0], verbose=0)\n",
    "        print(\n",
    "            \"Timesteps\", str(i) + \"/\" + str(timesteps) + \" -\",\n",
    "            \"acc spiking (orig): %.2f%% (%.2f%%)\" % (acc*100, testacc*100),\n",
    "            \"- conv loss: %+.2f%%\" % ((-(1 - acc/testacc)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "batch_size=512\n",
    "epochs = 5\n",
    "act='relu'\n",
    "\n",
    "\n",
    "def create_ann():\n",
    "    inputs = tf.keras.Input(shape=(784,))\n",
    "    x = tf.keras.layers.Dense(500, activation=act)(inputs)\n",
    "    #x = tf.keras.layers.ReLU()(x)  # max_value=1\n",
    "    x = tf.keras.layers.Dense(100, activation=act)(x)\n",
    "    #x = tf.keras.layers.Activation(tf.nn.relu)(x)  # not implemented yet\n",
    "    x = tf.keras.layers.Dense(10, activation=act)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    ann = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    ann.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    ann.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7013 - sparse_categorical_accuracy: 0.7837\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1656 - sparse_categorical_accuracy: 0.9499\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9831\n",
      "\n",
      "--------------------------------\n",
      "Normalizing by 5.39086127281189 \n",
      "--------------------------------\n",
      "Converted model:\n",
      "--------------------------------\n",
      "Input Layer\n",
      "Dense Layer with SpikingReLU\n",
      "Dense Layer with SpikingReLU\n",
      "Dense Layer with SpikingReLU\n",
      "Accumulate + Softmax Layer\n",
      "10\n",
      "--------------------------------\n",
      "\n",
      "Timesteps 1/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 2/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 3/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 4/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 5/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 6/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 7/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 8/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 9/50 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 10/50 - acc spiking (orig): 9.84% (97.74%) - conv loss: -89.93%\n",
      "Timesteps 11/50 - acc spiking (orig): 9.99% (97.74%) - conv loss: -89.78%\n",
      "Timesteps 12/50 - acc spiking (orig): 10.55% (97.74%) - conv loss: -89.21%\n",
      "Timesteps 13/50 - acc spiking (orig): 12.04% (97.74%) - conv loss: -87.68%\n",
      "Timesteps 14/50 - acc spiking (orig): 14.87% (97.74%) - conv loss: -84.79%\n",
      "Timesteps 15/50 - acc spiking (orig): 19.95% (97.74%) - conv loss: -79.59%\n",
      "Timesteps 16/50 - acc spiking (orig): 26.32% (97.74%) - conv loss: -73.07%\n",
      "Timesteps 17/50 - acc spiking (orig): 34.31% (97.74%) - conv loss: -64.90%\n",
      "Timesteps 18/50 - acc spiking (orig): 43.94% (97.74%) - conv loss: -55.04%\n",
      "Timesteps 19/50 - acc spiking (orig): 53.80% (97.74%) - conv loss: -44.96%\n",
      "Timesteps 20/50 - acc spiking (orig): 63.22% (97.74%) - conv loss: -35.32%\n",
      "Timesteps 21/50 - acc spiking (orig): 71.23% (97.74%) - conv loss: -27.12%\n",
      "Timesteps 22/50 - acc spiking (orig): 77.44% (97.74%) - conv loss: -20.77%\n",
      "Timesteps 23/50 - acc spiking (orig): 81.82% (97.74%) - conv loss: -16.29%\n",
      "Timesteps 24/50 - acc spiking (orig): 85.26% (97.74%) - conv loss: -12.77%\n",
      "Timesteps 25/50 - acc spiking (orig): 87.59% (97.74%) - conv loss: -10.38%\n",
      "Timesteps 26/50 - acc spiking (orig): 89.23% (97.74%) - conv loss: -8.71%\n",
      "Timesteps 27/50 - acc spiking (orig): 90.23% (97.74%) - conv loss: -7.68%\n",
      "Timesteps 28/50 - acc spiking (orig): 91.14% (97.74%) - conv loss: -6.75%\n",
      "Timesteps 29/50 - acc spiking (orig): 92.05% (97.74%) - conv loss: -5.82%\n",
      "Timesteps 30/50 - acc spiking (orig): 92.36% (97.74%) - conv loss: -5.50%\n",
      "Timesteps 31/50 - acc spiking (orig): 92.93% (97.74%) - conv loss: -4.92%\n",
      "Timesteps 32/50 - acc spiking (orig): 93.62% (97.74%) - conv loss: -4.22%\n",
      "Timesteps 33/50 - acc spiking (orig): 94.11% (97.74%) - conv loss: -3.71%\n",
      "Timesteps 34/50 - acc spiking (orig): 94.36% (97.74%) - conv loss: -3.46%\n",
      "Timesteps 35/50 - acc spiking (orig): 94.81% (97.74%) - conv loss: -3.00%\n",
      "Timesteps 36/50 - acc spiking (orig): 95.04% (97.74%) - conv loss: -2.76%\n",
      "Timesteps 37/50 - acc spiking (orig): 95.27% (97.74%) - conv loss: -2.53%\n",
      "Timesteps 38/50 - acc spiking (orig): 95.64% (97.74%) - conv loss: -2.15%\n",
      "Timesteps 39/50 - acc spiking (orig): 95.68% (97.74%) - conv loss: -2.11%\n",
      "Timesteps 40/50 - acc spiking (orig): 96.01% (97.74%) - conv loss: -1.77%\n",
      "Timesteps 41/50 - acc spiking (orig): 96.02% (97.74%) - conv loss: -1.76%\n",
      "Timesteps 42/50 - acc spiking (orig): 96.09% (97.74%) - conv loss: -1.69%\n",
      "Timesteps 43/50 - acc spiking (orig): 96.17% (97.74%) - conv loss: -1.61%\n",
      "Timesteps 44/50 - acc spiking (orig): 96.18% (97.74%) - conv loss: -1.60%\n",
      "Timesteps 45/50 - acc spiking (orig): 96.34% (97.74%) - conv loss: -1.43%\n",
      "Timesteps 46/50 - acc spiking (orig): 96.54% (97.74%) - conv loss: -1.23%\n",
      "Timesteps 47/50 - acc spiking (orig): 96.51% (97.74%) - conv loss: -1.26%\n",
      "Timesteps 48/50 - acc spiking (orig): 96.69% (97.74%) - conv loss: -1.07%\n",
      "Timesteps 49/50 - acc spiking (orig): 96.81% (97.74%) - conv loss: -0.95%\n",
      "Timesteps 50/50 - acc spiking (orig): 96.89% (97.74%) - conv loss: -0.87%\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Import Data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train = x_train.reshape((60000, 784))\n",
    "x_test = x_test.reshape((10000, 784))\n",
    "\n",
    "# Analog model\n",
    "ann = create_ann()\n",
    "\n",
    "_, testacc = ann.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "#weights = ann.get_weights()\n",
    "weights = get_normalized_weights(ann, x_train, percentile=85)\n",
    "\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "#x_rnn = np.tile(x_train, (1, 1, 1))\n",
    "#y_rnn = y_train  # np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "snn = convert(ann, weights, x_test, y_test)\n",
    "evaluate_conversion(snn, ann, x_test, y_test, testacc, timesteps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    \n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scale = inputs[1]\n",
    "        return inputs[0] / scale\n",
    "\n",
    "    \n",
    "class MatMulLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1])\n",
    "\n",
    "    \n",
    "class MatMulLayerTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayerTranspose, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1], transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 192) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "(500, 50, 192)\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 19s 150ms/step - loss: 1.4263 - accuracy: 0.5409 - val_loss: 0.3095 - val_accuracy: 0.9101\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 18s 147ms/step - loss: 0.2888 - accuracy: 0.9133 - val_loss: 0.2013 - val_accuracy: 0.9423\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 18s 147ms/step - loss: 0.1995 - accuracy: 0.9433 - val_loss: 0.1544 - val_accuracy: 0.9555\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 18s 147ms/step - loss: 0.1548 - accuracy: 0.9542 - val_loss: 0.1308 - val_accuracy: 0.9595\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 18s 147ms/step - loss: 0.1308 - accuracy: 0.9615 - val_loss: 0.1187 - val_accuracy: 0.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5b009f2d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fully Functional Modular version with Multiply layers instead of einsums\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "patch_size = 4\n",
    "channels = 1\n",
    "patch_dim = channels * patch_size ** 2\n",
    "d_model = 64*3\n",
    "image_size = 28\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "batch_size = 500\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# # Flat dataset loading\n",
    "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# x_train, x_test = x_train / 255., x_test / 255.\n",
    "# x_train = x_train.reshape((60000, 784))\n",
    "# x_test = x_test.reshape((10000, 784))\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "patches = extract_patches(inp)\n",
    "x = tf.keras.layers.Dense(d_model)(patches)\n",
    "\n",
    "pos_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, num_patches + 1, d_model)), \n",
    "                      name=\"pos_emb\", validate_shape=(1, num_patches + 1, d_model), trainable=True)\n",
    "class_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, 1, d_model)), name=\"class_emb\", \n",
    "                        validate_shape=(1, 1, d_model), trainable=True)\n",
    "\n",
    "class_emb = tf.broadcast_to(class_emb, [batch_size, 1, d_model])\n",
    "\n",
    "x = tf.concat([class_emb, x], axis=1)\n",
    "x = x + pos_emb\n",
    "\n",
    "# x = tf.keras.layers.Reshape([50, 64*3])(x)\n",
    "\n",
    "# att = MultiHeadsAttModel(l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8 )\n",
    "# x = att([x,x,x])\n",
    "l = 50\n",
    "d = 64*3\n",
    "dv = 8*3\n",
    "dout = 32\n",
    "nv = 8\n",
    "# v1 = tf.keras.layers.Input()(x)\n",
    "# q1 = tf.keras.layers.Input()(x)\n",
    "# k1 = tf.keras.layers.Input()(x)\n",
    "\n",
    "v2 = tf.keras.layers.Dense(dv*nv, activation=\"relu\")(x)\n",
    "q2 = tf.keras.layers.Dense(dv*nv, activation=\"relu\")(x)\n",
    "k2 = tf.keras.layers.Dense(dv*nv, activation=\"relu\")(x)\n",
    "print(v2.shape)\n",
    "v = tf.keras.layers.Reshape([l, nv, dv])(v2)\n",
    "q = tf.keras.layers.Reshape([l, nv, dv])(q2)\n",
    "k = tf.keras.layers.Reshape([l, nv, dv])(k2)\n",
    "\n",
    "# att = tf.keras.layers.Multiply()([q, k])\n",
    "att = MatMulLayerTranspose()\n",
    "att = att([q, k])\n",
    "# att = tf.matmul(q, k , transpose_b=True)\n",
    "\n",
    "# att = att/np.sqrt(dv)\n",
    "# att = tf.keras.layers.Multiply()([att, 1/np.sqrt(dv)])\n",
    "# att = tf.math.divide(att, np.sqrt(dv))\n",
    "att = ScaleLayer()([att, np.sqrt(dv)])\n",
    "# att = tf.einsum('baik,baij->bakj',q, k)/np.sqrt(dv)\n",
    "att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "\n",
    "# out = tf.einsum('bajk,baik->baji',att, v)\n",
    "\n",
    "# out = tf.keras.layers.Multiply()([att, v])\n",
    "\n",
    "out = MatMulLayer()([att, v])\n",
    "# out = tf.matmul(att, v)\n",
    "\n",
    "out = tf.keras.layers.Reshape([l, d])(out)\n",
    "x = tf.keras.layers.Reshape([l, d])(x)\n",
    "# out = tf.expand_dims(out, axis=3)\n",
    "# x = tf.expand_dims(x, axis=3)\n",
    "add = tf.keras.layers.Add()([out, x])\n",
    "\n",
    "out = tf.keras.layers.Dense(dout, activation=\"relu\")(add)\n",
    "\n",
    "# x = tf.keras.layers.Reshape([6, 6, 32])(out)\n",
    "\n",
    "# out = tf.keras.layers.BatchNormalization()(out)\n",
    "\n",
    "out = tf.keras.layers.Flatten()(out)\n",
    "# out = tf.keras.layers.Dense(32, activation='relu')(out)\n",
    "out = tf.keras.layers.Dense(num_classes, activation='softmax')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=500, epochs=5, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (4,)                 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.extract_patches (TFOpL (None, 7, 7, 16)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, None, 16)     0           tf.image.extract_patches[0][0]   \n",
      "                                                                 tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 192)    3264        tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (500, None, 192)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (500, 50, 192)       0           tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (500, 50, 192)       37056       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (500, 50, 192)       37056       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (500, 50, 8, 24)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (500, 50, 8, 24)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose (MatMul (500, 50, 8, 8)      0           reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer (ScaleLayer)        (500, 50, 8, 8)      0           mat_mul_layer_transpose[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (500, 50, 192)       37056       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (500, 50, 8, 8)      0           scale_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (500, 50, 8, 24)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer (MatMulLayer)     (500, 50, 8, 24)     0           softmax[0][0]                    \n",
      "                                                                 reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (500, 50, 192)       0           mat_mul_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (500, 50, 192)       0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (500, 50, 192)       0           reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (500, 50, 32)        6176        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (500, 1600)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (500, 10)            16010       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 136,618\n",
      "Trainable params: 136,618\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-608b6c70530d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnum_patches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpatch_size\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_patches(self, images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "        strides=[1, self.patch_size, self.patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\n",
    "    return patches\n",
    "\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "self.patch_dim = channels * patch_size ** 2\n",
    "\n",
    "self.patch_size = patch_size\n",
    "self.d_model = d_model\n",
    "self.num_layers = num_layers\n",
    "\n",
    "self.rescale = Rescaling(1.0 / 255)\n",
    "self.pos_emb = self.add_weight(\n",
    "    \"pos_emb\", shape=(1, num_patches + 1, d_model)\n",
    ")\n",
    "self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "self.patch_proj = Dense(d_model)\n",
    "self.enc_layers = [\n",
    "    TransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "    for _ in range(num_layers)\n",
    "]\n",
    "LayerNormalization(epsilon=1e-6)\n",
    "Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "Dropout(dropout),\n",
    "Dense(num_classes),\n",
    "\n",
    "\n",
    "\n",
    "batch_size = tf.shape(x)[0]\n",
    "x = Rescaling(1.0 / 255)(x)\n",
    "patches = extract_patches(x)\n",
    "x = Dense(d_model)(patches)\n",
    "\n",
    "class_emb = tf.broadcast_to(\n",
    "    self.class_emb, [batch_size, 1, self.d_model]\n",
    ")\n",
    "print(x.shape)\n",
    "print(class_emb.shape)\n",
    "print(self.pos_emb.shape)\n",
    "x = tf.concat([class_emb, x], axis=1)\n",
    "x = x + self.pos_emb\n",
    "\n",
    "for layer in self.enc_layers:\n",
    "    x = layer(x, training)\n",
    "\n",
    "# First (class token) is used for classification\n",
    "x = self.mlp_head(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "logdir = \"logs\"\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_layers = 4\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 28, 28, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tfds.load(\"mnist\", as_supervised=True)\n",
    "\n",
    "ds_train = (ds[\"train\"].shuffle(5 * batch_size).batch(batch_size))\n",
    "\n",
    "ds_test = (\n",
    "    ds[\"test\"]\n",
    "    .cache()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "next(iter(ds_train))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "# x_train = x_train / 255\n",
    "# x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = tf.expand_dims(x_train, axis)\n",
    "x_test = tf.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VisionTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b099064525c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = VisionTransformer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VisionTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=10,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    channels=1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "# model.fit(\n",
    "#     ds_train,\n",
    "#     validation_data=ds_test,\n",
    "#     epochs=1,\n",
    "# )\n",
    "\n",
    "# model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vision_transformer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             multiple                  1088      \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform multiple                  33472     \n",
      "_________________________________________________________________\n",
      "transformer_block_1 (Transfo multiple                  33472     \n",
      "_________________________________________________________________\n",
      "transformer_block_2 (Transfo multiple                  33472     \n",
      "_________________________________________________________________\n",
      "transformer_block_3 (Transfo multiple                  33472     \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 10)                9738      \n",
      "=================================================================\n",
      "Total params: 147,978\n",
      "Trainable params: 147,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiking Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    RNN\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class SpikingMultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SpikingTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = SpikingMultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim),\n",
    "                RNN(SpikingReLU(mlp_dim), return_sequences=True, return_state=False, stateful=True),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.4.1 and trying to load a custom op (custom_ops/activations/_activation_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.2.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.2.0 and strictly below 2.3.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/options.py:47: RuntimeWarning: Traceback (most recent call last):\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 56, in gelu\n",
      "    return _gelu_custom_op(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 71, in _gelu_custom_op\n",
      "    return _activation_so.ops.addons_gelu(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py\", line 64, in ops\n",
      "    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 57, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/custom_ops/activations/_activation_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\n",
      "\n",
      "\n",
      "The gelu C++/CUDA custom op could not be loaded.\n",
      "For this reason, Addons will fallback to an implementation written\n",
      "in Python with public TensorFlow ops. There worst you might experience with\n",
      "this is a moderate slowdown on GPU. There can be multiple\n",
      "reason for this loading error, one of them may be an ABI incompatibility between\n",
      "the TensorFlow installed on your system and the TensorFlow used to compile\n",
      "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
      "shared object file was displayed above.\n",
      "\n",
      "If you want this warning to disappear, either make sure the TensorFlow installed\n",
      "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
      "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
      "by changing the TF_ADDONS_PY_OPS flag\n",
      "either with the environment variable:\n",
      "```bash\n",
      "TF_ADDONS_PY_OPS=1 python my_script.py\n",
      "```\n",
      "or in your code, after your imports:\n",
      "```python\n",
      "import tensorflow_addons as tfa\n",
      "import ...\n",
      "import ...\n",
      "\n",
      "tfa.options.TF_ADDONS_PY_OPS = True\n",
      "```\n",
      "\n",
      "  warnings.warn(warning_msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 21s 17ms/step - loss: 0.9392 - accuracy: 0.6778 - val_loss: 0.2894 - val_accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5afdd38e50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "dropout = 0.1\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "def extract_patches(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(input_shape))\n",
    "x = Rescaling(1.0 / 255)(inp)\n",
    "\n",
    "# =============== VISION PART =====================\n",
    "# patching, positional embedding and class embedding\n",
    "patches = extract_patches(x)\n",
    "x = Dense(d_model)(patches)\n",
    "\n",
    "pos_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, num_patches + 1, d_model)), \n",
    "                      name=\"pos_emb\", validate_shape=(1, num_patches + 1, d_model), trainable=True)\n",
    "class_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, 1, d_model)), name=\"class_emb\", \n",
    "                        validate_shape=(1, 1, d_model), trainable=True)\n",
    "\n",
    "class_emb = tf.broadcast_to(class_emb, [batch_size, 1, d_model])\n",
    "\n",
    "x = tf.concat([class_emb, x], axis=1)\n",
    "x = x + pos_emb\n",
    "\n",
    "# Transformer Blocks\n",
    "x = TransformerBlock(d_model, num_heads, mlp_dim, dropout)(x)\n",
    "\n",
    "# ================= MLP HEAD ===================\n",
    "x = Dense(mlp_dim, activation=tf.nn.relu)(x[:, 0])\n",
    "x = Dense(num_classes)(x)\n",
    "\n",
    "# ================ Model compilation and training ==================\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling_3 (Rescaling)         (None, 28, 28, 1)    0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (4,)                 0           rescaling_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.extract_patches_1 (TFO (None, 7, 7, 16)     0           rescaling_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_1 (TFOpLambda)       (None, None, 16)     0           tf.image.extract_patches_1[0][0] \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 64)     1088        tf.reshape_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (50, None, 64)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (50, 50, 64)         0           tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (50, 50, 64)         33472       tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (50, 64)             0           transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (50, 128)            8320        tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (50, 10)             1290        dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 44,170\n",
      "Trainable params: 44,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "def convert(model, weights, x_test, y_test):\n",
    "    print(\"Converted model:\\n\" + \"-\"*32)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            print(\"Input Layer\")\n",
    "            inputs = tf.keras.Input(shape=(1, model.layers[0].input_shape[0][1]), batch_size=y_test.shape[0])\n",
    "            x = inputs        \n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            x = tf.keras.layers.Dense(layer.output_shape[1])(x)\n",
    "            # x = tf.keras.layers.RNN(DenseRNN(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            if layer.activation.__name__ == 'linear':\n",
    "                print(\"Dense Layer w/o activation\")\n",
    "                pass\n",
    "            elif layer.activation.__name__ == 'relu':\n",
    "                print(\"Dense Layer with SpikingReLU\")\n",
    "                x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'sigmoid':\n",
    "                print(\"Dense Layer with SpikingSigmoid\")\n",
    "                x = tf.keras.layers.RNN(SpikingSigmoid(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'tanh':\n",
    "                print(\"Dense Layer with SpikingTanh\")\n",
    "                x = tf.keras.layers.RNN(SpikingTanh(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            else:\n",
    "                print('[Info] Activation type', layer.activation.__name__, 'not implemented')\n",
    "        elif isinstance(layer, tf.keras.layers.ReLU):\n",
    "            print(\"SpikingReLU Layer\")\n",
    "            x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "        elif isinstance(layer, tf.keras.layers.Softmax):\n",
    "            print(\"Accumulate + Softmax Layer\")\n",
    "            print(layer.output_shape[1])\n",
    "            x = tf.keras.layers.RNN(Accumulate(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            x = tf.keras.layers.Softmax()(x)\n",
    "        elif isinstance(layer, TransformerBlock):\n",
    "            x  = SpikingTransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "        else:\n",
    "            print(\"[Info] Layer type \", layer, \"not implemented, so we use it's keras version\")\n",
    "            x = layer(x)\n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "\n",
    "    spiking.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [50,1,64] vs. shape[1] = [60000,49,64] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fad6126523a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_normalized_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m##################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocessing for RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (60000, 784) -> (60000, 1, 784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4b8b1471280f>\u001b[0m in \u001b[0;36mget_normalized_weights\u001b[0;34m(model, x_test, percentile)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_activation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mmax_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \"\"\"\n\u001b[0;32m--> 424\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    425\u001b[0m         inputs, training=training, mask=mask)\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1675\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [50,1,64] vs. shape[1] = [60000,49,64] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "weights = get_normalized_weights(model, x_train, percentile=85)\n",
    "\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "#x_rnn = np.tile(x_train, (1, 1, 1))\n",
    "#y_rnn = y_train  # np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "snn = convert(ann, weights, x_test, y_test)\n",
    "evaluate_conversion(snn, ann, x_test, y_test, testacc, timesteps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
