{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from spiking_models import DenseRNN, SpikingReLU, SpikingSigmoid, SpikingTanh, Accumulate\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etienne's conversion code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(model, weights, x_test, y_test):\n",
    "    print(\"Converted model:\\n\" + \"-\"*32)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            print(\"Input Layer\")\n",
    "            inputs = tf.keras.Input(shape=(1, model.layers[0].input_shape[0][1]), batch_size=y_test.shape[0])\n",
    "            x = inputs        \n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            x = tf.keras.layers.Dense(layer.output_shape[1])(x)\n",
    "            # x = tf.keras.layers.RNN(DenseRNN(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            if layer.activation.__name__ == 'linear':\n",
    "                print(\"Dense Layer w/o activation\")\n",
    "                pass\n",
    "            elif layer.activation.__name__ == 'relu':\n",
    "                print(\"Dense Layer with SpikingReLU\")\n",
    "                x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'sigmoid':\n",
    "                print(\"Dense Layer with SpikingSigmoid\")\n",
    "                x = tf.keras.layers.RNN(SpikingSigmoid(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'tanh':\n",
    "                print(\"Dense Layer with SpikingTanh\")\n",
    "                x = tf.keras.layers.RNN(SpikingTanh(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            else:\n",
    "                print('[Info] Activation type', layer.activation.__name__, 'not implemented')\n",
    "        elif isinstance(layer, tf.keras.layers.ReLU):\n",
    "            print(\"SpikingReLU Layer\")\n",
    "            x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "        elif isinstance(layer, tf.keras.layers.Softmax):\n",
    "            print(\"Accumulate + Softmax Layer\")\n",
    "            print(layer.output_shape[1])\n",
    "            x = tf.keras.layers.RNN(Accumulate(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            x = tf.keras.layers.Softmax()(x)\n",
    "        else:\n",
    "            print(\"[Info] Layer type \", layer, \"not implemented\")\n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "\n",
    "    spiking.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_weights(model, x_test, percentile=100):\n",
    "#     x_test = x_test[::25]\n",
    "    max_activation = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ReLU):\n",
    "            activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "            if np.percentile(activation, percentile) > max_activation:\n",
    "                max_activation = np.percentile(activation, percentile)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            if layer.activation.__name__ == 'relu':\n",
    "                activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "                if np.percentile(activation, percentile) > max_activation:\n",
    "                    max_activation = np.percentile(activation, percentile)\n",
    "\n",
    "    weights = model.get_weights()     \n",
    "    if max_activation == 0:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNo normalization\\n\" + \"-\"*32)\n",
    "    else:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNormalizing by\", max_activation, \"\\n\" + \"-\"*32)\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] /= (max_activation)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_conversion(converted_model, original_model, x_test, y_test, testacc, timesteps=50):\n",
    "    for i in range(1, timesteps+1):\n",
    "        _, acc = converted_model.evaluate(x_test, y_test, batch_size=y_test.shape[0], verbose=0)\n",
    "        print(\n",
    "            \"Timesteps\", str(i) + \"/\" + str(timesteps) + \" -\",\n",
    "            \"acc spiking (orig): %.2f%% (%.2f%%)\" % (acc*100, testacc*100),\n",
    "            \"- conv loss: %+.2f%%\" % ((-(1 - acc/testacc)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "batch_size=512\n",
    "epochs = 5\n",
    "act='relu'\n",
    "\n",
    "\n",
    "def create_ann():\n",
    "    inputs = tf.keras.Input(shape=(784,))\n",
    "    x = tf.keras.layers.Dense(500, activation=act)(inputs)\n",
    "    #x = tf.keras.layers.ReLU()(x)  # max_value=1\n",
    "    x = tf.keras.layers.Dense(100, activation=act)(x)\n",
    "#     x = tf.keras.layers.Dense(200)(x)\n",
    "    #x = tf.keras.layers.Activation(tf.nn.relu)(x)  # not implemented yet\n",
    "    x = tf.keras.layers.Dense(10, activation=act)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    ann = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    ann.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    ann.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.7013 - sparse_categorical_accuracy: 0.7837\n",
      "Epoch 2/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1656 - sparse_categorical_accuracy: 0.9499\n",
      "Epoch 3/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.1091 - sparse_categorical_accuracy: 0.9670\n",
      "Epoch 4/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.0562 - sparse_categorical_accuracy: 0.9831\n",
      "\n",
      "--------------------------------\n",
      "Normalizing by 3.329308807849884 \n",
      "--------------------------------\n",
      "Converted model:\n",
      "--------------------------------\n",
      "Input Layer\n",
      "Dense Layer with SpikingReLU\n",
      "Dense Layer with SpikingReLU\n",
      "Dense Layer with SpikingReLU\n",
      "Accumulate + Softmax Layer\n",
      "10\n",
      "--------------------------------\n",
      "\n",
      "Timesteps 1/100 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 2/100 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 3/100 - acc spiking (orig): 9.80% (97.74%) - conv loss: -89.97%\n",
      "Timesteps 4/100 - acc spiking (orig): 10.09% (97.74%) - conv loss: -89.68%\n",
      "Timesteps 5/100 - acc spiking (orig): 15.88% (97.74%) - conv loss: -83.75%\n",
      "Timesteps 6/100 - acc spiking (orig): 34.89% (97.74%) - conv loss: -64.30%\n",
      "Timesteps 7/100 - acc spiking (orig): 61.51% (97.74%) - conv loss: -37.07%\n",
      "Timesteps 8/100 - acc spiking (orig): 80.53% (97.74%) - conv loss: -17.61%\n",
      "Timesteps 9/100 - acc spiking (orig): 88.14% (97.74%) - conv loss: -9.82%\n",
      "Timesteps 10/100 - acc spiking (orig): 92.30% (97.74%) - conv loss: -5.57%\n",
      "Timesteps 11/100 - acc spiking (orig): 94.13% (97.74%) - conv loss: -3.69%\n",
      "Timesteps 12/100 - acc spiking (orig): 95.36% (97.74%) - conv loss: -2.44%\n",
      "Timesteps 13/100 - acc spiking (orig): 95.89% (97.74%) - conv loss: -1.89%\n",
      "Timesteps 14/100 - acc spiking (orig): 96.40% (97.74%) - conv loss: -1.37%\n",
      "Timesteps 15/100 - acc spiking (orig): 96.88% (97.74%) - conv loss: -0.88%\n",
      "Timesteps 16/100 - acc spiking (orig): 97.03% (97.74%) - conv loss: -0.73%\n",
      "Timesteps 17/100 - acc spiking (orig): 97.14% (97.74%) - conv loss: -0.61%\n",
      "Timesteps 18/100 - acc spiking (orig): 97.21% (97.74%) - conv loss: -0.54%\n",
      "Timesteps 19/100 - acc spiking (orig): 97.25% (97.74%) - conv loss: -0.50%\n",
      "Timesteps 20/100 - acc spiking (orig): 97.28% (97.74%) - conv loss: -0.47%\n",
      "Timesteps 21/100 - acc spiking (orig): 97.43% (97.74%) - conv loss: -0.32%\n",
      "Timesteps 22/100 - acc spiking (orig): 97.51% (97.74%) - conv loss: -0.24%\n",
      "Timesteps 23/100 - acc spiking (orig): 97.49% (97.74%) - conv loss: -0.26%\n",
      "Timesteps 24/100 - acc spiking (orig): 97.50% (97.74%) - conv loss: -0.25%\n",
      "Timesteps 25/100 - acc spiking (orig): 97.58% (97.74%) - conv loss: -0.16%\n",
      "Timesteps 26/100 - acc spiking (orig): 97.63% (97.74%) - conv loss: -0.11%\n",
      "Timesteps 27/100 - acc spiking (orig): 97.60% (97.74%) - conv loss: -0.14%\n",
      "Timesteps 28/100 - acc spiking (orig): 97.61% (97.74%) - conv loss: -0.13%\n",
      "Timesteps 29/100 - acc spiking (orig): 97.63% (97.74%) - conv loss: -0.11%\n",
      "Timesteps 30/100 - acc spiking (orig): 97.62% (97.74%) - conv loss: -0.12%\n",
      "Timesteps 31/100 - acc spiking (orig): 97.68% (97.74%) - conv loss: -0.06%\n",
      "Timesteps 32/100 - acc spiking (orig): 97.62% (97.74%) - conv loss: -0.12%\n",
      "Timesteps 33/100 - acc spiking (orig): 97.67% (97.74%) - conv loss: -0.07%\n",
      "Timesteps 34/100 - acc spiking (orig): 97.73% (97.74%) - conv loss: -0.01%\n",
      "Timesteps 35/100 - acc spiking (orig): 97.65% (97.74%) - conv loss: -0.09%\n",
      "Timesteps 36/100 - acc spiking (orig): 97.64% (97.74%) - conv loss: -0.10%\n",
      "Timesteps 37/100 - acc spiking (orig): 97.71% (97.74%) - conv loss: -0.03%\n",
      "Timesteps 38/100 - acc spiking (orig): 97.70% (97.74%) - conv loss: -0.04%\n",
      "Timesteps 39/100 - acc spiking (orig): 97.63% (97.74%) - conv loss: -0.11%\n",
      "Timesteps 40/100 - acc spiking (orig): 97.65% (97.74%) - conv loss: -0.09%\n",
      "Timesteps 41/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 42/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n",
      "Timesteps 43/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 44/100 - acc spiking (orig): 97.66% (97.74%) - conv loss: -0.08%\n",
      "Timesteps 45/100 - acc spiking (orig): 97.67% (97.74%) - conv loss: -0.07%\n",
      "Timesteps 46/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 47/100 - acc spiking (orig): 97.83% (97.74%) - conv loss: +0.09%\n",
      "Timesteps 48/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 49/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 50/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 51/100 - acc spiking (orig): 97.65% (97.74%) - conv loss: -0.09%\n",
      "Timesteps 52/100 - acc spiking (orig): 97.68% (97.74%) - conv loss: -0.06%\n",
      "Timesteps 53/100 - acc spiking (orig): 97.69% (97.74%) - conv loss: -0.05%\n",
      "Timesteps 54/100 - acc spiking (orig): 97.73% (97.74%) - conv loss: -0.01%\n",
      "Timesteps 55/100 - acc spiking (orig): 97.74% (97.74%) - conv loss: -0.00%\n",
      "Timesteps 56/100 - acc spiking (orig): 97.72% (97.74%) - conv loss: -0.02%\n",
      "Timesteps 57/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 58/100 - acc spiking (orig): 97.78% (97.74%) - conv loss: +0.04%\n",
      "Timesteps 59/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 60/100 - acc spiking (orig): 97.74% (97.74%) - conv loss: -0.00%\n",
      "Timesteps 61/100 - acc spiking (orig): 97.71% (97.74%) - conv loss: -0.03%\n",
      "Timesteps 62/100 - acc spiking (orig): 97.74% (97.74%) - conv loss: -0.00%\n",
      "Timesteps 63/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 64/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n",
      "Timesteps 65/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 66/100 - acc spiking (orig): 97.81% (97.74%) - conv loss: +0.07%\n",
      "Timesteps 67/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 68/100 - acc spiking (orig): 97.72% (97.74%) - conv loss: -0.02%\n",
      "Timesteps 69/100 - acc spiking (orig): 97.69% (97.74%) - conv loss: -0.05%\n",
      "Timesteps 70/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 71/100 - acc spiking (orig): 97.70% (97.74%) - conv loss: -0.04%\n",
      "Timesteps 72/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n",
      "Timesteps 73/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 74/100 - acc spiking (orig): 97.71% (97.74%) - conv loss: -0.03%\n",
      "Timesteps 75/100 - acc spiking (orig): 97.72% (97.74%) - conv loss: -0.02%\n",
      "Timesteps 76/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 77/100 - acc spiking (orig): 97.73% (97.74%) - conv loss: -0.01%\n",
      "Timesteps 78/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 79/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 80/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 81/100 - acc spiking (orig): 97.73% (97.74%) - conv loss: -0.01%\n",
      "Timesteps 82/100 - acc spiking (orig): 97.76% (97.74%) - conv loss: +0.02%\n",
      "Timesteps 83/100 - acc spiking (orig): 97.74% (97.74%) - conv loss: -0.00%\n",
      "Timesteps 84/100 - acc spiking (orig): 97.80% (97.74%) - conv loss: +0.06%\n",
      "Timesteps 85/100 - acc spiking (orig): 97.84% (97.74%) - conv loss: +0.10%\n",
      "Timesteps 86/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 87/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n",
      "Timesteps 88/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 89/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 90/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n",
      "Timesteps 91/100 - acc spiking (orig): 97.78% (97.74%) - conv loss: +0.04%\n",
      "Timesteps 92/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 93/100 - acc spiking (orig): 97.75% (97.74%) - conv loss: +0.01%\n",
      "Timesteps 94/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 95/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 96/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n",
      "Timesteps 97/100 - acc spiking (orig): 97.78% (97.74%) - conv loss: +0.04%\n",
      "Timesteps 98/100 - acc spiking (orig): 97.77% (97.74%) - conv loss: +0.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps 99/100 - acc spiking (orig): 97.81% (97.74%) - conv loss: +0.07%\n",
      "Timesteps 100/100 - acc spiking (orig): 97.79% (97.74%) - conv loss: +0.05%\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Import Data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train = x_train.reshape((60000, 784))\n",
    "x_test = x_test.reshape((10000, 784))\n",
    "\n",
    "# Analog model\n",
    "ann = create_ann()\n",
    "\n",
    "_, testacc = ann.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "# weights = ann.get_weights()\n",
    "weights = get_normalized_weights(ann, x_train, percentile=75)\n",
    "\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "#x_rnn = np.tile(x_train, (1, 1, 1))\n",
    "#y_rnn = y_train  # np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "snn = convert(ann, weights, x_test, y_test)\n",
    "evaluate_conversion(snn, ann, x_test, y_test, testacc, timesteps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST ViT Adapted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    \n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scale = inputs[1]\n",
    "        return inputs[0] / scale\n",
    "\n",
    "    \n",
    "class MatMulLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1])\n",
    "\n",
    "    \n",
    "class MatMulLayerTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayerTranspose, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1], transpose_b=True)\n",
    "\n",
    "    \n",
    "class PositionalEncodingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PositionalEncodingLayer, self).__init__()\n",
    "        self.pos_emb = self.add_weight(\"pos_emb\", shape=(1, num_patches + 1, d_model))\n",
    "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        class_emb = tf.broadcast_to(self.class_emb, [batch_size, 1, d_model])\n",
    "        x = tf.concat([class_emb, inputs], axis=1)\n",
    "        return x + self.pos_emb\n",
    "\n",
    "    \n",
    "class ExtractPatchesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ExtractPatchesLayer, self).__init__()\n",
    "        self.patch_size = 4\n",
    "        self.patch_dim = 16\n",
    "        \n",
    "    def extract_patches(self, images, patch_size, patch_dim):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, patch_size, patch_size, 1],\n",
    "            strides=[1, patch_size, patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "        return patches\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.extract_patches(inputs, self.patch_size, self.patch_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 6s 6ms/step - loss: 0.6276 - accuracy: 0.8023 - val_loss: 0.1368 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0a0706910>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fully Functional Modular version with Multiply layers instead of einsums\n",
    "\"\"\"\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "channels = 1\n",
    "patch_dim = channels * patch_size ** 2\n",
    "batch_size = 64\n",
    "embed_dim = d_model = 64\n",
    "\n",
    "l = 50\n",
    "d = 192\n",
    "dv = 24\n",
    "dout = 32\n",
    "nv = 8\n",
    "\n",
    "inp = Input(shape=(28, 28, 1))\n",
    "patches = ExtractPatchesLayer()(inp)\n",
    "x = tf.keras.layers.Dense(d_model, activation=\"relu\")(patches)\n",
    "x = PositionalEncodingLayer()(x)\n",
    "\n",
    "# Attention Module\n",
    "v2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "q2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "k2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "\n",
    "v = tf.keras.layers.Reshape([l, nv, nv])(v2)\n",
    "q = tf.keras.layers.Reshape([l, nv, nv])(q2)\n",
    "k = tf.keras.layers.Reshape([l, nv, nv])(k2)\n",
    "\n",
    "# =============== Scaled dot-product attention =================\n",
    "# QK^T\n",
    "att = MatMulLayerTranspose()([q, k])\n",
    "# softmax(QK^T)\n",
    "att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "# softmax(QK^T)*V\n",
    "out = MatMulLayer()([att, v])\n",
    "\n",
    "out = tf.keras.layers.Reshape([l, d_model, 1])(out)\n",
    "x = tf.keras.layers.Reshape([l, d_model, 1])(x)\n",
    "\n",
    "# Concat Layer\n",
    "add = tf.keras.layers.Add()([out, x])\n",
    "out = tf.keras.layers.Flatten()(add)\n",
    "\n",
    "out = tf.keras.layers.Dense(32, activation=\"relu\")(out)\n",
    "out = tf.keras.layers.Dense(num_classes, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "def convert(model, weights, x_test, y_test):\n",
    "    print(\"Converted model:\\n\" + \"-\"*32)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            print(\"Input Layer\")\n",
    "            inputs = tf.keras.Input(shape=(1, model.layers[0].input_shape[0][1]), batch_size=y_test.shape[0])\n",
    "            x = inputs        \n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            x = tf.keras.layers.Dense(layer.output_shape[1])(x)\n",
    "            # x = tf.keras.layers.RNN(DenseRNN(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            if layer.activation.__name__ == 'linear':\n",
    "                print(\"Dense Layer w/o activation\")\n",
    "                pass\n",
    "            elif layer.activation.__name__ == 'relu':\n",
    "                print(\"Dense Layer with SpikingReLU\")\n",
    "                x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'sigmoid':\n",
    "                print(\"Dense Layer with SpikingSigmoid\")\n",
    "                x = tf.keras.layers.RNN(SpikingSigmoid(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'tanh':\n",
    "                print(\"Dense Layer with SpikingTanh\")\n",
    "                x = tf.keras.layers.RNN(SpikingTanh(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            else:\n",
    "                print('[Info] Activation type', layer.activation.__name__, 'not implemented')\n",
    "        elif isinstance(layer, tf.keras.layers.ReLU):\n",
    "            print(\"SpikingReLU Layer\")\n",
    "            x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "        elif isinstance(layer, tf.keras.layers.Softmax):\n",
    "            print(\"Accumulate + Softmax Layer\")\n",
    "            print(layer.output_shape[1])\n",
    "            x = tf.keras.layers.RNN(Accumulate(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            x = tf.keras.layers.Softmax()(x)\n",
    "#         elif isinstance(layer, TransformerBlock):\n",
    "#             x  = SpikingTransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "        else:\n",
    "            print(\"[Info] Layer type \", layer, \"not implemented, so we just use it's non-spiking version\")\n",
    "            try:\n",
    "                x = layer(x)\n",
    "            except:\n",
    "                import pdb;pdb.set_trace()\n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "\n",
    "    spiking.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converted_model(weights):\n",
    "    num_classes = 10\n",
    "    image_size = 28\n",
    "    patch_size = 4\n",
    "    num_patches = (image_size // patch_size) ** 2\n",
    "    channels = 1\n",
    "    patch_dim = channels * patch_size ** 2\n",
    "    batch_size = 64\n",
    "    embed_dim = d_model = 64\n",
    "\n",
    "    l = 50\n",
    "    d = 192\n",
    "    dv = 24\n",
    "    dout = 32\n",
    "    nv = 8\n",
    "\n",
    "    inp = Input(shape=(28, 28, 1), batch_size=10000)\n",
    "    patches = ExtractPatchesLayer()(inp)\n",
    "    x = tf.keras.layers.Dense(d_model)(patches)\n",
    "    x = tf.keras.layers.RNN(SpikingReLU(d_model), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "    x = PositionalEncodingLayer()(x)\n",
    "    \n",
    "    \n",
    "    # Attention Module\n",
    "    v2 = tf.keras.layers.Dense(nv*nv)(x)\n",
    "    v2 = tf.keras.layers.RNN(SpikingReLU(nv*nv), return_sequences=True, return_state=False, stateful=True)(v2)\n",
    "    q2 = tf.keras.layers.Dense(nv*nv)(x)\n",
    "    q2 = tf.keras.layers.RNN(SpikingReLU(nv*nv), return_sequences=True, return_state=False, stateful=True)(q2)\n",
    "    k2 = tf.keras.layers.Dense(nv*nv)(x)\n",
    "    k2 = tf.keras.layers.RNN(SpikingReLU(nv*nv), return_sequences=True, return_state=False, stateful=True)(k2)\n",
    "    \n",
    "#     v2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "#     q2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "#     k2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "\n",
    "    v = tf.keras.layers.Reshape([l, nv, nv])(v2)\n",
    "    q = tf.keras.layers.Reshape([l, nv, nv])(q2)\n",
    "    k = tf.keras.layers.Reshape([l, nv, nv])(k2)\n",
    "\n",
    "    # =============== Scaled dot-product attention =================\n",
    "    # QK^T\n",
    "    att = MatMulLayerTranspose()([q, k])\n",
    "    # softmax(QK^T)\n",
    "    # Exchanged: Softmax = RNN(Accumulate) + Softmax (Added Reshape layers around RNN layer)\n",
    "    att= tf.keras.layers.Reshape([l, nv*nv])(att)\n",
    "    att = tf.keras.layers.RNN(Accumulate(64), return_sequences=True, return_state=False, stateful=True)(att)\n",
    "    att= tf.keras.layers.Reshape([l, nv, nv])(att)\n",
    "    att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "    # softmax(QK^T)*V\n",
    "    out = MatMulLayer()([att, v])\n",
    "\n",
    "    out = tf.keras.layers.Reshape([l, d_model, 1])(out)\n",
    "    x = tf.keras.layers.Reshape([l, d_model, 1])(x)\n",
    "\n",
    "    # Concat Layer\n",
    "    add = tf.keras.layers.Add()([out, x])\n",
    "    out = tf.keras.layers.Flatten()(add)\n",
    "    out = tf.keras.layers.Dense(dout)(out)\n",
    "    out = tf.expand_dims(out, axis=1)\n",
    "    out = tf.keras.layers.RNN(SpikingReLU(dout), return_sequences=True, return_state=False, stateful=True)(out)\n",
    "    out = tf.keras.layers.Dense(num_classes)(out)\n",
    "    # Exchanged: Softmax = RNN(Accumulate) + Softmax\n",
    "    out = tf.keras.layers.RNN(Accumulate(num_classes), return_sequences=True, return_state=False, stateful=True)(out)\n",
    "    out = tf.keras.layers.Softmax()(out)\n",
    "    out = tf.squeeze(out, axis=1)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.set_weights(weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_weights(model, x_test, percentile=99.9):\n",
    "    x_test = x_test[::25]\n",
    "#     x_test = tf.squeeze(x_test, axis=1)\n",
    "    max_activation = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ReLU):\n",
    "            activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "            if np.percentile(activation, percentile) > max_activation:\n",
    "                max_activation = np.percentile(activation, percentile)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            if layer.activation.__name__ == 'relu':\n",
    "                activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "                if np.percentile(activation, percentile) > max_activation:\n",
    "                    max_activation = np.percentile(activation, percentile)\n",
    "\n",
    "    weights = model.get_weights()     \n",
    "    if max_activation == 0:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNo normalization\\n\" + \"-\"*32)\n",
    "    else:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNormalizing by\", max_activation, \"\\n\" + \"-\"*32)\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] /= (max_activation)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations_layer(layer_in, layer_out, x, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        batch_size = 10\n",
    "\n",
    "    if len(x) % batch_size != 0:\n",
    "        x = x[: -(len(x) % batch_size)]\n",
    "\n",
    "    return Model(layer_in, layer_out).predict(x, batch_size)\n",
    "\n",
    "def weight_conversion_robust_and_data_based(weights, bias, model, data, normalization_method='robust', ppercentile=0.99):\n",
    "\n",
    "    if normalization_method == 'data':\n",
    "        ppercentile = 1.0\n",
    "\n",
    "    # Get weights from trained network\n",
    "    converted_weights = weights\n",
    "    converted_bias = bias\n",
    "    \n",
    "    # use training set to find max_act for each neuron\n",
    "            \n",
    "    activations = []\n",
    "    for l in range(0, len(converted_weights)):\n",
    "        activation = get_activations_layer(model.input, model.layers[l].output, data)\n",
    "        activation_per_neuron = [np.max(activation[:, i]) for i in range(activation.shape[1])]\n",
    "        activations.append(activation_per_neuron)\n",
    "        \n",
    "    previous_factor = 1\n",
    "    for l in range(len(converted_weights)):\n",
    "        # get the p-percentile of the activation\n",
    "        pos_inputs = activations[l]\n",
    "        pos_inputs.sort()\n",
    "        max_act = pos_inputs[int(ppercentile * (len(pos_inputs) - 1))]\n",
    "        # get the maximum weight in the layer\n",
    "        max_wt = tf.math.reduce_max(converted_weights[l])\n",
    "        if converted_bias is not None and converted_bias[l] is not None:\n",
    "            max_bias = tf.math.reduce_max(converted_bias[l])\n",
    "            max_wt = tf.math.maximum(max_wt, max_bias)\n",
    "        scale_factor = tf.math.maximum(max_wt, max_act)\n",
    "\n",
    "        applied_factor = scale_factor / previous_factor\n",
    "        # rescale weights\n",
    "        converted_weights[l] = converted_weights[l] / applied_factor\n",
    "\n",
    "        # rescale bias\n",
    "        if converted_bias is not None and converted_bias[l] is not None:\n",
    "            converted_bias[l] = converted_bias[l] / scale_factor\n",
    "        previous_factor = scale_factor\n",
    "        print(f\"Scale factor for this layer is {previous_factor}\")\n",
    "\n",
    "    return converted_weights, converted_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-179-be43693543a5>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  weights_ = np.array([model_weights[0], model_weights[1]])\n",
      "<ipython-input-179-be43693543a5>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  bias = np.array([model_weights[1], model_weights[3]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale factor for this layer is 1.0\n",
      "Scale factor for this layer is 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 64])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = get_normalized_weights(model, x_train, percentile=50)\n",
    "# weights = model.get_weights()\n",
    "model_weights = model.get_weights()\n",
    "weights_ = np.array([model_weights[0], model_weights[1]])\n",
    "bias = np.array([model_weights[1], model_weights[3]])\n",
    "weights, bias = weight_conversion_robust_and_data_based(weights_, bias, model, x_test)\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "# x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "# x_test = np.expand_dims(x_test, axis=1)\n",
    "#x_rnn = np.tile(x_train, (1, 1, 1))\n",
    "#y_rnn = y_train  # np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "# _, testacc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "# snn = converted_model(weights)\n",
    "# evaluate_conversion(snn, model, x_test, y_test, testacc, timesteps=50)\n",
    "weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = tf.expand_dims(x_train, axis)\n",
    "x_test = tf.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    "    RNN\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class SpikingMultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class SpikingTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = SpikingMultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim),\n",
    "                RNN(SpikingReLU(mlp_dim), return_sequences=True, return_state=False, stateful=True),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_1), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.4.1 and trying to load a custom op (custom_ops/activations/_activation_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.2.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.2.0 and strictly below 2.3.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/options.py:47: RuntimeWarning: Traceback (most recent call last):\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 56, in gelu\n",
      "    return _gelu_custom_op(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 71, in _gelu_custom_op\n",
      "    return _activation_so.ops.addons_gelu(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py\", line 64, in ops\n",
      "    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 57, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/custom_ops/activations/_activation_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\n",
      "\n",
      "\n",
      "The gelu C++/CUDA custom op could not be loaded.\n",
      "For this reason, Addons will fallback to an implementation written\n",
      "in Python with public TensorFlow ops. There worst you might experience with\n",
      "this is a moderate slowdown on GPU. There can be multiple\n",
      "reason for this loading error, one of them may be an ABI incompatibility between\n",
      "the TensorFlow installed on your system and the TensorFlow used to compile\n",
      "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
      "shared object file was displayed above.\n",
      "\n",
      "If you want this warning to disappear, either make sure the TensorFlow installed\n",
      "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
      "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
      "by changing the TF_ADDONS_PY_OPS flag\n",
      "either with the environment variable:\n",
      "```bash\n",
      "TF_ADDONS_PY_OPS=1 python my_script.py\n",
      "```\n",
      "or in your code, after your imports:\n",
      "```python\n",
      "import tensorflow_addons as tfa\n",
      "import ...\n",
      "import ...\n",
      "\n",
      "tfa.options.TF_ADDONS_PY_OPS = True\n",
      "```\n",
      "\n",
      "  warnings.warn(warning_msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 21s 17ms/step - loss: 0.9392 - accuracy: 0.6778 - val_loss: 0.2894 - val_accuracy: 0.9085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5afdd38e50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "dropout = 0.1\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "def extract_patches(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches\n",
    "\n",
    "inp = tf.keras.layers.Input(shape=(input_shape))\n",
    "x = Rescaling(1.0 / 255)(inp)\n",
    "\n",
    "# =============== VISION PART =====================\n",
    "# patching, positional embedding and class embedding\n",
    "patches = extract_patches(x)\n",
    "x = Dense(d_model)(patches)\n",
    "\n",
    "pos_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, num_patches + 1, d_model)), \n",
    "                      name=\"pos_emb\", validate_shape=(1, num_patches + 1, d_model), trainable=True)\n",
    "class_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, 1, d_model)), name=\"class_emb\", \n",
    "                        validate_shape=(1, 1, d_model), trainable=True)\n",
    "\n",
    "class_emb = tf.broadcast_to(class_emb, [batch_size, 1, d_model])\n",
    "\n",
    "x = tf.concat([class_emb, x], axis=1)\n",
    "x = x + pos_emb\n",
    "\n",
    "# Transformer Blocks\n",
    "x = TransformerBlock(d_model, num_heads, mlp_dim, dropout)(x)\n",
    "\n",
    "# ================= MLP HEAD ===================\n",
    "x = Dense(mlp_dim, activation=tf.nn.relu)(x[:, 0])\n",
    "x = Dense(num_classes)(x)\n",
    "\n",
    "# ================ Model compilation and training ==================\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "dropout = 0.1\n",
    "\n",
    "\n",
    "def convert(model, weights, x_test, y_test):\n",
    "    print(\"Converted model:\\n\" + \"-\"*32)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.InputLayer):\n",
    "            print(\"Input Layer\")\n",
    "            inputs = tf.keras.Input(shape=(1, model.layers[0].input_shape[0][1]), batch_size=y_test.shape[0])\n",
    "            x = inputs        \n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            x = tf.keras.layers.Dense(layer.output_shape[1])(x)\n",
    "            # x = tf.keras.layers.RNN(DenseRNN(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            if layer.activation.__name__ == 'linear':\n",
    "                print(\"Dense Layer w/o activation\")\n",
    "                pass\n",
    "            elif layer.activation.__name__ == 'relu':\n",
    "                print(\"Dense Layer with SpikingReLU\")\n",
    "                x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'sigmoid':\n",
    "                print(\"Dense Layer with SpikingSigmoid\")\n",
    "                x = tf.keras.layers.RNN(SpikingSigmoid(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            elif layer.activation.__name__ == 'tanh':\n",
    "                print(\"Dense Layer with SpikingTanh\")\n",
    "                x = tf.keras.layers.RNN(SpikingTanh(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            else:\n",
    "                print('[Info] Activation type', layer.activation.__name__, 'not implemented')\n",
    "        elif isinstance(layer, tf.keras.layers.ReLU):\n",
    "            print(\"SpikingReLU Layer\")\n",
    "            x = tf.keras.layers.RNN(SpikingReLU(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "        elif isinstance(layer, tf.keras.layers.Softmax):\n",
    "            print(\"Accumulate + Softmax Layer\")\n",
    "            print(layer.output_shape[1])\n",
    "            x = tf.keras.layers.RNN(Accumulate(layer.output_shape[1]), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "            x = tf.keras.layers.Softmax()(x)\n",
    "        elif isinstance(layer, TransformerBlock):\n",
    "            x  = SpikingTransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "        else:\n",
    "            print(\"[Info] Layer type \", layer, \"not implemented, so we use it's keras version\")\n",
    "            x = layer(x)\n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "\n",
    "    spiking.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],)\n",
    "\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [50,1,64] vs. shape[1] = [60000,49,64] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-fad6126523a0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mweights\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_normalized_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m85\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m##################################################\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Preprocessing for RNN\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mx_train\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand_dims\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# (60000, 784) -> (60000, 1, 784)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-3-4b8b1471280f>\u001B[0m in \u001B[0;36mget_normalized_weights\u001B[0;34m(model, x_test, percentile)\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'relu'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m                 \u001B[0mactivation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpercentile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mmax_activation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m                     \u001B[0mmax_activation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpercentile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mactivation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpercentile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[0;32m-> 1012\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1013\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1014\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    422\u001B[0m         \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mtensors\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mthere\u001B[0m \u001B[0mare\u001B[0m \u001B[0mmore\u001B[0m \u001B[0mthan\u001B[0m \u001B[0mone\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    423\u001B[0m     \"\"\"\n\u001B[0;32m--> 424\u001B[0;31m     return self._run_internal_graph(\n\u001B[0m\u001B[1;32m    425\u001B[0m         inputs, training=training, mask=mask)\n\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001B[0m in \u001B[0;36m_run_internal_graph\u001B[0;34m(self, inputs, training, mask)\u001B[0m\n\u001B[1;32m    558\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    559\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_arguments\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 560\u001B[0;31m         \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnode\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    561\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    562\u001B[0m         \u001B[0;31m# Update tensor_dict.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1010\u001B[0m         with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1011\u001B[0m             self._compute_dtype_object):\n\u001B[0;32m-> 1012\u001B[0;31m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1013\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1014\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001B[0m in \u001B[0;36m_call_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1325\u001B[0m     \u001B[0;31m# Decorate the function to produce this layer's call method\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1327\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1328\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_call_wrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001B[0m in \u001B[0;36m_call_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1357\u001B[0m       \u001B[0;31m# multiple ops w/ the same name when the layer is reused)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1358\u001B[0m       \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'name'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1359\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1360\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcreated_variables\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtape\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwatched_variables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1361\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 201\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    202\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    203\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mconcat\u001B[0;34m(values, axis, name)\u001B[0m\n\u001B[1;32m   1675\u001B[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001B[1;32m   1676\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0midentity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1677\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcat_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1678\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1679\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001B[0m in \u001B[0;36mconcat_v2\u001B[0;34m(values, axis, name)\u001B[0m\n\u001B[1;32m   1191\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1192\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1193\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1194\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1195\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6860\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6861\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6862\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6863\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6864\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [50,1,64] vs. shape[1] = [60000,49,64] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "weights = get_normalized_weights(model, x_train, percentile=85)\n",
    "\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "#x_rnn = np.tile(x_train, (1, 1, 1))\n",
    "#y_rnn = y_train  # np.tile(x_test, (1, timesteps, 1))\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "snn = convert(ann, weights, x_test, y_test)\n",
    "evaluate_conversion(snn, ann, x_test, y_test, testacc, timesteps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}