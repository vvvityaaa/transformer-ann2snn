{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from spiking_models import DenseRNN, SpikingReLU, SpikingSigmoid, SpikingTanh, Accumulate\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, Model\n",
    "from operations_layers import SqueezeLayer, ExpandLayer, MatMulLayer, MatMulLayerTranspose, TransposeLayer, \\\n",
    "    ExtractPatchesLayer, PositionalEncodingLayer, Tokpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_weights(model, x_test, percentile=100):\n",
    "    x_test = x_test[::10]\n",
    "    max_activation = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ReLU):\n",
    "            activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "            if np.percentile(activation, percentile) > max_activation:\n",
    "                max_activation = np.percentile(activation, percentile)\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            if layer.activation.__name__ == 'relu':\n",
    "                activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "                if np.percentile(activation, percentile) > max_activation:\n",
    "                    max_activation = np.percentile(activation, percentile)\n",
    "\n",
    "    weights = model.get_weights()     \n",
    "    if max_activation == 0:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNo normalization\\n\" + \"-\"*32)\n",
    "    else:\n",
    "        print(\"\\n\" + \"-\"*32 + \"\\nNormalizing by\", max_activation, \"\\n\" + \"-\"*32)\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] /= (max_activation)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def evaluate_conversion(converted_model, original_model, x_test, y_test, testacc, timesteps=50):\n",
    "    for i in range(1, timesteps+1):\n",
    "        _, acc = converted_model.evaluate(x_test, y_test, batch_size=y_test.shape[0], verbose=0)\n",
    "        print(\n",
    "            \"Timesteps\", str(i) + \"/\" + str(timesteps) + \" -\",\n",
    "            \"acc spiking (orig): %.2f%% (%.2f%%)\" % (acc*100, testacc*100),\n",
    "            \"- conv loss: %+.2f%%\" % ((-(1 - acc/testacc)*100)))\n",
    "        \n",
    "def evaluate_conversion_and_save_data(converted_model, original_model, x_test, y_test, testacc, timesteps=50):\n",
    "    accuracy_per_t = []\n",
    "    for i in range(0, timesteps):\n",
    "        _, acc = converted_model.evaluate(x_test, y_test, batch_size=y_test.shape[0], verbose=0)\n",
    "        accuracy_per_t.append(acc)\n",
    "        print(\n",
    "            \"Timesteps\", str(i) + \"/\" + str(timesteps) + \" -\",\n",
    "            \"acc spiking (orig): %.2f%% (%.2f%%)\" % (acc*100, testacc*100),\n",
    "            \"- conv loss: %+.2f%%\" % ((-(1 - acc/testacc)*100)))\n",
    "    return accuracy_per_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_weight_normalization(model, x_test, ppercentile=1):\n",
    "    prev_factor = 1\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.ReLU) or (isinstance(layer, tf.keras.layers.Dense) and\n",
    "                                                       layer.activation.__name__ == 'relu'):\n",
    "\n",
    "            activation = tf.keras.Model(inputs=model.inputs, outputs=layer.output)(x_test).numpy()\n",
    "            activation = tf.math.reduce_max(activation, axis=0)\n",
    "            activation = tf.sort(activation)\n",
    "            max_act = activation[int(ppercentile * (len(activation) - 1))]\n",
    "\n",
    "            weights, bias = layer.get_weights()\n",
    "            max_wt = max(0, tf.math.reduce_max(weights))\n",
    "            max_bias = tf.math.reduce_max(bias)\n",
    "\n",
    "            max_wt_bias = max(max_bias, max_wt)\n",
    "\n",
    "            scale_factor = max(max_act, max_wt_bias)\n",
    "            applied_factor = scale_factor / prev_factor\n",
    "\n",
    "            weights = weights / applied_factor\n",
    "            bias = bias / scale_factor\n",
    "\n",
    "            prev_factor = scale_factor\n",
    "            layer.set_weights([weights, bias])\n",
    "            print(f\"Scale factor for layer {layer}\")\n",
    "            print(f\"{applied_factor}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs = 2\n",
    "act='relu'\n",
    "\n",
    "def create_ann_with_embedding():\n",
    "    dv = 25\n",
    "    nv = -1\n",
    "    vocab_size = 20000  # Only consider the top 20k words\n",
    "    maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "    embed_dim = 32  # Embedding size for each token\n",
    "    num_classes = 2\n",
    "    l = 50\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(maxlen,))\n",
    "#     x = Tokposangles()(inputs)\n",
    "#     x = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=32)(inputs)\n",
    "    x = Tokpos(maxlen, vocab_size, embed_dim)(inputs)\n",
    "    \n",
    "    # -------------- TRANSFORMER BLOCK -----------------\n",
    "    v2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    q2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    k2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "\n",
    "    v = tf.keras.layers.Reshape([embed_dim, nv, dv])(v2)\n",
    "    q = tf.keras.layers.Reshape([embed_dim, nv, dv])(q2)\n",
    "    k = tf.keras.layers.Reshape([embed_dim, nv, dv])(k2)\n",
    "\n",
    "    # softmax(q*k^T/sqrt(dv))\n",
    "    att = MatMulLayerTranspose()([q, k])\n",
    "    # att = ScaleLayer()([att, np.sqrt(dv)])\n",
    "    # TODO: observer if axis=-1 is not necessary\n",
    "    att = tf.keras.layers.Softmax()(att)\n",
    "    # softmax(q*k^T/sqrt(dv))*v\n",
    "    out = MatMulLayer()([att, v])\n",
    "\n",
    "    out = tf.keras.layers.Reshape([embed_dim, maxlen, 1])(out)\n",
    "    x = tf.keras.layers.Reshape([embed_dim, maxlen, 1])(x)\n",
    "    add = tf.keras.layers.Add()([out, x])\n",
    "    # add = tf.add(out, x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(add)\n",
    "    x = tf.keras.layers.Dense(embed_dim, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "#     x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#     x = tf.keras.layers.AveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(l, activation=\"relu\")(x)\n",
    "    # --------------------------------------------------\n",
    "    outputs = tf.keras.layers.Dense(num_classes)(x)\n",
    "    outputs = tf.keras.layers.Softmax()(outputs)\n",
    "    ann = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    ann.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    \n",
    "#     ann.compile(\n",
    "#         optimizer=tf.keras.optimizers.RMSprop(),\n",
    "#         loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "#         metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "    ann.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=(x_test, y_test),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs)\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tailored(weights, y_test):\n",
    "    dv = 25\n",
    "    nv = -1\n",
    "    vocab_size = 20000  # Only consider the top 20k words\n",
    "    maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "    embed_dim = 32  # Embedding size for each token\n",
    "    num_classes = 2\n",
    "    l = 50\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(1, maxlen,), batch_size=y_test.shape[0])\n",
    "    x = Tokpos(maxlen, vocab_size, embed_dim)(inputs)\n",
    "    \n",
    "    # -------------- TRANSFORMER BLOCK -----------------\n",
    "\n",
    "    v2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    q2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    k2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "\n",
    "    v = tf.keras.layers.Reshape([embed_dim, nv, dv])(v2)\n",
    "    q = tf.keras.layers.Reshape([embed_dim, nv, dv])(q2)\n",
    "    k = tf.keras.layers.Reshape([embed_dim, nv, dv])(k2)\n",
    "\n",
    "    # softmax(q*k^T/sqrt(dv))\n",
    "    att = MatMulLayerTranspose()([q, k])\n",
    "    # att = ScaleLayer()([att, np.sqrt(dv)])\n",
    "    # TODO: observer if axis=-1 is not necessary\n",
    "#     att = tf.keras.layers.Reshape([1, embed_dim*nv*dv])(att)\n",
    "#     print(att.shape)\n",
    "#     att = tf.keras.layers.RNN(Accumulate(embed_dim*dv), return_sequences=True, return_state=False, stateful=True)(att)\n",
    "#     att = tf.keras.layers.Reshape([embed_dim, nv, dv])(att)\n",
    "    att = tf.keras.layers.Softmax()(att)\n",
    "    \n",
    "    # softmax(q*k^T/sqrt(dv))*v\n",
    "    out = MatMulLayer()([att, v])\n",
    "\n",
    "    out = tf.keras.layers.Reshape([embed_dim, maxlen, 1])(out)\n",
    "    x = tf.keras.layers.Reshape([embed_dim, maxlen, 1])(x)\n",
    "    add = tf.keras.layers.Add()([out, x])\n",
    "    # add = tf.add(out, x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(add)\n",
    "    x = ExpandLayer()(x)\n",
    "    x = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    x = tf.keras.layers.RNN(SpikingReLU(embed_dim), return_sequences=True, return_state=False, \n",
    "                            stateful=True)(x)\n",
    "    x = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "    x = tf.keras.layers.Dense(l)(x)\n",
    "    x = tf.keras.layers.RNN(SpikingReLU(l), return_sequences=True, return_state=False, \n",
    "                            stateful=True)(x)\n",
    "    # --------------------------------------------------\n",
    "    x = tf.keras.layers.Dense(num_classes)(x)\n",
    "    x = tf.keras.layers.RNN(Accumulate(num_classes), return_sequences=True, return_state=False, stateful=True)(x)\n",
    "    x = tf.keras.layers.Softmax()(x)\n",
    "    x = SqueezeLayer()(x)\n",
    "    \n",
    "    spiking = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    \n",
    "    print(\"-\"*32 + \"\\n\")\n",
    "    spiking.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"])\n",
    "    print(spiking.summary())\n",
    "    spiking.set_weights(weights)\n",
    "    return spiking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n",
      "Epoch 1/2\n",
      "391/391 [==============================] - 7s 16ms/step - loss: 0.6313 - accuracy: 0.5751 - val_loss: 0.2955 - val_accuracy: 0.8742\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.2071 - accuracy: 0.9187 - val_loss: 0.3097 - val_accuracy: 0.8742\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tokpos_28 (Tokpos)              (None, 200, 32)      646400      input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_197 (Dense)               (None, 200, 32)      1056        tokpos_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_198 (Dense)               (None, 200, 32)      1056        tokpos_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_141 (Reshape)           (None, 32, 8, 25)    0           dense_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_142 (Reshape)           (None, 32, 8, 25)    0           dense_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose_28 (Mat (None, 32, 8, 8)     0           reshape_141[0][0]                \n",
      "                                                                 reshape_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_196 (Dense)               (None, 200, 32)      1056        tokpos_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_56 (Softmax)            (None, 32, 8, 8)     0           mat_mul_layer_transpose_28[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_140 (Reshape)           (None, 32, 8, 25)    0           dense_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_28 (MatMulLayer)  (None, 32, 8, 25)    0           softmax_56[0][0]                 \n",
      "                                                                 reshape_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_143 (Reshape)           (None, 32, 200, 1)   0           mat_mul_layer_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_144 (Reshape)           (None, 32, 200, 1)   0           tokpos_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 200, 1)   0           reshape_143[0][0]                \n",
      "                                                                 reshape_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 6400)         0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_199 (Dense)               (None, 32)           204832      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 32)           1056        dense_199[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, 50)           1650        dense_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, 2)            102         dense_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_57 (Softmax)            (None, 2)            0           dense_202[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 857,208\n",
      "Trainable params: 857,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Scale factor for layer <tensorflow.python.keras.layers.core.Dense object at 0x7f51834f6970>\n",
      "9.09416389465332\n",
      "Scale factor for layer <tensorflow.python.keras.layers.core.Dense object at 0x7f5147941160>\n",
      "0.06649134308099747\n",
      "--------------------------------\n",
      "\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(25000, 1, 200)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tokpos_29 (Tokpos)              (25000, 1, 200, 32)  646400      input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_204 (Dense)               (25000, 1, 200, 32)  1056        tokpos_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_205 (Dense)               (25000, 1, 200, 32)  1056        tokpos_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_146 (Reshape)           (25000, 32, 8, 25)   0           dense_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_147 (Reshape)           (25000, 32, 8, 25)   0           dense_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose_29 (Mat (25000, 32, 8, 8)    0           reshape_146[0][0]                \n",
      "                                                                 reshape_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (25000, 1, 200, 32)  1056        tokpos_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_58 (Softmax)            (25000, 32, 8, 8)    0           mat_mul_layer_transpose_29[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_145 (Reshape)           (25000, 32, 8, 25)   0           dense_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_29 (MatMulLayer)  (25000, 32, 8, 25)   0           softmax_58[0][0]                 \n",
      "                                                                 reshape_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_148 (Reshape)           (25000, 32, 200, 1)  0           mat_mul_layer_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_149 (Reshape)           (25000, 32, 200, 1)  0           tokpos_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (25000, 32, 200, 1)  0           reshape_148[0][0]                \n",
      "                                                                 reshape_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (25000, 6400)        0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "expand_layer_14 (ExpandLayer)   (25000, 1, 6400)     0           flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_206 (Dense)               (25000, 1, 32)       204832      expand_layer_14[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_42 (RNN)                    (25000, 1, 32)       0           dense_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_207 (Dense)               (25000, 1, 32)       1056        rnn_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_208 (Dense)               (25000, 1, 50)       1650        dense_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_43 (RNN)                    (25000, 1, 50)       0           dense_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_209 (Dense)               (25000, 1, 2)        102         rnn_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "rnn_44 (RNN)                    (25000, 1, 2)        0           dense_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_59 (Softmax)            (25000, 1, 2)        0           rnn_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_layer_14 (SqueezeLayer) (25000, 2)           0           softmax_59[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 857,208\n",
      "Trainable params: 857,208\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Start evaluation\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_test), \"Validation sequences\")\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)\n",
    "# x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "# x_test = np.expand_dims(x_test, axis=1)\n",
    "\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "# Analog model\n",
    "ann = create_ann_with_embedding()\n",
    "print(ann.summary())\n",
    "\n",
    "_, testacc = ann.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
    "# weights = ann.get_weights()\n",
    "# weights = get_normalized_weights(ann, x_train, percentile=99)\n",
    "model_normalized = robust_weight_normalization(ann, x_train, 0.99)\n",
    "weights = model_normalized.get_weights()\n",
    "\n",
    "##################################################\n",
    "# Preprocessing for RNN \n",
    "x_train = np.expand_dims(x_train, axis=1)  # (60000, 784) -> (60000, 1, 784)\n",
    "x_test = np.expand_dims(x_test, axis=1)\n",
    "\n",
    "##################################################\n",
    "# Conversion to spiking model\n",
    "# snn = convert(ann, weights, x_test, y_test)\n",
    "snn = convert_tailored(weights, y_test)\n",
    "print(\"Start evaluation\")\n",
    "# evaluate_conversion(snn, ann, x_test, y_test, testacc, timesteps=50)\n",
    "timesteps = 50\n",
    "accuracy = evaluate_conversion_and_save_data(snn, ann, x_test, y_test, testacc, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'simulation time-steps')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(range(1, timesteps + 1), accuracy)\n",
    "ax.plot(range(1, timesteps + 1), [testacc for i in range(1, timesteps + 1)], color=\"orange\")\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('simulation time-steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
