{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    # TODO: moved init arguments to constants embed_dim and num_heads\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        #if embed_dim % num_heads != 0:\n",
    "        #    raise ValueError(\n",
    "        #        f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "        #    )\n",
    "        self.projection_dim = self.embed_dim // self.num_heads\n",
    "        self.query_dense = Dense(self.embed_dim)\n",
    "        self.key_dense = Dense(self.embed_dim)\n",
    "        self.value_dense = Dense(self.embed_dim)\n",
    "        self.combine_heads = Dense(self.embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'projection_dim': self.projection_dim,\n",
    "            'query_dense': self.query_dense,\n",
    "            'key_dense': self.key_dense,\n",
    "            'value_dense': self.value_dense,\n",
    "            'combine_heads': self.combine_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "logdir = \"logs\"\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_layers = 4\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "channels = 1\n",
    "dropout = 0.1\n",
    "num_classes = 10\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "patch_dim = channels * patch_size ** 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "# x_train = x_train / 255\n",
    "# x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = tf.expand_dims(x_train, axis)\n",
    "x_test = tf.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "def extract_patches(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    \n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.__operators__.add_16), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'pos_emb:0' shape=(1, 50, 64) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.4.1 and trying to load a custom op (custom_ops/activations/_activation_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.2.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.2.0 and strictly below 2.3.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/options.py:47: RuntimeWarning: Traceback (most recent call last):\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 56, in gelu\n",
      "    return _gelu_custom_op(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/activations/gelu.py\", line 71, in _gelu_custom_op\n",
      "    return _activation_so.ops.addons_gelu(x, approximate)\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py\", line 64, in ops\n",
      "    self._ops = tf.load_op_library(get_path_to_datafile(self.relative_path))\n",
      "  File \"/home/viktor/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py\", line 57, in load_op_library\n",
      "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /home/viktor/.local/lib/python3.8/site-packages/tensorflow_addons/custom_ops/activations/_activation_ops.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\n",
      "\n",
      "\n",
      "The gelu C++/CUDA custom op could not be loaded.\n",
      "For this reason, Addons will fallback to an implementation written\n",
      "in Python with public TensorFlow ops. There worst you might experience with\n",
      "this is a moderate slowdown on GPU. There can be multiple\n",
      "reason for this loading error, one of them may be an ABI incompatibility between\n",
      "the TensorFlow installed on your system and the TensorFlow used to compile\n",
      "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
      "shared object file was displayed above.\n",
      "\n",
      "If you want this warning to disappear, either make sure the TensorFlow installed\n",
      "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
      "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
      "by changing the TF_ADDONS_PY_OPS flag\n",
      "either with the environment variable:\n",
      "```bash\n",
      "TF_ADDONS_PY_OPS=1 python my_script.py\n",
      "```\n",
      "or in your code, after your imports:\n",
      "```python\n",
      "import tensorflow_addons as tfa\n",
      "import ...\n",
      "import ...\n",
      "\n",
      "tfa.options.TF_ADDONS_PY_OPS = True\n",
      "```\n",
      "\n",
      "  warnings.warn(warning_msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 24s 6ms/step - loss: 0.8032 - accuracy: 0.7364 - val_loss: 0.3207 - val_accuracy: 0.8975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f27ff62df70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "inp = tf.keras.layers.Input(shape=(input_shape))\n",
    "x = Rescaling(1.0 / 255)(inp)\n",
    "\n",
    "# =============== VISION PART =====================\n",
    "# patching, positional embedding and class embedding\n",
    "patches = extract_patches(x)\n",
    "x = Dense(d_model)(patches)\n",
    "\n",
    "pos_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, num_patches + 1, d_model)), \n",
    "                      name=\"pos_emb\", validate_shape=(1, num_patches + 1, d_model), trainable=True)\n",
    "class_emb = tf.Variable(initial_value=tf.random.uniform(shape=(1, 1, d_model)), name=\"class_emb\", \n",
    "                        validate_shape=(1, 1, d_model), trainable=True)\n",
    "\n",
    "class_emb = tf.broadcast_to(class_emb, [batch_size, 1, d_model])\n",
    "\n",
    "x = tf.concat([class_emb, x], axis=1)\n",
    "x = x + pos_emb\n",
    "\n",
    "# Transformer Blocks\n",
    "x = TransformerBlock(d_model, num_heads, mlp_dim, dropout)(x)\n",
    "# 1 ============ ATTENTION BLOCK ===================\n",
    "# attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "# out1 = attn_output + x\n",
    "\n",
    "# # MLP module inside of attention block\n",
    "# mlp_dense = Dense(mlp_dim, activation=tf.nn.relu)(out1)\n",
    "# mlp_dense = Dense(d_model)(mlp_dense)\n",
    "\n",
    "# x = mlp_dense + out1\n",
    "\n",
    "# ================= MLP HEAD ===================\n",
    "x = Dense(mlp_dim, activation=tf.nn.relu)(x[:, 0])\n",
    "x = Dense(num_classes)(x)\n",
    "\n",
    "# ================ Model compilation and training ==================\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=x)\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 28, 28, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape (TFOpLambda) (4,)                 0           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.extract_patches (TFOpL (None, 7, 7, 16)     0           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici ()                   0           tf.compat.v1.shape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, None, 16)     0           tf.image.extract_patches[0][0]   \n",
      "                                                                 tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 64)     1088        tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, None, 64)     66368       dense[0][0]                      \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, None, 64)     0           multi_head_attention[0][0]       \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 128)    8320        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 64)     8256        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, None, 64)     0           dense_2[0][0]                    \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 64)           0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          8320        tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           1290        dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 93,642\n",
      "Trainable params: 93,642\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "keras.models.save_model(\n",
    "    model, \n",
    "    os.path.join(\"/home/viktor/PycharmProjects/guided_research/transformer-to-snn-conversion\", \n",
    "    \"mnist_transformer\" + '.h5')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\n",
    "    os.path.join(\"/home/viktor/PycharmProjects/guided_research/transformer-to-snn-conversion\", \n",
    "    \"mnist_transformer\" + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}