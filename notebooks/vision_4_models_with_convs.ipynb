{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout,  Conv2D, Input, Lambda, Flatten, TimeDistributed\n",
    "from tensorflow.keras.layers import Add, Reshape, MaxPooling2D, Concatenate, Embedding, RepeatVector, \\\n",
    "BatchNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Layer\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Default MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 175/1875 [=>............................] - ETA: 46s - loss: 1.9277 - accuracy: 0.2516"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-19dddaeae61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "inp = Input(shape = (28, 28, 1))\n",
    "x = Conv2D(32, (2,2), activation='relu', padding='same')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "c = Conv2D(64, (2,2), activation='relu')\n",
    "x = c(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "x = Conv2D(64*3, (2,2), activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Reshape([6*6,64*3])(x)\n",
    "\n",
    "\n",
    "att = MultiHeadAttention(num_heads=4, key_dim=64)\n",
    "x = att(x,x)\n",
    "\n",
    "# x = Reshape([6,6,32])(x)\n",
    "\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_32 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 28, 28, 32)   160         input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 13, 13, 64)   8256        max_pooling2d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 6, 6, 192)    49344       max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_49 (Reshape)            (None, 36, 192)      0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 36, 192)      197568      reshape_49[0][0]                 \n",
      "                                                                 reshape_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 6912)         0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 256)          1769728     flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 10)           2570        dense_126[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,027,626\n",
      "Trainable params: 2,027,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Multi head attention, defined in a functional way from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiHeadsAttModel(l=8*8, d=512, dv=64, dout=512, nv = 8 ):\n",
    "\n",
    "    v1 = tf.keras.layers.Input(shape = (l, d))\n",
    "    q1 = tf.keras.layers.Input(shape = (l, d))\n",
    "    k1 = tf.keras.layers.Input(shape = (l, d))\n",
    "\n",
    "    v2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(v1)\n",
    "    q2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(q1)\n",
    "    k2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(k1)\n",
    "\n",
    "    v = tf.keras.layers.Reshape([l, nv, dv])(v2)\n",
    "    q = tf.keras.layers.Reshape([l, nv, dv])(q2)\n",
    "    k = tf.keras.layers.Reshape([l, nv, dv])(k2)\n",
    "    \n",
    "    # CAN BE SIMULATED WITH tf experiment EinsumDense, but it has weights, which it learns\n",
    "    att = tf.einsum('baik,baij->bakj',q, k)/np.sqrt(dv)\n",
    "    #att = Lambda(lambda x: K.batch_dot(x[0],x[1] ,axes=[-1,-1]) / np.sqrt(dv),output_shape=(l, nv, nv))([q,k])# l, nv, nv\n",
    "    #att = tf.einsum('', q, k)\n",
    "    att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "#     att = Lambda(lambda x:  K.softmax(x) , output_shape=(l, nv, nv))(att)\n",
    "    out = tf.einsum('bajk,baik->baji',att, v)\n",
    "    #out = Lambda(lambda x: K.batch_dot(x[0], x[1],axes=[2,2]),  output_shape=(l, nv, dv))([att, v])\n",
    "    out = tf.keras.layers.Reshape([l, d])(out)\n",
    "    \n",
    "    out = tf.keras.layers.Add()([out, q1])\n",
    "\n",
    "    out = tf.keras.layers.Dense(dout, activation = \"relu\")(out)\n",
    "\n",
    "    return  Model(inputs=[q1,k1,v1], outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Modular ViT with Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.1878 - accuracy: 0.9393 - val_loss: 0.0631 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa3b3136c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fully Functional Modular version with matmul instead of einsums\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "inp = Input(shape = (28, 28, 1))\n",
    "x = Conv2D(32, (2,2), activation='relu', padding='same')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "c = Conv2D(64, (2,2), activation='relu')\n",
    "x = c(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "x = Conv2D(64*3, (2,2), activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Reshape([6*6,64*3])(x)\n",
    "\n",
    "# att = MultiHeadsAttModel(l=6*6, d=64*3 , dv=8*3, dout=32, nv = 8 )\n",
    "# x = att([x,x,x])\n",
    "l=6*6\n",
    "d=64*3\n",
    "dv=8*3\n",
    "dout=32\n",
    "nv = 8\n",
    "# v1 = tf.keras.layers.Input()(x)\n",
    "# q1 = tf.keras.layers.Input()(x)\n",
    "# k1 = tf.keras.layers.Input()(x)\n",
    "\n",
    "v2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(x)\n",
    "q2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(x)\n",
    "k2 = tf.keras.layers.Dense(dv*nv, activation = \"relu\")(x)\n",
    "\n",
    "v = tf.keras.layers.Reshape([l, nv, dv])(v2)\n",
    "q = tf.keras.layers.Reshape([l, nv, dv])(q2)\n",
    "k = tf.keras.layers.Reshape([l, nv, dv])(k2)\n",
    "\n",
    "att = tf.matmul(q, k, transpose_b=True)/np.sqrt(dv)\n",
    "# att = tf.einsum('baik,baij->bakj',q, k)/np.sqrt(dv)\n",
    "# print(att.shape)\n",
    "# print(q.shape)\n",
    "# print(k.shape)\n",
    "att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "# out = tf.einsum('bajk,baik->baji',att, v)\n",
    "out = tf.matmul(att, v)\n",
    "out = tf.keras.layers.Reshape([l, d])(out)\n",
    "\n",
    "out = tf.keras.layers.Add()([out, x])\n",
    "\n",
    "out = tf.keras.layers.Dense(dout, activation = \"relu\")(out)\n",
    "\n",
    "x = Reshape([6,6,32])(out)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional modular ViT compatible with snn_toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(images, patch_size, patch_dim):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    print(f\"Extract patches {batch_size}\")\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding=\"VALID\",\n",
    "    )\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ScaleLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        scale = inputs[1]\n",
    "        return inputs[0] / scale\n",
    "\n",
    "    \n",
    "class MatMulLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1])\n",
    "    \n",
    "\n",
    "class TransposeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TransposeLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    \n",
    "class SqueezeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SqueezeLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.squeeze(inputs, axis=1)\n",
    "\n",
    "class SliceLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SliceLayer, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs[:, 0]\n",
    "    \n",
    "class MatMulLayerTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MatMulLayerTranspose, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs[0], inputs[1], transpose_b=True)\n",
    "\n",
    "    \n",
    "class PositionalEncodingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PositionalEncodingLayer, self).__init__()\n",
    "        self.pos_emb = self.add_weight(\"pos_emb\", shape=(1, num_patches + 1, d_model))\n",
    "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        class_emb = tf.broadcast_to(self.class_emb, [batch_size, 1, d_model])\n",
    "        x = tf.concat([class_emb, inputs], axis=1)\n",
    "        return x + self.pos_emb\n",
    "\n",
    "    \n",
    "class ExtractPatchesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ExtractPatchesLayer, self).__init__()\n",
    "        self.patch_size = 4\n",
    "        self.patch_dim = 16\n",
    "        \n",
    "    def extract_patches(self, images, patch_size, patch_dim):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, patch_size, patch_size, 1],\n",
    "            strides=[1, patch_size, patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "        return patches\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.extract_patches(inputs, self.patch_size, self.patch_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(x):\n",
    "    # ================== Multi Head Self Attention ===============\n",
    "    v2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    q2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "    k2 = tf.keras.layers.Dense(embed_dim)(x)\n",
    "\n",
    "    v = tf.keras.layers.Reshape([l, num_heads, projection_dim])(v2)\n",
    "    v = TransposeLayer()(v)\n",
    "    q = tf.keras.layers.Reshape([l, num_heads, projection_dim])(q2)\n",
    "    q = TransposeLayer()(q)\n",
    "    k = tf.keras.layers.Reshape([l, num_heads, projection_dim])(k2)\n",
    "    k = TransposeLayer()(k)\n",
    "\n",
    "    # =============== Scaled dot-product attention =================\n",
    "    # QK^T\n",
    "    att = MatMulLayerTranspose()([q, k])\n",
    "    # softmax(QK^T)\n",
    "    att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "    # softmax(QK^T)*V\n",
    "    out = MatMulLayer()([att, v])\n",
    "\n",
    "    att = TransposeLayer()(out)\n",
    "    out = tf.keras.layers.Reshape([-1, l, embed_dim])(att)\n",
    "    out = tf.keras.layers.Dense(embed_dim)(out)\n",
    "    out = Dropout(dropout)(out)\n",
    "    # out = tf.keras.layers.Reshape([l, d_model, 1])(out)\n",
    "    x = tf.keras.layers.Reshape([-1, l, embed_dim])(x)\n",
    "    # ============== End of Multi Head Self Attention =============\n",
    "    # Concat Layer\n",
    "    add = tf.keras.layers.Add()([out, x])\n",
    "\n",
    "    out = tf.keras.layers.Dense(mlp_dim, activation=\"relu\")(add)\n",
    "    out = Dropout(dropout)(out)\n",
    "    out = tf.keras.layers.Dense(embed_dim)(out)\n",
    "    out = Dropout(dropout)(out)\n",
    "    out = tf.keras.layers.Add()([out, add])\n",
    "    # ================== End of Transformer =======================\n",
    "    return out    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 57s 58ms/step - loss: 1.2982 - accuracy: 0.5453 - val_loss: 0.1888 - val_accuracy: 0.9406\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 54s 57ms/step - loss: 0.2469 - accuracy: 0.9240 - val_loss: 0.1385 - val_accuracy: 0.9552\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 54s 58ms/step - loss: 0.1786 - accuracy: 0.9455 - val_loss: 0.1297 - val_accuracy: 0.9625\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.1392 - accuracy: 0.9578 - val_loss: 0.0953 - val_accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 56s 59ms/step - loss: 0.1284 - accuracy: 0.9615 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 54s 58ms/step - loss: 0.1124 - accuracy: 0.9663 - val_loss: 0.0886 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 57s 60ms/step - loss: 0.0979 - accuracy: 0.9702 - val_loss: 0.1063 - val_accuracy: 0.9691\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 57s 61ms/step - loss: 0.0948 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 56s 60ms/step - loss: 0.0828 - accuracy: 0.9740 - val_loss: 0.0663 - val_accuracy: 0.9782\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 54s 58ms/step - loss: 0.0816 - accuracy: 0.9746 - val_loss: 0.0797 - val_accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39abc86580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fully Functional Modular version with Multiply layers instead of einsums\n",
    "\"\"\"\n",
    "\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "channels = 1\n",
    "patch_dim = channels * patch_size ** 2\n",
    "batch_size = 64\n",
    "embed_dim = d_model = 64\n",
    "num_heads = 4\n",
    "projection_dim = embed_dim//num_heads\n",
    "mlp_dim = 128\n",
    "l = 50\n",
    "dropout = 0.1\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "dv = 24\n",
    "dout = 32\n",
    "nv = 8\n",
    "\n",
    "inp = Input(shape=(28, 28, 1))\n",
    "patches = ExtractPatchesLayer()(inp)\n",
    "x = tf.keras.layers.Dense(d_model)(patches)\n",
    "x = PositionalEncodingLayer()(x)\n",
    "\n",
    "out = x\n",
    "for i in range(4):\n",
    "    out = multi_head_attention(out)\n",
    "\n",
    "out = SqueezeLayer()(out)\n",
    "out = SliceLayer()(out)\n",
    "# out = tf.keras.layers.Flatten()(out)\n",
    "out = tf.keras.layers.Dense(embed_dim, activation='relu')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = tf.keras.layers.Dense(num_classes, activation='softmax')(out)\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "extract_patches_layer_1 (Extrac (None, None, 16)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 64)     1088        extract_patches_layer_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_layer_1 (Po (None, 50, 64)       3264        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50, 64)       4160        positional_encoding_layer_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 50, 64)       4160        positional_encoding_layer_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50, 4, 16)    0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 50, 4, 16)    0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_1 (TransposeLay (None, 4, 50, 16)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_2 (TransposeLay (None, 4, 50, 16)    0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50, 64)       4160        positional_encoding_layer_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose (MatMul (None, 4, 50, 50)    0           transpose_layer_1[0][0]          \n",
      "                                                                 transpose_layer_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 4, 16)    0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 4, 50, 50)    0           mat_mul_layer_transpose[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer (TransposeLayer (None, 4, 50, 16)    0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer (MatMulLayer)     (None, 4, 50, 16)    0           softmax[0][0]                    \n",
      "                                                                 transpose_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_3 (TransposeLay (None, 50, 4, 16)    0           mat_mul_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 50, 64)    0           transpose_layer_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 50, 64)    4160        reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 50, 64)    0           positional_encoding_layer_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 50, 64)    0           dense_5[0][0]                    \n",
      "                                                                 reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 50, 128)   8320        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 50, 64)    8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1, 50, 64)    0           dense_7[0][0]                    \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1, 50, 64)    4160        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 50, 64)    4160        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 50, 4, 16)    0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50, 4, 16)    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_5 (TransposeLay (None, 4, 50, 16)    0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_6 (TransposeLay (None, 4, 50, 16)    0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 50, 64)    4160        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose_1 (MatM (None, 4, 50, 50)    0           transpose_layer_5[0][0]          \n",
      "                                                                 transpose_layer_6[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 50, 4, 16)    0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, 4, 50, 50)    0           mat_mul_layer_transpose_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_4 (TransposeLay (None, 4, 50, 16)    0           reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_1 (MatMulLayer)   (None, 4, 50, 16)    0           softmax_1[0][0]                  \n",
      "                                                                 transpose_layer_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_7 (TransposeLay (None, 50, 4, 16)    0           mat_mul_layer_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 50, 64)    0           transpose_layer_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1, 50, 64)    4160        reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)             (None, 1, 50, 64)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 1, 50, 64)    0           dense_11[0][0]                   \n",
      "                                                                 reshape_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1, 50, 128)   8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1, 50, 64)    8256        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 50, 64)    0           dense_13[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1, 50, 64)    4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1, 50, 64)    4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)            (None, 50, 4, 16)    0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, 50, 4, 16)    0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_9 (TransposeLay (None, 4, 50, 16)    0           reshape_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_10 (TransposeLa (None, 4, 50, 16)    0           reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1, 50, 64)    4160        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose_2 (MatM (None, 4, 50, 50)    0           transpose_layer_9[0][0]          \n",
      "                                                                 transpose_layer_10[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)            (None, 50, 4, 16)    0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, 4, 50, 50)    0           mat_mul_layer_transpose_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_8 (TransposeLay (None, 4, 50, 16)    0           reshape_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_2 (MatMulLayer)   (None, 4, 50, 16)    0           softmax_2[0][0]                  \n",
      "                                                                 transpose_layer_8[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_11 (TransposeLa (None, 50, 4, 16)    0           mat_mul_layer_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 1, 50, 64)    0           transpose_layer_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1, 50, 64)    4160        reshape_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 50, 64)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 1, 50, 64)    0           dense_17[0][0]                   \n",
      "                                                                 reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1, 50, 128)   8320        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1, 50, 64)    8256        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1, 50, 64)    0           dense_19[0][0]                   \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1, 50, 64)    4160        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1, 50, 64)    4160        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 50, 4, 16)    0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 50, 4, 16)    0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_13 (TransposeLa (None, 4, 50, 16)    0           reshape_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_14 (TransposeLa (None, 4, 50, 16)    0           reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1, 50, 64)    4160        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose_3 (MatM (None, 4, 50, 50)    0           transpose_layer_13[0][0]         \n",
      "                                                                 transpose_layer_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 50, 4, 16)    0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "softmax_3 (Softmax)             (None, 4, 50, 50)    0           mat_mul_layer_transpose_3[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_12 (TransposeLa (None, 4, 50, 16)    0           reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_3 (MatMulLayer)   (None, 4, 50, 16)    0           softmax_3[0][0]                  \n",
      "                                                                 transpose_layer_12[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "transpose_layer_15 (TransposeLa (None, 50, 4, 16)    0           mat_mul_layer_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 50, 64)    0           transpose_layer_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1, 50, 64)    4160        reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_19 (Reshape)            (None, 1, 50, 64)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1, 50, 64)    0           dense_23[0][0]                   \n",
      "                                                                 reshape_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1, 50, 128)   8320        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 1, 50, 64)    8256        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1, 50, 64)    0           dense_25[0][0]                   \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_layer (SqueezeLayer)    (None, 50, 64)       0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "slice_layer (SliceLayer)        (None, 64)           0           squeeze_layer[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 64)           4160        slice_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 10)           650         dense_26[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 142,026\n",
      "Trainable params: 142,026\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original ViT / Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    LayerNormalization,\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        print(f\"Query shape - {query.shape}\")\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        print(f\"Query shape after separating heads - {query.shape}\")\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        # Dense Layer in the end\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(embed_dim),\n",
    "                Dropout(dropout),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inputs_norm = self.layernorm1(inputs)\n",
    "        attn_output = self.att(inputs_norm)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        out1_norm = self.layernorm2(out1)\n",
    "        mlp_output = self.mlp(out1_norm)\n",
    "        mlp_output = self.dropout2(mlp_output, training=training)\n",
    "        return mlp_output + out1\n",
    "\n",
    "\n",
    "class VisionTransformer(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size,\n",
    "        patch_size,\n",
    "        num_layers,\n",
    "        num_classes,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        mlp_dim,\n",
    "        channels=3,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.patch_dim = channels * patch_size ** 2\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "#         self.rescale = Rescaling(1.0 / 255)\n",
    "        self.pos_emb = self.add_weight(\n",
    "            \"pos_emb\", shape=(1, num_patches + 1, d_model)\n",
    "        )\n",
    "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "        self.patch_proj = Dense(d_model)\n",
    "        self.enc_layers = [\n",
    "            TransformerBlock(d_model, num_heads, mlp_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.mlp_head = tf.keras.Sequential(\n",
    "            [\n",
    "                LayerNormalization(epsilon=1e-6),\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dropout(dropout),\n",
    "                Dense(num_classes),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def extract_patches(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "#         print(f\"Batch size for extracting patches - {batch_size}\")\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\n",
    "        return patches\n",
    "    \n",
    "    def call(self, x, training):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        print(f\"Batch size - {batch_size.shape}\")\n",
    "#         x = self.rescale(x)\n",
    "        #  print(x.shape) # (None, 28, 28, 1)\n",
    "        patches = self.extract_patches(x)\n",
    "        # print(patches.shape) # (None, None, 16)\n",
    "        x = self.patch_proj(patches)\n",
    "        # print(x.shape) # (None, None, 64)\n",
    "        class_emb = tf.broadcast_to(\n",
    "            self.class_emb, [batch_size, 1, self.d_model]\n",
    "        )\n",
    "        # print(class_emb.shape) # (None, 1, 64)\n",
    "        # print(self.pos_emb.shape) # (1, 50, 64)\n",
    "        x = tf.concat([class_emb, x], axis=1)\n",
    "        # print(x.shape) # (None, None, 64)\n",
    "        x = x + self.pos_emb\n",
    "#         print(x.shape)\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training)\n",
    "        print(x.shape)\n",
    "        # First (class token) is used for classification\n",
    "        x = x[:, 0]\n",
    "        print(x.shape)\n",
    "        x = self.mlp_head(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "logdir = \"logs\"\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_layers = 4\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = tf.expand_dims(x_train, axis)\n",
    "x_test = tf.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size - ()\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "(None, 50, 64)\n",
      "(None, 64)\n",
      "(None, 10)\n",
      "Batch size - ()\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "Query shape - (None, 50, 64)\n",
      "Query shape after separating heads - (None, 4, None, 16)\n",
      "(None, 50, 64)\n",
      "(None, 64)\n",
      "(None, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d317b86e198d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# model.compile('adam', 'categorical_crossentropy', ['accuracy'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VisionTransformer(\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=10,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    channels=1,\n",
    ")\n",
    "\n",
    "# TODO: THIS THING IS VERY IMPORTANT\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Layer Multi Head Attention, defined in Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Strange behaviour, when commenting transpose permutations, accuracy increases\n",
    "\"\"\"\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, num_heads=8, **kwargs):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "           raise ValueError(\n",
    "               f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "           )\n",
    "        self.projection_dim = self.embed_dim // self.num_heads\n",
    "        self.query_dense = Dense(self.embed_dim)\n",
    "        self.key_dense = Dense(self.embed_dim)\n",
    "        self.value_dense = Dense(self.embed_dim)\n",
    "        self.combine_heads = Dense(self.embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "#         return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'projection_dim': self.projection_dim,\n",
    "            'query_dense': self.query_dense,\n",
    "            'key_dense': self.key_dense,\n",
    "            'value_dense': self.value_dense,\n",
    "            'combine_heads': self.combine_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "#         attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, num_heads=8, **kwargs):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "           raise ValueError(\n",
    "               f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "           )\n",
    "        self.projection_dim = self.embed_dim // self.num_heads\n",
    "        self.query_dense = Dense(self.embed_dim)\n",
    "        self.key_dense = Dense(self.embed_dim)\n",
    "        self.value_dense = Dense(self.embed_dim)\n",
    "        self.combine_heads = Dense(self.embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(\n",
    "            x, (batch_size, -1, self.num_heads, self.projection_dim)\n",
    "        )\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def get_config(self):\n",
    "\n",
    "        config = super().get_config().copy()num_classes = 10\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "channels = 1\n",
    "patch_dim = channels * patch_size ** 2\n",
    "batch_size = 64\n",
    "embed_dim = d_model = 64\n",
    "\n",
    "l = 50\n",
    "d = 192\n",
    "dv = 24\n",
    "dout = 32\n",
    "nv = 8\n",
    "\n",
    "inp = Input(shape=(28, 28, 1))\n",
    "patches = ExtractPatchesLayer()(inp)\n",
    "x = Dense(d_model)(patches)\n",
    "x = PositionalEncodingLayer()(x)\n",
    "\n",
    "# Attention Module\n",
    "v2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "q2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "k2 = tf.keras.layers.Dense(nv*nv, activation=\"relu\")(x)\n",
    "\n",
    "v = tf.keras.layers.Reshape([l, nv, nv])(v2)\n",
    "q = tf.keras.layers.Reshape([l, nv, nv])(q2)\n",
    "k = tf.keras.layers.Reshape([l, nv, nv])(k2)\n",
    "\n",
    "# =============== Scaled dot-product attention =================\n",
    "# QK^T\n",
    "att = MatMulLayerTranspose()([q, k])\n",
    "# softmax(QK^T)\n",
    "att = tf.keras.layers.Softmax(axis=-1)(att)\n",
    "# softmax(QK^T)*V\n",
    "out = MatMulLayer()([att, v])\n",
    "\n",
    "out = tf.keras.layers.Reshape([l, d_model, 1])(out)\n",
    "x = tf.keras.layers.Reshape([l, d_model, 1])(x)\n",
    "\n",
    "# Concat Layer\n",
    "add = tf.keras.layers.Add()([out, x])\n",
    "out = tf.keras.layers.Dense(32, activation=\"relu\")(add)\n",
    "\n",
    "out = tf.keras.layers.Flatten()(out)\n",
    "# out = tf.keras.layers.Dense(32, activation='relu')(out)\n",
    "out = tf.keras.layers.Dense(num_classes, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'projection_dim': self.projection_dim,\n",
    "            'query_dense': self.query_dense,\n",
    "            'key_dense': self.key_dense,\n",
    "            'value_dense': self.value_dense,\n",
    "            'combine_heads': self.combine_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.6339 - accuracy: 0.7941 - val_loss: 0.3415 - val_accuracy: 0.8998\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1176 - accuracy: 0.9648 - val_loss: 0.5680 - val_accuracy: 0.8469\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0941 - accuracy: 0.9720 - val_loss: 0.1288 - val_accuracy: 0.9631\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0753 - accuracy: 0.9772 - val_loss: 0.1292 - val_accuracy: 0.9656\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 37s 19ms/step - loss: 0.0636 - accuracy: 0.9805 - val_loss: 0.1166 - val_accuracy: 0.9666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc288cc2190>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "inp = Input(shape = (28, 28, 1))\n",
    "x = Conv2D(32, (2,2), activation='relu', padding='same')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "c = Conv2D(64, (2,2), activation='relu')\n",
    "x = c(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "x = Conv2D(64*3, (2,2), activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Reshape([6*6,64*3])(x)\n",
    "\n",
    "\n",
    "att = MultiHeadSelfAttention(embed_dim=128, num_heads=8)\n",
    "x = att(x)\n",
    "\n",
    "x = Reshape([24,6,32])(x)\n",
    "\n",
    "# x = Reshape([6,6,32])(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Functional Multi Head Attentional Model with separate heads and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-988d449cc872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprojection_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Multi Head attention in a functional fashion. Includes two more complicated functions > attention and separate heads\n",
    "\"\"\"\n",
    "\n",
    "def separate_heads(x, batch_size, num_head, projection_dim):\n",
    "    x = tf.reshape(\n",
    "        x, (batch_size, -1, num_heads, projection_dim)\n",
    "    )\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "def attention(query, key, value):\n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_score = score / tf.math.sqrt(dim_key)\n",
    "    weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "    output = tf.matmul(weights, value)\n",
    "    return output, weights\n",
    "\n",
    "\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "batch_size = tf.shape(x)[0]\n",
    "\n",
    "projection_dim = embed_dim // num_heads\n",
    "query_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "key_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "value_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "\n",
    "# query = separate_heads(query_dense, batch_size, num_heads, projection_dim)\n",
    "query = tf.keras.layers.Reshape([batch_size, -1, num_heads, projection_dim])(query_dense)\n",
    "query = tf.keras.layers.Permute()(query)\n",
    "key = separate_heads(key_dense, batch_size, num_heads, projection_dim)\n",
    "value = separate_heads(value_dense, batch_size, num_heads, projection_dim)\n",
    "\n",
    "attention, weights = attention(query, key, value)\n",
    "concat_attention = tf.reshape(attention, (batch_size, -1, embed_dim))\n",
    "x = tf.keras.layers.Dense(embed_dim)(concat_attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 4, 36, 16)\n",
      "(None, 1, 4, 36, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 16 and 36 for '{{node tf.linalg.matmul_42/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](Placeholder, Placeholder_1)' with input shapes: [?,1,4,36,16], [?,1,4,36,16].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3250\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_resource_variable_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3251\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3252\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_resource_variable_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 16 and 36 for '{{node tf.linalg.matmul_42/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](Placeholder, Placeholder_1)' with input shapes: [?,1,4,36,16], [?,1,4,36,16].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-d103e7ad1a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# weights = tf.nn.softmax(scaled_score, axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mconcat_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, args, kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GLOBAL_DISPATCHERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, op, args, kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         for x in nest.flatten([args, kwargs])):\n\u001b[0;32m-> 1450\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mTFOpLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1451\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# multiple ops w/ the same name when the layer is reused)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3274\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3275\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3276\u001b[0;31m       return gen_math_ops.batch_mat_mul_v2(\n\u001b[0m\u001b[1;32m   3277\u001b[0m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m   \u001b[0madj_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"adj_y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1535\u001b[0m         \"BatchMatMulV2\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n\u001b[1;32m   1536\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transformer-snn-conversion/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 16 and 36 for '{{node tf.linalg.matmul_42/MatMul}} = BatchMatMulV2[T=DT_FLOAT, adj_x=false, adj_y=false](Placeholder, Placeholder_1)' with input shapes: [?,1,4,36,16], [?,1,4,36,16]."
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "inp = Input(shape = (28, 28, 1))\n",
    "x = Conv2D(32, (2,2), activation='relu', padding='same')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "c = Conv2D(64, (2,2), activation='relu')\n",
    "x = c(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "x = Conv2D(64*3, (2,2), activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Reshape([6*6,64*3])(x)\n",
    "\n",
    "# ===========================================================================================\n",
    "def separate_heads(x, batch_size, num_head, projection_dim):\n",
    "    x = tf.reshape(\n",
    "        x, (batch_size, -1, num_heads, projection_dim)\n",
    "    )\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "def attention(query, key, value):\n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_score = score / tf.math.sqrt(dim_key)\n",
    "    weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "    output = tf.matmul(weights, value)\n",
    "    return output, weights\n",
    "\n",
    "\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "batch_size = tf.shape(x)[0]\n",
    "\n",
    "projection_dim = embed_dim // num_heads\n",
    "query_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "key_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "value_dense = tf.keras.layers.Dense(embed_dim)(x)\n",
    "\n",
    "# query = separate_heads(query_dense, batch_size, num_heads, projection_dim)\n",
    "# query = tf.transpose(query, perm=[0, 2, 1, 3])\n",
    "query = tf.keras.layers.Reshape((-1, 36, num_heads, projection_dim))(query_dense)\n",
    "# query = tf.reshape(query_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "query = tf.keras.layers.Permute((1, 3, 2, 4))(query)\n",
    "\n",
    "# key = separate_heads(key_dense, batch_size, num_heads, projection_dim)\n",
    "key = tf.keras.layers.Reshape((-1, 36, num_heads, projection_dim))(key_dense)\n",
    "# key = tf.reshape(key_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "key = tf.keras.layers.Permute((1, 3, 2, 4))(key)\n",
    "\n",
    "# value = separate_heads(value_dense, batch_size, num_heads, projection_dim)\n",
    "value = tf.keras.layers.Reshape((-1, 36, num_heads, projection_dim))(value_dense)\n",
    "# value = tf.reshape(value_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "value = tf.keras.layers.Permute((1, 3, 2, 4))(value)\n",
    "\n",
    "# attention, weights = attention(query, key, value)\n",
    "score = tf.matmul(query, key, transpose_b=True)\n",
    "dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "scaled_score = score / tf.math.sqrt(dim_key)\n",
    "# weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "weights = tf.keras.layers.Softmax(axis=-1)(scaled_score)\n",
    "attention = tf.matmul(weights, value)\n",
    "\n",
    "concat_attention = tf.keras.layers.Reshape((-1, 36, embed_dim))(attention)\n",
    "# concat_attention = tf.reshape(attention, (batch_size, -1, embed_dim))\n",
    "x = tf.keras.layers.Dense(embed_dim)(concat_attention)\n",
    "\n",
    "# ===========================================================================================\n",
    "\n",
    "x = Reshape([6, 12, 32])(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x) \n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 28, 28, 32)   160         input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 13, 13, 64)   8256        max_pooling2d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_97 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 6, 6, 192)    49344       max_pooling2d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_121 (Reshape)           (None, 36, 192)      0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_204 (Dense)               (None, 36, 64)       12352       reshape_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_123 (Reshape)           (None, 1, 36, 4, 16) 0           dense_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 1, 4, 36, 16) 0           reshape_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (None, 36, 64)       12352       reshape_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_55 (TFOpLamb (5,)                 0           permute_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_122 (Reshape)           (None, 1, 36, 4, 16) 0           dense_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_55 (Sl ()                   0           tf.compat.v1.shape_55[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 1, 4, 36, 16) 0           reshape_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_19 (TFOpLambda)         ()                   0           tf.__operators__.getitem_55[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_39 (TFOpLambda (None, 1, 4, 36, 36) 0           permute_28[0][0]                 \n",
      "                                                                 permute_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sqrt_19 (TFOpLambda)    ()                   0           tf.cast_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_205 (Dense)               (None, 36, 64)       12352       reshape_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_21 (TFOpLambda) (None, 1, 4, 36, 36) 0           tf.linalg.matmul_39[0][0]        \n",
      "                                                                 tf.math.sqrt_19[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_124 (Reshape)           (None, 1, 36, 4, 16) 0           dense_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 1, 4, 36, 36) 0           tf.math.truediv_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 1, 4, 36, 16) 0           reshape_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_40 (TFOpLambda (None, 1, 4, 36, 16) 0           softmax[0][0]                    \n",
      "                                                                 permute_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_125 (Reshape)           (None, 1, 36, 64)    0           tf.linalg.matmul_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_206 (Dense)               (None, 1, 36, 64)    4160        reshape_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_126 (Reshape)           (None, 6, 12, 32)    0           dense_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 6, 12, 32)    128         reshape_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 2304)         0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_207 (Dense)               (None, 256)          590080      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_208 (Dense)               (None, 10)           2570        dense_207[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 691,754\n",
      "Trainable params: 691,690\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Simplest Attention Model only with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not multi head attention with simplest operations. Only attention function is somehow more complicated\n",
    "\"\"\"\n",
    "\n",
    "def attention(query, key, value):\n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_score = score / tf.math.sqrt(dim_key)\n",
    "    weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "    output = tf.matmul(weights, value)\n",
    "    return output, weights\n",
    "\n",
    "\n",
    "embed_dim = 64\n",
    "num_heads = 1\n",
    "batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "projection_dim = embed_dim // num_heads\n",
    "query_dense = Dense(embed_dim)(x)\n",
    "key_dense = Dense(embed_dim)(x)\n",
    "value_dense = Dense(embed_dim)(x)\n",
    "\n",
    "query = tf.reshape(query_dense, (batch_size, -1, num_heads, self.projection_dim))\n",
    "key = tf.reshape(key_dense, (batch_size, -1, num_heads, self.projection_dim))\n",
    "value = tf.reshape(value_dense, (batch_size, -1, num_heads, self.projection_dim))\n",
    "\n",
    "attention, weights = attention(query, key, value)\n",
    "concat_attention = tf.reshape(attention, (batch_size, -1, embed_dim))\n",
    "output = Dense(embed_dim)(concat_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize input so we can train ANN with it.\n",
    "# Will be converted back to integers for SNN layer.\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Add a channel dimension.\n",
    "axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
    "x_train = np.expand_dims(x_train, axis)\n",
    "x_test = np.expand_dims(x_test, axis)\n",
    "\n",
    "# One-hot encode target vectors.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "inp = Input(shape = (28, 28, 1))\n",
    "x = Conv2D(32, (2,2), activation='relu', padding='same')(inp)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "c = Conv2D(64, (2,2), activation='relu')\n",
    "x = c(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "x = Conv2D(64*3, (2,2), activation='relu')(x)\n",
    "\n",
    "\n",
    "x = Reshape([6*6,64*3])(x)\n",
    "\n",
    "def attention(query, key, value):\n",
    "    score = tf.matmul(query, key, transpose_b=True)\n",
    "    dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_score = score / tf.math.sqrt(dim_key)\n",
    "    weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "    output = tf.matmul(weights, value)\n",
    "    return output, weights\n",
    "\n",
    "\n",
    "embed_dim = 64\n",
    "num_heads = 1\n",
    "batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "projection_dim = embed_dim // num_heads\n",
    "\n",
    "query_dense = Dense(embed_dim)(x)\n",
    "key_dense = Dense(embed_dim)(x)\n",
    "value_dense = Dense(embed_dim)(x)\n",
    "\n",
    "query = tf.reshape(query_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "key = tf.reshape(key_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "value = tf.reshape(value_dense, (batch_size, -1, num_heads, projection_dim))\n",
    "\n",
    "attention, weights = attention(query, key, value)\n",
    "concat_attention = tf.reshape(attention, (batch_size, -1, embed_dim))\n",
    "x = Dense(embed_dim)(concat_attention)\n",
    "\n",
    "# att = MultiHeadSelfAttention(embed_dim=64, num_heads=1)\n",
    "# x = att(x)\n",
    "# # att = MultiHeadAttention(num_heads=4, key_dim=64)\n",
    "# # x = att(x, x)\n",
    "\n",
    "\n",
    "\n",
    "x = Reshape([12,6,32])(x)\n",
    "\n",
    "# x = Reshape([6,6,32])(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=1, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'get_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-eedee1354a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_multi_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-eedee1354a14>\u001b[0m in \u001b[0;36mparse_multi_head_attention\u001b[0;34m(layer, attributes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_multi_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_multi_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'get_weights'"
     ]
    }
   ],
   "source": [
    "def parse_multi_head_attention(layer, attributes):\n",
    "    attributes['parameters'] = list(layer.get_weights())\n",
    "    return attributes\n",
    "\n",
    "attrs = parse_multi_head_attention(att, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.05251397,  0.05196556,  0.04602323, ..., -0.0906411 ,\n",
       "           0.05808846, -0.05304115],\n",
       "         [ 0.07712557,  0.06473607,  0.06472164, ..., -0.09025709,\n",
       "           0.1291429 , -0.06681956],\n",
       "         [ 0.14465804,  0.05553916,  0.07451871, ...,  0.05384645,\n",
       "           0.13792342, -0.09032944],\n",
       "         [-0.07952031,  0.10550651,  0.08444484, ...,  0.08768411,\n",
       "          -0.10532371,  0.11276584]],\n",
       " \n",
       "        [[-0.13679186,  0.15290363,  0.16425851, ..., -0.22392105,\n",
       "           0.18364385, -0.12704042],\n",
       "         [ 0.14089543,  0.15607025,  0.13811384, ..., -0.17982219,\n",
       "           0.1849788 , -0.18002434],\n",
       "         [ 0.20148136,  0.21233286,  0.23205617, ...,  0.21763808,\n",
       "           0.18484046, -0.19925883],\n",
       "         [-0.2809631 ,  0.20544429,  0.2593414 , ...,  0.2762511 ,\n",
       "          -0.2782754 ,  0.27995571]],\n",
       " \n",
       "        [[ 0.20744342, -0.19630732, -0.17898946, ...,  0.08385453,\n",
       "          -0.1826546 ,  0.23804533],\n",
       "         [-0.14874424, -0.15827128, -0.24028395, ...,  0.100737  ,\n",
       "          -0.0583225 ,  0.1336612 ],\n",
       "         [-0.11334974, -0.2937594 , -0.20369865, ..., -0.20085111,\n",
       "          -0.08043937,  0.16457197],\n",
       "         [ 0.19272026, -0.25913465, -0.17048728, ..., -0.24019986,\n",
       "           0.24992478, -0.22585393]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.3248921 , -0.28375605, -0.3139957 , ...,  0.20770995,\n",
       "          -0.31454122,  0.33459002],\n",
       "         [-0.21800542, -0.25742123, -0.3112824 , ...,  0.19888529,\n",
       "          -0.08865257,  0.22753443],\n",
       "         [-0.13150805, -0.32200855, -0.22637974, ..., -0.27126753,\n",
       "          -0.09487324,  0.18178672],\n",
       "         [ 0.29408613, -0.32930878, -0.27372587, ..., -0.3262213 ,\n",
       "           0.35279748, -0.32069728]],\n",
       " \n",
       "        [[-0.11212746,  0.16101916,  0.12644473, ..., -0.16661216,\n",
       "           0.1552081 , -0.1332578 ],\n",
       "         [ 0.13157053,  0.12494146,  0.08053752, ..., -0.13125898,\n",
       "           0.14075834, -0.1304971 ],\n",
       "         [ 0.19321415,  0.18581644,  0.1868764 , ...,  0.17816375,\n",
       "           0.19763297, -0.17903683],\n",
       "         [-0.19637111,  0.16641484,  0.2018307 , ...,  0.1987217 ,\n",
       "          -0.16400634,  0.17659226]],\n",
       " \n",
       "        [[ 0.11011035, -0.10693034, -0.10543351, ...,  0.05013831,\n",
       "          -0.10423423,  0.10354344],\n",
       "         [-0.03282916, -0.04995808, -0.06846881, ...,  0.00036288,\n",
       "           0.03116482,  0.03831413],\n",
       "         [ 0.03720722, -0.02278123,  0.01742615, ..., -0.03058437,\n",
       "           0.06385469, -0.02850666],\n",
       "         [ 0.09478367, -0.12544328, -0.08742071, ..., -0.0814392 ,\n",
       "           0.09613014, -0.12517273]]], dtype=float32),\n",
       " array([[ 3.67264785e-02, -1.92353781e-02, -2.08534226e-02,\n",
       "         -1.24450503e-02, -8.02363083e-03, -2.95702200e-02,\n",
       "          6.66772481e-03, -2.35431176e-02,  2.59126816e-02,\n",
       "         -5.18125407e-02, -2.93882284e-02, -3.63801979e-02,\n",
       "         -1.01592736e-02,  9.07306559e-03,  9.47861373e-03,\n",
       "         -5.15060686e-03,  2.78108809e-02, -7.86438212e-03,\n",
       "          7.19622010e-03, -6.55086071e-04, -1.96008142e-02,\n",
       "          1.93691794e-02, -1.09895654e-02, -2.41432153e-02,\n",
       "          8.17009658e-02,  8.57748650e-03, -2.64836736e-02,\n",
       "         -1.45244198e-02, -4.34065750e-03,  3.61034879e-03,\n",
       "          6.52378574e-02,  8.06402117e-02,  2.46290565e-02,\n",
       "          1.51379257e-02,  7.33390683e-04,  4.75873835e-02,\n",
       "          1.46446321e-02, -1.04934135e-02, -2.40428653e-03,\n",
       "         -2.02336926e-02,  6.02037944e-02,  2.42632758e-02,\n",
       "         -2.47458904e-03,  3.02637089e-02,  2.35752892e-02,\n",
       "         -1.86028164e-02, -5.97217306e-02, -8.31325352e-03,\n",
       "          2.72099562e-02, -1.60082034e-03, -8.48930329e-03,\n",
       "          4.98611256e-02, -2.41888463e-02, -3.19169485e-03,\n",
       "         -7.39914482e-04, -8.36339686e-03, -5.94247021e-02,\n",
       "         -8.39101374e-02,  6.61061481e-02,  1.39307156e-02,\n",
       "          4.04974446e-03, -2.98418384e-02, -1.67319793e-02,\n",
       "          4.06129248e-02],\n",
       "        [ 1.03385085e-02,  4.00376134e-03, -3.35896201e-02,\n",
       "         -8.22391827e-03, -1.88279548e-03,  2.54392307e-02,\n",
       "          3.18979509e-02, -3.65162306e-02,  1.72774233e-02,\n",
       "          1.48174400e-02,  3.34136188e-03, -2.47348286e-03,\n",
       "         -2.59143319e-02,  2.28014570e-02, -1.82334557e-02,\n",
       "          6.60551488e-02,  3.22867348e-03,  2.24442780e-03,\n",
       "          7.94607867e-03,  1.11054294e-02, -5.47300419e-03,\n",
       "         -1.80960577e-02, -3.48072685e-02, -1.99855026e-02,\n",
       "          6.81558400e-02, -3.67250480e-02, -1.94571298e-02,\n",
       "         -4.17745821e-02,  4.69630659e-02, -8.52226652e-03,\n",
       "         -2.04505250e-02, -5.89670194e-03, -5.20796031e-02,\n",
       "          9.04307049e-03, -2.45912205e-02, -1.07733849e-02,\n",
       "          1.00313999e-01,  3.92907560e-02, -6.58449670e-03,\n",
       "          1.24923158e-02,  6.66204141e-03, -3.82831097e-02,\n",
       "          1.36946272e-02, -2.16744225e-02, -8.93550552e-03,\n",
       "         -2.05575884e-03,  1.45797394e-02,  2.62697181e-03,\n",
       "         -8.44759401e-03, -1.40733179e-02, -4.41236086e-02,\n",
       "         -1.01456828e-02, -7.21096480e-03,  1.46188261e-02,\n",
       "         -6.81843832e-02,  1.00430241e-02,  2.44240439e-03,\n",
       "         -1.25807459e-02,  1.08235879e-02, -9.40079894e-03,\n",
       "          1.45787047e-02, -1.09702582e-02,  6.54072464e-02,\n",
       "         -1.20236045e-02],\n",
       "        [ 8.61410648e-02,  2.02334020e-02,  6.14810288e-02,\n",
       "          1.50855973e-01, -3.05021964e-02, -1.02320667e-02,\n",
       "          2.12921966e-02, -8.01636949e-02,  8.41224864e-02,\n",
       "         -2.77626328e-03,  3.13523561e-02,  7.59031251e-02,\n",
       "         -1.30062252e-01,  8.37213248e-02, -4.40544169e-03,\n",
       "          1.25339255e-01,  5.76919056e-02,  9.86882660e-05,\n",
       "         -7.63817728e-02, -8.48374050e-03, -1.66685730e-02,\n",
       "         -1.19823895e-01, -2.81472504e-02,  2.76287999e-02,\n",
       "          5.78720719e-02, -1.14074927e-02, -6.19310774e-02,\n",
       "          4.51217294e-02,  2.42780261e-02,  9.23473574e-03,\n",
       "          9.20530036e-02,  1.24173217e-01, -9.92387310e-02,\n",
       "          5.08118682e-02, -3.03241797e-02, -4.67042578e-03,\n",
       "          1.09992407e-01, -9.67589170e-02,  1.04322352e-01,\n",
       "          8.32539611e-03, -6.55164868e-02,  5.32241352e-02,\n",
       "         -1.22194635e-02,  1.51383383e-02,  4.24944982e-02,\n",
       "          1.42738223e-01,  2.25581937e-02,  5.78712076e-02,\n",
       "         -6.13751821e-02,  1.00050226e-01, -7.32049271e-02,\n",
       "         -6.50412729e-03,  1.51322663e-01,  1.12583511e-01,\n",
       "         -1.63761340e-02,  5.98313101e-03, -6.34511234e-03,\n",
       "         -3.25138271e-02,  1.79801024e-02,  1.36467246e-02,\n",
       "          3.13744284e-02,  2.44426597e-02,  1.01944603e-01,\n",
       "         -6.34210259e-02],\n",
       "        [-1.97113454e-02, -1.76092554e-02,  3.07962615e-02,\n",
       "          1.24579947e-02, -3.27715613e-02,  6.73374906e-03,\n",
       "         -9.96034686e-03, -1.19572878e-03,  1.60768181e-02,\n",
       "         -1.52198644e-02,  1.23702188e-03,  2.18529298e-04,\n",
       "         -1.57730374e-02,  1.04968389e-02, -8.14917460e-02,\n",
       "          5.70380781e-03,  6.72883913e-02, -8.03498458e-03,\n",
       "          1.64083540e-02, -3.74057218e-02, -2.35969406e-02,\n",
       "         -1.73933823e-02, -7.63057265e-04,  1.12226969e-02,\n",
       "         -4.56721755e-03, -6.32631918e-03, -6.83019590e-03,\n",
       "         -1.80063527e-02,  3.36813414e-03, -2.47221626e-02,\n",
       "         -1.02794413e-02,  3.91529960e-04,  1.73179246e-02,\n",
       "         -4.11410555e-02,  8.03945865e-03,  9.99789592e-03,\n",
       "         -9.22617316e-03,  1.48231935e-04, -2.11890060e-02,\n",
       "         -1.91049594e-02,  5.19258389e-03, -1.02336761e-02,\n",
       "          9.89730190e-03, -7.46764289e-03, -1.05775567e-02,\n",
       "         -8.68598185e-03,  3.93764153e-02,  1.01323212e-02,\n",
       "         -8.86173174e-03,  2.06284486e-02, -7.05638947e-03,\n",
       "         -1.03500467e-02, -3.66633665e-03,  3.09559852e-02,\n",
       "         -1.75635722e-02, -4.50474732e-02,  6.04076264e-03,\n",
       "         -6.14332929e-02, -3.20579000e-02,  1.49435224e-02,\n",
       "         -9.41126794e-03,  2.03650631e-02, -1.08012529e-02,\n",
       "          2.50242371e-02]], dtype=float32),\n",
       " array([[[ 0.23854066, -0.22348335, -0.22567108, ...,  0.24735443,\n",
       "          -0.22430879,  0.2245996 ],\n",
       "         [-0.15456282, -0.14485495, -0.07945699, ...,  0.11880515,\n",
       "          -0.23744062,  0.13282645],\n",
       "         [-0.19264999, -0.220915  , -0.21994086, ..., -0.17893426,\n",
       "          -0.20807296,  0.20977952],\n",
       "         [ 0.18508114, -0.16528337, -0.20824   , ..., -0.20440166,\n",
       "           0.19472665, -0.19077308]],\n",
       " \n",
       "        [[ 0.00228145, -0.01763216, -0.00950418, ...,  0.02385407,\n",
       "          -0.05313367,  0.01142595],\n",
       "         [-0.09230047, -0.08517404, -0.01338046, ...,  0.10206332,\n",
       "          -0.10815106,  0.0790775 ],\n",
       "         [-0.09981573, -0.12834321, -0.09455985, ..., -0.09117981,\n",
       "          -0.11844628,  0.09430643],\n",
       "         [ 0.04741482,  0.01682752, -0.02319152, ..., -0.02042111,\n",
       "           0.02686703, -0.02297623]],\n",
       " \n",
       "        [[-0.06155355,  0.02620113,  0.02151468, ..., -0.0130672 ,\n",
       "           0.04207881, -0.02788395],\n",
       "         [-0.00267837,  0.01132905,  0.02825818, ..., -0.00870662,\n",
       "          -0.05279669,  0.01950553],\n",
       "         [-0.07651199, -0.03677196, -0.08149083, ..., -0.0319609 ,\n",
       "          -0.08600153,  0.0751844 ],\n",
       "         [ 0.03321326, -0.03171618, -0.03952465, ..., -0.02957392,\n",
       "           0.02905799, -0.05519472]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.07142885,  0.04282058,  0.0482048 , ..., -0.0272369 ,\n",
       "           0.05387414, -0.06038409],\n",
       "         [ 0.01560866,  0.0072724 ,  0.06916567, ..., -0.04025218,\n",
       "          -0.06494538, -0.03848077],\n",
       "         [-0.08715633,  0.0460653 , -0.03945186, ...,  0.04583551,\n",
       "          -0.07323343,  0.05714203],\n",
       "         [-0.02569941,  0.03601796,  0.02339874, ...,  0.01592802,\n",
       "          -0.03211446,  0.01657426]],\n",
       " \n",
       "        [[ 0.17334954, -0.19042484, -0.20092985, ...,  0.20904124,\n",
       "          -0.19127741,  0.14492126],\n",
       "         [-0.01852084, -0.05046272, -0.01030393, ...,  0.03790881,\n",
       "          -0.04875692,  0.04212916],\n",
       "         [-0.1053179 , -0.07759866, -0.12013506, ..., -0.09843317,\n",
       "          -0.11314262,  0.11477505],\n",
       "         [ 0.10332423, -0.08813749, -0.09220254, ..., -0.10367622,\n",
       "           0.09413244, -0.09581064]],\n",
       " \n",
       "        [[-0.04154803,  0.0515606 ,  0.06842543, ..., -0.0366044 ,\n",
       "           0.06080653, -0.02947238],\n",
       "         [-0.03769856, -0.03510613, -0.00853543, ...,  0.03821031,\n",
       "          -0.02815151,  0.01818838],\n",
       "         [ 0.01804414,  0.01629794,  0.00812744, ...,  0.02671731,\n",
       "          -0.02079362, -0.00482348],\n",
       "         [-0.02015945,  0.06365805,  0.00763238, ...,  0.01568667,\n",
       "          -0.02664814,  0.01018282]]], dtype=float32),\n",
       " array([[-1.37055249e-04,  2.25094336e-05,  2.22647450e-05,\n",
       "          6.79706791e-05,  4.16337425e-05, -5.52425117e-05,\n",
       "         -1.04371684e-04, -4.20684898e-07, -4.33806463e-07,\n",
       "         -3.87622531e-05,  7.45717116e-05,  4.15598042e-05,\n",
       "          7.44287463e-05,  3.61236780e-05, -2.25362273e-05,\n",
       "         -1.77995717e-05, -4.00587414e-05,  1.72535169e-06,\n",
       "         -5.69563890e-05,  6.39166465e-05, -2.41577382e-05,\n",
       "          2.66609386e-05, -1.81530231e-05,  2.66396837e-05,\n",
       "         -1.50095721e-05,  7.84751610e-05, -1.51086908e-06,\n",
       "         -4.16150033e-05, -3.57911085e-05, -4.95653039e-05,\n",
       "         -1.33324604e-04, -3.88972185e-05,  4.81038478e-05,\n",
       "         -4.25834478e-05,  1.10112605e-05, -1.47936051e-04,\n",
       "         -3.48593458e-05,  2.09758655e-05, -2.89098182e-07,\n",
       "          4.20089418e-05,  1.55605539e-05, -8.69934520e-05,\n",
       "          1.57441282e-05, -1.97675081e-06, -3.77364740e-05,\n",
       "         -5.11728904e-05, -9.03296677e-06, -6.92315953e-05,\n",
       "         -3.90523164e-05,  5.62306377e-05, -6.46163389e-05,\n",
       "         -6.21404179e-05,  2.29454254e-05,  6.77826320e-05,\n",
       "         -2.52783429e-05,  7.89393198e-06,  1.30531234e-05,\n",
       "         -1.97089867e-05,  1.77608817e-05,  5.84155132e-05,\n",
       "         -7.71838459e-05, -1.08128806e-05,  3.68865221e-05,\n",
       "         -8.17880937e-05],\n",
       "        [-1.21271441e-05,  2.09239097e-05, -1.51894828e-05,\n",
       "         -1.60717809e-05, -5.12880251e-06, -1.32210316e-05,\n",
       "          1.06820116e-05,  1.59897954e-05, -2.16900116e-06,\n",
       "         -9.43565965e-07,  1.04821520e-05,  2.78016273e-06,\n",
       "          3.32943200e-05,  2.08756251e-06, -2.87043281e-06,\n",
       "         -3.31728870e-07, -2.72518701e-05,  1.52184396e-06,\n",
       "          6.25424900e-06, -2.39958190e-05,  3.60194849e-06,\n",
       "         -1.38367459e-05,  1.72994914e-05, -4.46734448e-05,\n",
       "          8.85428165e-07,  1.14542545e-05, -6.17072146e-05,\n",
       "         -6.85699388e-06, -1.81851537e-05, -8.84499741e-07,\n",
       "         -1.23102491e-05, -2.10458657e-05, -1.36291765e-05,\n",
       "          4.06657637e-05, -3.68729252e-06, -5.44112299e-06,\n",
       "         -1.76800349e-05, -1.62323977e-05, -1.26474652e-05,\n",
       "         -2.30711903e-05, -1.94222921e-05, -1.17195814e-05,\n",
       "          1.35674509e-05, -1.84300807e-05, -1.20269660e-05,\n",
       "         -6.38643678e-06, -4.37508697e-06, -2.28666304e-05,\n",
       "          2.29222169e-05, -8.77743150e-06, -6.89913068e-05,\n",
       "          3.51752642e-05,  3.70775451e-05,  3.80084316e-06,\n",
       "         -4.07605557e-06, -2.36049436e-05,  1.64791272e-05,\n",
       "          2.00923296e-06,  4.53956227e-06, -3.00955662e-06,\n",
       "         -9.50800131e-06, -3.83352426e-06, -2.15530745e-05,\n",
       "          1.26186751e-05],\n",
       "        [ 3.54875119e-05,  3.86332249e-05,  3.54306285e-05,\n",
       "         -1.21201447e-06, -3.90410823e-05, -4.80757262e-06,\n",
       "          3.47229579e-05,  1.27065541e-05,  1.68865154e-05,\n",
       "         -3.36728626e-05,  4.72174943e-05,  1.01862615e-05,\n",
       "          2.42371825e-05,  7.12094406e-05, -4.65639005e-06,\n",
       "          8.76096783e-06,  2.02048559e-05,  5.51500034e-06,\n",
       "         -1.87108999e-05,  1.25660927e-05,  1.00218585e-05,\n",
       "         -2.05639226e-05, -2.21712216e-05,  6.09836825e-05,\n",
       "          1.94517215e-05,  2.41123307e-05, -8.02091163e-05,\n",
       "          2.89396212e-06,  6.34230673e-05,  5.84884074e-05,\n",
       "          1.53395285e-06,  2.02069859e-05,  1.51441839e-06,\n",
       "          2.92682853e-06, -9.97014922e-06, -2.68881849e-05,\n",
       "         -3.46339243e-06, -2.11742226e-05,  5.63319336e-05,\n",
       "          3.95967108e-05, -3.94828603e-05,  2.57390366e-05,\n",
       "         -2.54598945e-05, -8.30106273e-06,  1.48006177e-06,\n",
       "          2.24582436e-05, -5.33282946e-05,  4.59144649e-05,\n",
       "          1.03429738e-05, -1.23072496e-05, -4.29686042e-05,\n",
       "          5.32315171e-05,  6.24600943e-05, -2.25795666e-05,\n",
       "         -5.41640802e-05,  5.42681992e-05,  3.07862865e-05,\n",
       "         -1.98539256e-05,  2.11738261e-05,  2.96789876e-05,\n",
       "          1.33581212e-04,  5.81705171e-05,  3.18759703e-05,\n",
       "         -1.51495915e-05],\n",
       "        [-3.72757895e-05, -6.20895371e-05, -4.38979623e-05,\n",
       "         -4.23713318e-05, -2.76754963e-05,  6.12455915e-05,\n",
       "          6.46084573e-08,  4.74866101e-05, -1.13374590e-05,\n",
       "          5.85745875e-05,  3.06572588e-06, -3.74419346e-06,\n",
       "          6.69585788e-05,  1.01074191e-04,  2.69484553e-05,\n",
       "         -2.13204057e-05,  2.60129855e-05, -7.46400183e-05,\n",
       "          1.54446738e-04,  2.83791123e-05, -4.08886335e-05,\n",
       "         -5.41033614e-06,  1.76197464e-05, -5.79023435e-05,\n",
       "         -7.68865648e-05, -6.92065878e-05,  7.42306365e-05,\n",
       "          3.34188990e-05,  2.49274090e-05, -5.43615897e-05,\n",
       "          5.39489702e-05, -5.86119204e-05,  3.45596818e-05,\n",
       "          4.51737360e-05,  2.25553267e-05,  3.44972686e-05,\n",
       "         -3.57102581e-05, -1.01173255e-05, -5.01989598e-05,\n",
       "         -1.95418197e-05, -1.02472304e-05,  2.25865151e-05,\n",
       "          8.81847609e-06, -9.66639982e-06,  5.18322595e-05,\n",
       "          3.34524921e-05,  1.01533687e-05,  4.96887915e-05,\n",
       "         -9.88923148e-06,  7.39640163e-05, -4.67874961e-05,\n",
       "          6.81663514e-05, -2.66409988e-05,  3.69372538e-05,\n",
       "          3.07045448e-05,  4.74566259e-05, -7.29739804e-06,\n",
       "          7.12487417e-06,  9.35018252e-05,  5.23187955e-05,\n",
       "          3.27892303e-05,  2.43628419e-05, -1.32792263e-06,\n",
       "         -1.59428073e-05]], dtype=float32),\n",
       " array([[[-1.66696459e-02, -1.21949829e-01,  7.59053603e-02, ...,\n",
       "          -6.41954783e-03,  7.47288987e-02, -1.41949102e-01],\n",
       "         [-6.22173250e-02, -7.27830604e-02, -6.70852661e-02, ...,\n",
       "          -8.30446333e-02, -5.32382019e-02, -2.03260891e-02],\n",
       "         [-1.59095183e-01,  1.20756611e-01, -6.71823993e-02, ...,\n",
       "           4.62612323e-02, -3.69769558e-02, -1.00128204e-01],\n",
       "         [ 3.01621594e-02, -7.49857575e-02,  3.83935161e-02, ...,\n",
       "           7.53246918e-02, -8.52447748e-02, -1.17535196e-01]],\n",
       " \n",
       "        [[-3.33210304e-02,  9.78175253e-02, -3.38985249e-02, ...,\n",
       "           3.39524671e-02,  9.09531675e-03,  3.49023077e-03],\n",
       "         [-2.73761526e-02, -6.08907314e-03,  1.45296268e-02, ...,\n",
       "           5.18943407e-02,  5.42344409e-04, -4.43246625e-02],\n",
       "         [ 1.23748504e-01, -4.65740897e-02, -2.86034262e-03, ...,\n",
       "           6.63182116e-04, -7.27192089e-02,  3.55725288e-02],\n",
       "         [-5.69776818e-02, -2.74178218e-02,  1.92103274e-02, ...,\n",
       "           4.53820191e-02, -2.68950853e-02,  1.14277892e-01]],\n",
       " \n",
       "        [[-3.95762399e-02,  8.12780112e-02, -1.73762217e-02, ...,\n",
       "          -3.20570134e-02, -2.63642520e-02,  2.31390465e-02],\n",
       "         [-1.23506226e-02, -1.11048892e-02,  3.36203096e-03, ...,\n",
       "          -2.26145294e-02,  1.89087521e-02,  3.19009162e-02],\n",
       "         [ 3.18113416e-02,  2.48855222e-02,  3.72718051e-02, ...,\n",
       "           1.42001861e-03, -7.05796629e-02,  4.56582159e-02],\n",
       "         [ 1.81428436e-02,  7.11547490e-03,  9.03082918e-03, ...,\n",
       "          -1.47641236e-02, -4.87628989e-02,  3.26607674e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-5.37086539e-02,  2.87951455e-02,  3.31681482e-02, ...,\n",
       "          -2.51105567e-03,  6.26966404e-03, -3.32671292e-02],\n",
       "         [-3.48142423e-02,  9.00444854e-03, -3.86121385e-02, ...,\n",
       "          -3.96005623e-02,  6.76909258e-05,  4.96713035e-02],\n",
       "         [ 1.14094550e-02,  3.15234885e-02,  4.12803814e-02, ...,\n",
       "           1.66538786e-02,  8.52017663e-03,  3.22909802e-02],\n",
       "         [ 7.79515656e-04,  1.23067608e-03,  3.65599655e-02, ...,\n",
       "          -3.88585441e-02, -1.84856988e-02,  3.97577742e-03]],\n",
       " \n",
       "        [[ 1.36506315e-02, -8.26681554e-02,  6.19911402e-03, ...,\n",
       "          -3.30416933e-02,  2.58762781e-02, -3.69104929e-02],\n",
       "         [-3.93559458e-03, -1.91305503e-02, -2.20978688e-02, ...,\n",
       "          -5.01593668e-03, -2.47998759e-02,  3.68980840e-02],\n",
       "         [-1.17103525e-01,  4.99013811e-02, -1.62622072e-02, ...,\n",
       "           3.30106318e-02,  1.79555509e-02, -3.11809182e-02],\n",
       "         [ 3.02206986e-02, -1.74513217e-02,  3.40492949e-02, ...,\n",
       "          -2.90086083e-02,  4.36567515e-02, -1.19151823e-01]],\n",
       " \n",
       "        [[ 2.44713388e-03,  3.45199369e-03, -2.84753833e-02, ...,\n",
       "          -1.80061460e-02, -1.15807410e-02,  2.50897314e-02],\n",
       "         [ 5.23077650e-03, -2.11237241e-02,  1.65094715e-03, ...,\n",
       "           6.29408378e-03,  2.54228190e-02, -1.66111328e-02],\n",
       "         [-2.87376717e-03, -2.06011515e-02,  1.91393979e-02, ...,\n",
       "          -2.33020429e-02, -2.66946927e-02, -1.54879410e-02],\n",
       "         [ 8.68638419e-03,  1.54961571e-02, -2.46106256e-02, ...,\n",
       "           1.34760085e-02, -7.44275469e-03,  1.08350429e-03]]],\n",
       "       dtype=float32),\n",
       " array([[ 9.96713061e-03, -2.56031547e-02,  1.22429832e-04,\n",
       "          8.94992333e-03, -9.45754442e-03,  4.11402341e-03,\n",
       "         -1.85724651e-03,  7.80094508e-03, -1.65453053e-03,\n",
       "          6.63085934e-03,  3.20263999e-03, -7.94129539e-03,\n",
       "         -5.62214060e-03, -6.39302284e-03,  4.64314688e-03,\n",
       "          3.71417450e-03, -1.41854351e-02,  1.43805100e-03,\n",
       "          6.85405871e-03,  1.17288117e-04, -5.01028146e-04,\n",
       "          1.23184896e-03, -4.17342270e-03, -2.10112613e-03,\n",
       "          4.72092396e-03, -6.18329330e-04,  9.20448545e-03,\n",
       "         -5.40156104e-03, -8.19862448e-03, -6.31613832e-04,\n",
       "         -4.27120039e-03, -4.65362845e-03,  3.16607719e-03,\n",
       "          4.59930953e-03, -1.23464065e-02,  1.45613376e-04,\n",
       "          4.00420511e-03, -2.12498987e-03,  2.87677278e-03,\n",
       "         -3.20814666e-04,  1.05484226e-03,  2.12598918e-03,\n",
       "         -6.27121117e-05, -3.86295433e-04,  7.62056559e-03,\n",
       "         -4.75563249e-03, -6.95641429e-05,  1.38637354e-03,\n",
       "          9.94336046e-03, -1.91667129e-03, -4.71866602e-04,\n",
       "         -1.25466762e-02, -8.07220303e-03, -6.17155153e-03,\n",
       "         -4.65258537e-03,  7.97217526e-03,  2.24248669e-03,\n",
       "          5.21565147e-04,  6.21176558e-03,  1.63702667e-02,\n",
       "         -1.50665399e-02,  1.36430701e-03,  6.06559729e-03,\n",
       "         -1.23481620e-02],\n",
       "        [ 2.39935145e-03,  4.59715212e-03, -3.85421328e-03,\n",
       "          2.31569284e-03,  4.32087481e-03,  1.64098130e-03,\n",
       "         -4.97843488e-04,  2.10651476e-03,  1.06848299e-03,\n",
       "          3.15051852e-03,  2.45553747e-05,  3.20039736e-03,\n",
       "          1.73198688e-03,  1.96979567e-03,  6.54634670e-04,\n",
       "          4.42529423e-03, -2.46123178e-03,  6.10488886e-03,\n",
       "          3.06985364e-03, -5.61504485e-03,  3.29784263e-04,\n",
       "         -6.48110686e-03, -4.97059012e-03, -4.34968527e-03,\n",
       "          2.35648768e-05, -4.68562962e-03, -1.49497716e-03,\n",
       "          3.42819677e-03, -5.76543901e-03, -8.29092599e-03,\n",
       "          2.04404187e-03, -1.71116856e-03,  5.20701613e-03,\n",
       "         -6.22501457e-03, -2.75187148e-03,  5.67929447e-03,\n",
       "         -6.98912237e-03, -2.07000948e-03,  2.09734612e-03,\n",
       "          2.34663789e-03,  7.75999948e-03,  1.33606722e-03,\n",
       "          2.64229742e-03,  4.69107321e-03,  1.25754979e-02,\n",
       "         -1.04028801e-03, -3.38888640e-05, -7.01434386e-04,\n",
       "          9.39046592e-03,  1.20995007e-03, -4.31990670e-03,\n",
       "         -3.60465259e-03, -5.26970113e-03,  9.29679547e-04,\n",
       "          2.76562432e-03, -4.07905458e-03,  3.20705958e-03,\n",
       "          1.15884030e-02,  8.25850666e-03, -8.10502097e-03,\n",
       "         -2.47838325e-03,  4.86707035e-03, -7.88792458e-05,\n",
       "         -3.69791160e-05],\n",
       "        [-2.19363682e-02,  3.07245180e-03, -4.13523195e-03,\n",
       "         -8.46208597e-04, -4.83410852e-03, -1.48275960e-03,\n",
       "         -5.88614633e-03, -1.29035441e-03,  1.62857911e-03,\n",
       "         -1.18064228e-02,  9.32188984e-03, -1.10681099e-03,\n",
       "          1.01423822e-02,  1.06786434e-02, -3.07647884e-03,\n",
       "          1.61505339e-03,  1.85164134e-03,  2.54305103e-03,\n",
       "          5.44017600e-03, -7.43950345e-03,  4.83831810e-03,\n",
       "          1.29915792e-02, -1.25240758e-02, -1.25039108e-02,\n",
       "         -7.24447798e-03, -5.41902147e-04,  7.37554976e-04,\n",
       "          3.21678608e-03, -6.76587690e-03,  3.17868381e-03,\n",
       "          5.25686843e-03,  2.52347928e-03,  2.80453451e-03,\n",
       "         -5.19304443e-03, -5.09236753e-03, -8.26796051e-03,\n",
       "          5.76288905e-03,  3.45927104e-03,  3.90864955e-03,\n",
       "          5.26957959e-03, -2.68206862e-03,  2.83616479e-03,\n",
       "         -3.81867168e-04, -6.22142339e-04, -1.34149881e-03,\n",
       "         -1.09303254e-03,  6.69368496e-03,  1.26993214e-03,\n",
       "         -8.75321159e-04,  1.42797381e-02,  9.97421885e-05,\n",
       "         -2.52752239e-03,  4.77731880e-03, -3.40032013e-04,\n",
       "          2.23041722e-03,  1.48586114e-03, -2.92136613e-03,\n",
       "          5.57643082e-03,  8.20043311e-03,  4.46102116e-03,\n",
       "         -5.27381012e-03,  3.56029300e-03,  5.30491024e-03,\n",
       "         -5.85253257e-03],\n",
       "        [ 1.59903755e-03, -1.72079512e-04, -2.73677311e-03,\n",
       "         -2.22620578e-03,  3.45143699e-03, -1.51085143e-04,\n",
       "          2.42914702e-03,  1.11974333e-03,  5.35901729e-03,\n",
       "         -1.94074363e-02, -6.06489601e-03,  9.52238776e-03,\n",
       "         -6.81143673e-03,  1.46301172e-03,  3.24167684e-03,\n",
       "          1.07058184e-02,  1.65276881e-03,  1.27213150e-02,\n",
       "          1.27643421e-02,  3.58372368e-03,  6.14070101e-03,\n",
       "          8.25105421e-03,  1.47824746e-03, -3.93044809e-03,\n",
       "          2.83362088e-03, -5.42763807e-03, -3.35445162e-03,\n",
       "          5.08023601e-04,  1.04076741e-03,  1.63830556e-02,\n",
       "         -1.54114852e-03,  4.56539914e-04, -3.36834975e-03,\n",
       "          2.61800201e-03, -9.33092233e-05, -5.19750360e-03,\n",
       "         -1.16554252e-03, -5.94822969e-03,  3.60181020e-03,\n",
       "          2.73130881e-03, -7.21622631e-03,  1.41825769e-02,\n",
       "         -1.23494654e-03,  3.55168013e-03,  6.55379752e-03,\n",
       "          1.64158846e-04, -7.00418791e-03, -1.43561717e-02,\n",
       "          1.65731894e-04, -5.20107802e-03, -5.51787345e-03,\n",
       "         -1.39646921e-02,  3.08697170e-04, -6.05679955e-03,\n",
       "         -3.89022345e-04, -1.11562721e-02, -2.87142955e-03,\n",
       "          8.14193336e-04, -1.36194956e-02, -1.42997922e-03,\n",
       "         -9.88600368e-06, -1.63687300e-03,  1.51992124e-02,\n",
       "         -1.67369582e-02]], dtype=float32),\n",
       " array([[[-0.04374456,  0.01326919,  0.0245734 , ...,  0.05828539,\n",
       "           0.02372556, -0.03287029],\n",
       "         [-0.02676465, -0.05497005, -0.04395018, ...,  0.06023281,\n",
       "          -0.04908499,  0.0636971 ],\n",
       "         [ 0.02248038,  0.09305226, -0.05525563, ...,  0.04745208,\n",
       "          -0.03980444, -0.0635221 ],\n",
       "         ...,\n",
       "         [-0.06605446,  0.04725814, -0.01611619, ..., -0.06860487,\n",
       "          -0.04910226,  0.03718754],\n",
       "         [-0.06270388,  0.09507524,  0.05225728, ...,  0.07121433,\n",
       "          -0.02377738, -0.00659993],\n",
       "         [-0.00093369,  0.02327142, -0.0293128 , ..., -0.05561322,\n",
       "          -0.03101952,  0.04099636]],\n",
       " \n",
       "        [[ 0.06059157, -0.03895003,  0.02161752, ...,  0.05603731,\n",
       "           0.06452795,  0.0301319 ],\n",
       "         [ 0.05479469, -0.01369158,  0.048776  , ..., -0.02473699,\n",
       "           0.08065924,  0.02254012],\n",
       "         [-0.01989154, -0.06227081, -0.00639157, ...,  0.07101718,\n",
       "          -0.04459505,  0.0635284 ],\n",
       "         ...,\n",
       "         [-0.0499232 , -0.03927785, -0.01190616, ...,  0.00937376,\n",
       "           0.06694497,  0.02985179],\n",
       "         [-0.07524803, -0.02566404, -0.01850835, ..., -0.03206476,\n",
       "          -0.00482128, -0.00119399],\n",
       "         [ 0.04915711, -0.01584847, -0.06379209, ..., -0.0419775 ,\n",
       "           0.06202648, -0.02600807]],\n",
       " \n",
       "        [[ 0.01126519, -0.04791617, -0.04974961, ...,  0.04948018,\n",
       "           0.04099676,  0.0658554 ],\n",
       "         [ 0.01004716,  0.05953031, -0.03621014, ...,  0.01267128,\n",
       "          -0.00692227, -0.0787669 ],\n",
       "         [ 0.03760441,  0.01686699, -0.03952871, ..., -0.04923322,\n",
       "          -0.06223989,  0.04859578],\n",
       "         ...,\n",
       "         [ 0.02857001, -0.01383622,  0.05450271, ..., -0.06494635,\n",
       "           0.02652471, -0.02499717],\n",
       "         [ 0.09505383,  0.07247251, -0.04192586, ..., -0.03689625,\n",
       "           0.10517828, -0.02597976],\n",
       "         [ 0.04952686,  0.06763218,  0.01037592, ..., -0.02299406,\n",
       "          -0.0269992 ,  0.01608934]],\n",
       " \n",
       "        [[ 0.03104541, -0.05388267, -0.00433121, ...,  0.01441451,\n",
       "          -0.07090461,  0.06240798],\n",
       "         [ 0.01187456, -0.01507152,  0.07420579, ..., -0.05443977,\n",
       "           0.03596004,  0.05864901],\n",
       "         [-0.06737056,  0.08482327, -0.02031374, ...,  0.06379341,\n",
       "          -0.0218805 , -0.09446324],\n",
       "         ...,\n",
       "         [-0.00357811,  0.01399661, -0.0614517 , ...,  0.03523169,\n",
       "           0.03920273,  0.01570589],\n",
       "         [ 0.09145244, -0.00988697,  0.04167205, ..., -0.06559657,\n",
       "           0.05908268,  0.05590067],\n",
       "         [ 0.11121105, -0.07229   , -0.02158438, ...,  0.03939518,\n",
       "          -0.04003592,  0.0909371 ]]], dtype=float32),\n",
       " array([ 4.1979869e-04,  1.9592324e-03,  5.5107158e-03,  7.5716714e-05,\n",
       "         5.4372638e-03, -5.5721551e-03, -1.6819824e-02, -1.0190679e-02,\n",
       "         3.8905786e-03,  1.1578243e-03,  1.6838878e-02,  2.1944516e-03,\n",
       "        -1.1834908e-02, -6.3684057e-03, -3.7954838e-03,  4.5372993e-03,\n",
       "         1.8800851e-02, -2.7731089e-03,  5.0392831e-03, -8.3934087e-03,\n",
       "        -2.3024722e-03, -6.3124052e-03,  7.7953492e-03,  9.1973469e-03,\n",
       "        -8.3632430e-04,  1.4174272e-02, -8.2594538e-03, -1.4243388e-03,\n",
       "         1.4553817e-02,  7.5920946e-03, -3.3402822e-03,  6.9864024e-03,\n",
       "        -3.6156010e-03,  2.9989827e-04,  3.2931755e-03,  5.2124304e-03,\n",
       "         1.7272547e-02, -5.9636771e-03, -6.4124260e-03, -3.6253878e-03,\n",
       "         1.1935927e-02, -1.3478280e-03, -4.6907016e-03,  5.0505856e-03,\n",
       "         4.2959312e-03, -3.4002783e-03, -6.0806358e-03, -2.1526363e-02,\n",
       "         9.4410153e-03,  1.0145055e-02,  5.2911853e-03, -1.9036918e-03,\n",
       "        -6.9359443e-03, -1.3267050e-03,  1.0560335e-03,  6.0420367e-04,\n",
       "         6.0214754e-04, -4.0525338e-03,  2.4675110e-03, -1.0550258e-02,\n",
       "         9.2430506e-04, -1.2088206e-02,  9.3227555e-04, -6.6092662e-03,\n",
       "        -7.0100506e-03, -3.5003952e-03,  7.5818254e-03, -1.0185444e-03,\n",
       "         3.7140639e-03,  1.7614678e-02,  5.2776933e-03,  7.2044544e-03,\n",
       "         5.9265614e-04,  5.7627601e-03,  1.9160256e-03,  5.8059744e-03,\n",
       "         8.4899301e-03, -7.3801228e-03, -6.0152547e-03,  2.2431463e-03,\n",
       "         8.0067450e-03, -1.4012663e-03,  6.2672710e-03,  3.0545143e-03,\n",
       "        -4.9705254e-03,  3.4910899e-03,  3.9478634e-03, -1.2913416e-02,\n",
       "        -9.2785424e-03,  4.9067112e-03, -3.2923657e-03, -6.2441453e-03,\n",
       "        -3.4624366e-03, -1.4645244e-03, -2.7165823e-03, -5.6578303e-03,\n",
       "        -2.2691838e-03, -1.5649211e-02,  1.2149848e-03,  1.8731178e-03,\n",
       "        -2.0694359e-05,  4.5074439e-03,  9.7086362e-04,  9.5446799e-03,\n",
       "        -4.4111470e-03, -1.1502880e-02, -6.6803251e-03, -5.2190218e-03,\n",
       "        -7.8829704e-03,  6.8333158e-03, -1.1850643e-02,  9.2050517e-03,\n",
       "         6.4887694e-04, -1.6595479e-03, -1.6277839e-03,  1.0517849e-02,\n",
       "         1.6610086e-03,  4.2254464e-03, -4.6838662e-03, -8.7551512e-03,\n",
       "        -4.5722153e-04, -5.5491058e-03, -3.0953073e-05, -6.0427054e-03,\n",
       "         9.2190159e-03, -1.7537827e-03, -6.6450099e-03,  6.0927792e-04,\n",
       "         1.6704015e-03, -3.0449804e-04,  6.6760513e-03,  6.1642504e-03,\n",
       "         7.1835243e-03,  3.8274759e-03,  9.9302875e-03, -2.6981714e-03,\n",
       "        -3.0797615e-03,  5.1608873e-03,  5.4584318e-03,  2.0401047e-03,\n",
       "        -2.5530977e-03,  2.5425835e-03, -4.7176918e-03,  1.2681457e-03,\n",
       "         1.1304681e-02, -3.8688108e-03, -5.5031562e-03, -8.2398281e-03,\n",
       "         5.7643312e-03,  3.5036907e-03, -2.6962559e-03, -7.7129654e-03,\n",
       "         5.9300265e-03, -8.5203694e-03,  1.4578579e-03, -8.1994105e-03,\n",
       "         7.9256725e-03, -4.7369031e-03,  6.1152983e-03, -7.8721223e-03,\n",
       "        -4.3657711e-03, -8.7732645e-03, -9.4557544e-03,  5.5939155e-03,\n",
       "        -7.4211163e-03, -2.1696216e-03, -1.2671399e-02,  7.8599323e-03,\n",
       "        -7.4995868e-03,  4.2008506e-03, -1.4982959e-03, -2.3213301e-04,\n",
       "         7.3333089e-03, -3.1533341e-03, -3.7467398e-03,  7.0977360e-03,\n",
       "        -2.4128219e-03, -7.2191772e-03, -5.0653685e-03,  1.1876721e-02,\n",
       "        -3.9850734e-03, -4.4071965e-04, -7.3534520e-03,  7.7285599e-03,\n",
       "         4.4866609e-03, -3.9868145e-03, -1.7714819e-02, -4.8642545e-03,\n",
       "         4.4788816e-03, -3.5786706e-03, -4.9746591e-03, -1.6543262e-03],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 28, 28, 32)   160         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 13, 64)   8256        max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 192)    49344       max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_142 (Reshape)           (None, 36, 192)      0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 36, 192)      37056       reshape_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 36, 192)      37056       reshape_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_144 (Reshape)           (None, 36, 8, 24)    0           dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_145 (Reshape)           (None, 36, 8, 24)    0           dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_transpose (MatMul (None, 36, 8, 8)     0           reshape_144[0][0]                \n",
      "                                                                 reshape_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "scale_layer_20 (ScaleLayer)     (None, 36, 8, 8)     0           mat_mul_layer_transpose[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 36, 192)      37056       reshape_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "softmax_18 (Softmax)            (None, 36, 8, 8)     0           scale_layer_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_143 (Reshape)           (None, 36, 8, 24)    0           dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mat_mul_layer_48 (MatMulLayer)  (None, 36, 8, 24)    0           softmax_18[0][0]                 \n",
      "                                                                 reshape_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_146 (Reshape)           (None, 36, 192)      0           mat_mul_layer_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_147 (Reshape)           (None, 36, 192)      0           reshape_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 36, 192)      0           reshape_146[0][0]                \n",
      "                                                                 reshape_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 36, 32)       6176        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 1152)         0           dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 10)           11530       flatten_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 186,634\n",
      "Trainable params: 186,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06048298254609108, 0.9819999933242798]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "keras.models.save_model(\n",
    "    model, \n",
    "    os.path.join(\"/home/viktor/PycharmProjects/guided_research/transformer-to-snn-conversion\", \n",
    "    \"mnist_transformer\" + '.h5')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_model = keras.models.load_model(\n",
    "#     os.path.join(\"/home/viktor/PycharmProjects/guided_research/transformer-to-snn-conversion\", \n",
    "#     \"mnist_transformer\" + '.h5'), custom_objects={'MultiHeadSelfAttention': MultiHeadSelfAttention})\n",
    "reconstructed_model = keras.models.load_model(\n",
    "    os.path.join(\"/home/viktor/PycharmProjects/guided_research/transformer-to-snn-conversion\", \n",
    "    \"mnist_transformer\" + '.h5'), custom_objects={'ScaleLayer': ScaleLayer, 'MatMulLayer': MatMulLayer, \n",
    "                                                  'MatMulLayerTranspose': MatMulLayerTranspose,\n",
    "                                                  'PositionalEncodingLayer': PositionalEncodingLayer,\n",
    "                                                  'ExtractPatchesLayer': ExtractPatchesLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 28, 28, 32)   160         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 14, 14, 32)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 13, 13, 64)   8256        max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 6, 6, 192)    49344       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 36, 192)      0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 36, 192)      37056       reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 36, 192)      37056       reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 36, 8, 24)    0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_59 (Reshape)            (None, 36, 8, 24)    0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 36, 8, 24)    0           reshape_58[0][0]                 \n",
      "                                                                 reshape_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_11 (TFOpLambda) (None, 36, 8, 24)    0           multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 36, 192)      37056       reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_11 (Softmax)            (None, 36, 8, 24)    0           tf.math.truediv_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 36, 8, 24)    0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 36, 8, 24)    0           softmax_11[0][0]                 \n",
      "                                                                 reshape_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_60 (Reshape)            (None, 36, 192)      0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 36, 192)      0           reshape_60[0][0]                 \n",
      "                                                                 reshape_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 36, 32)       6176        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_61 (Reshape)            (None, 6, 6, 32)     0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 6, 32)     128         reshape_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1152)         0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          295168      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 10)           2570        dense_52[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 472,970\n",
      "Trainable params: 472,906\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05877845361828804, 0.9815000295639038]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "338.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
