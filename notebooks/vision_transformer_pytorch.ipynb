{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "device = \"cuda\"\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "\n",
    "MIN_NUM_PATCHES = 16\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        mask_value = -torch.finfo(dots.dtype).max\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
    "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
    "            mask = mask[:, None, :] * mask[:, :, None]\n",
    "            dots.masked_fill_(~mask, mask_value)\n",
    "            del mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "        return out\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Residual(PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout))),\n",
    "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout)))\n",
    "            ]))\n",
    "    def forward(self, x, mask = None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, mask = mask)\n",
    "            x = ff(x)\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        assert num_patches > MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, mask = None):\n",
    "        p = self.patch_size\n",
    "\n",
    "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
    "        x = self.patch_to_embedding(x)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x, mask)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    image_size=28,\n",
    "    patch_size=4,\n",
    "    num_classes=10,\n",
    "    dim=128,\n",
    "    depth=64,\n",
    "    heads=4,\n",
    "    mlp_dim=128,\n",
    "    channels=1,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (patch_to_embedding): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (transformer): Transformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (18): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (21): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (24): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (25): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (26): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (27): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (28): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (29): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (30): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (31): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (32): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (33): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (34): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (35): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (36): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (37): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (38): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (39): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (40): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (41): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (42): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (43): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (44): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (45): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (46): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (47): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (48): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (49): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (50): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (51): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (52): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (53): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (54): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (55): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (56): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (57): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (58): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (59): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (60): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (61): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (62): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (63): ModuleList(\n",
       "        (0): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=128, out_features=768, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (fn): PreNorm(\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): GELU()\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "                (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (4): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (to_latent): Identity()\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=128, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-4\n",
    "gamma = 0.7\n",
    "epochs = 10\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d049b8fcf84f45b2d0f98faa26f57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 1 - loss : 1.1405 - acc: 0.5914 - val_loss : 0.4144 - val_acc: 0.8737\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef21fc757d0a4138a19ed826895db685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 2 - loss : 0.2740 - acc: 0.9177 - val_loss : 0.2085 - val_acc: 0.9363\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b918a83e0834cb59832436ced491661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 3 - loss : 0.1847 - acc: 0.9444 - val_loss : 0.1812 - val_acc: 0.9470\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b457f920b6b64b02b7e3dc622d759f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 4 - loss : 0.1458 - acc: 0.9555 - val_loss : 0.1398 - val_acc: 0.9588\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72d6460368048ac89ce530ff7d56430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 5 - loss : 0.1187 - acc: 0.9638 - val_loss : 0.1271 - val_acc: 0.9629\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ef1b52373e45689661d11ef1b3cd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 6 - loss : 0.0998 - acc: 0.9700 - val_loss : 0.0965 - val_acc: 0.9706\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff85eb3f73844b78054b777b4ff5ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 7 - loss : 0.0919 - acc: 0.9724 - val_loss : 0.0984 - val_acc: 0.9707\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc6e8ed8e85451993b8c842bc81cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 8 - loss : 0.0828 - acc: 0.9743 - val_loss : 0.0887 - val_acc: 0.9729\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6bd9e5c17f486582f3636d67e279ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 9 - loss : 0.0749 - acc: 0.9772 - val_loss : 0.1066 - val_acc: 0.9689\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093e5c3e6d0e4b52bf0d18e3603c91ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 10 - loss : 0.0711 - acc: 0.9782 - val_loss : 0.0916 - val_acc: 0.9727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for data, label in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = (output.argmax(dim=1) == label).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in valid_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
    "            epoch_val_accuracy += acc / len(valid_loader)\n",
    "            epoch_val_loss += val_loss / len(valid_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0018,  0.0594,  0.0684,  ...,  0.0808, -0.0304,  0.0774],\n",
       "        [-0.0115,  0.0919,  0.0489,  ..., -0.0375,  0.0328, -0.0561],\n",
       "        [-0.0432, -0.1457, -0.0638,  ...,  0.0164,  0.0696, -0.0432],\n",
       "        ...,\n",
       "        [-0.0201,  0.0657, -0.0618,  ...,  0.0240, -0.0236, -0.0439],\n",
       "        [-0.0355, -0.0727,  0.0708,  ..., -0.0118, -0.0200,  0.0528],\n",
       "        [-0.0696, -0.0612,  0.0940,  ...,  0.0682,  0.0082,  0.0381]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.layers[0][0].fn.fn.to_qkv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=128, out_features=10, bias=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp_head[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING AND LOADING NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./checkpoints/vision_transformer_pytorch/vit_torch\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(\n",
    "            image_size=28,\n",
    "            patch_size=4,\n",
    "            num_classes=10,\n",
    "            dim=128,\n",
    "            depth=64,\n",
    "            heads=4,\n",
    "            mlp_dim=128,\n",
    "            channels=1,\n",
    ").to(\"cuda\")\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
