{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = Dense(embed_dim)\n",
    "        self.key_dense = Dense(embed_dim)\n",
    "        self.value_dense = Dense(embed_dim)\n",
    "        self.combine_heads = Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_dim):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.mlp = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tf.nn.relu),\n",
    "                Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        out1 = attn_output + inputs\n",
    "\n",
    "        mlp_output = self.mlp(out1)\n",
    "        return mlp_output + out1\n",
    "\n",
    "\n",
    "class VisionTransformer(tf.keras.Model):\n",
    "    def __init__(self, image_size, patch_size, num_layers, num_classes, d_model, num_heads, mlp_dim, channels=1):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        self.patch_dim = channels * patch_size ** 2\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rescale = Rescaling(1.0 / 255)\n",
    "        self.pos_emb = self.add_weight(\n",
    "            \"pos_emb\", shape=(1, num_patches + 1, d_model)\n",
    "        )\n",
    "        self.class_emb = self.add_weight(\"class_emb\", shape=(1, 1, d_model))\n",
    "        self.patch_proj = Dense(d_model)\n",
    "        self.enc_layers = [\n",
    "            TransformerBlock(d_model, num_heads, mlp_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        self.mlp_head = tf.keras.Sequential(\n",
    "            [\n",
    "                Dense(mlp_dim, activation=tfa.activations.gelu),\n",
    "                Dense(num_classes),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def extract_patches(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patches = tf.reshape(patches, [batch_size, -1, self.patch_dim])\n",
    "        return patches\n",
    "\n",
    "    def call(self, x, training):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = self.rescale(x)\n",
    "        patches = self.extract_patches(x)\n",
    "        x = self.patch_proj(patches)\n",
    "\n",
    "        class_emb = tf.broadcast_to(self.class_emb, [batch_size, 1, self.d_model])\n",
    "        x = tf.concat([class_emb, x], axis=1)\n",
    "        x = x + self.pos_emb\n",
    "\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, training)\n",
    "\n",
    "        # First (class token) is used for classification\n",
    "        x = self.mlp_head(x[:, 0])\n",
    "        return x\n",
    "    \n",
    "    def load_weight(self, filepath):\n",
    "        \"\"\"Loads all layer weights, either from a TensorFlow or an HDF5 weight file.\n",
    "        Arguments:\n",
    "            filepath: String, path to the weights file to load. For weight files in\n",
    "                TensorFlow format, this is the file prefix (the same as was passed\n",
    "                to `save_weights`).\n",
    "        Returns:\n",
    "            When loading a weight file in TensorFlow format, returns the same status\n",
    "            object as `tf.train.Checkpoint.restore`. When graph building, restore\n",
    "            ops are run automatically as soon as the network is built (on first call\n",
    "            for user-defined classes inheriting from `Model`, immediately if it is\n",
    "            already built).\n",
    "            When loading weights in HDF5 format, returns `None`.\n",
    "        Raises:\n",
    "            ImportError: If h5py is not available and the weight file is in HDF5\n",
    "                format.\n",
    "            ValueError: If `skip_mismatch` is set to `True` when `by_name` is\n",
    "              `False`.\n",
    "        \"\"\"\n",
    "\n",
    "        filepath = path_to_string(filepath)\n",
    "        if h5py is None:\n",
    "            raise ImportError(\n",
    "                '`load_weights` requires h5py when loading weights from HDF5.')\n",
    "        if not self._is_graph_network and not self.built:\n",
    "            raise ValueError(\n",
    "                'Unable to load weights saved in HDF5 format into a subclassed '\n",
    "                'Model which has not created its variables yet. Call the Model '\n",
    "                'first, then load the weights.')\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            if 'layer_names' not in f.attrs and 'model_weights' in f:\n",
    "                f = f['model_weights']\n",
    "            else:\n",
    "                hdf5_format.load_weights_from_hdf5_group(f, self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 63s 4s/step - loss: 2.2481 - accuracy: 0.1662 - val_loss: 2.1216 - val_accuracy: 0.2338\n",
      "3/3 [==============================] - 3s 982ms/step - loss: 3.9850 - accuracy: 0.1661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.9850449562072754, 0.16609999537467957]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "logdir = \"logs\"\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_layers = 4\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 4096\n",
    "epochs = 1\n",
    "\n",
    "ds = tfds.load(\"mnist\", as_supervised=True)\n",
    "\n",
    "ds_train = (ds[\"train\"].shuffle(5 * batch_size).batch(batch_size))\n",
    "\n",
    "ds_test = (\n",
    "    ds[\"test\"]\n",
    "    .cache()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "\n",
    "model = VisionTransformer(\n",
    "    image_size=image_size,\n",
    "    patch_size=patch_size,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=10,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    mlp_dim=mlp_dim,\n",
    "    channels=1,\n",
    ")\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=weight_decay),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_test,\n",
    "    epochs=epochs,\n",
    "    callbacks=[TensorBoard(log_dir=logdir, profile_batch=0),],\n",
    ")\n",
    "model.load_weights(\"../saved_weights/vit.hdf5\")\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vision_transformer_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_11 (Rescaling)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            multiple                  1088      \n",
      "_________________________________________________________________\n",
      "transformer_block_44 (Transf multiple                  33216     \n",
      "_________________________________________________________________\n",
      "transformer_block_45 (Transf multiple                  33216     \n",
      "_________________________________________________________________\n",
      "transformer_block_46 (Transf multiple                  33216     \n",
      "_________________________________________________________________\n",
      "transformer_block_47 (Transf multiple                  33216     \n",
      "_________________________________________________________________\n",
      "sequential_59 (Sequential)   (None, 10)                9610      \n",
      "=================================================================\n",
      "Total params: 146,826\n",
      "Trainable params: 146,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      " 2/15 [===>..........................] - ETA: 2s - loss: 2.3370 - accuracy: 0.1193WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1050s vs `on_train_batch_end` time: 0.1593s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1050s vs `on_train_batch_end` time: 0.1593s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 2.1984 - accuracy: 0.1835WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa7a8620430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fa7a8620430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 6s 382ms/step - loss: 2.1984 - accuracy: 0.1835 - val_loss: 2.0695 - val_accuracy: 0.2563\n",
      "Epoch 2/300\n",
      "15/15 [==============================] - 4s 275ms/step - loss: 1.9991 - accuracy: 0.2813 - val_loss: 1.9038 - val_accuracy: 0.3208\n",
      "Epoch 3/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 1.7814 - accuracy: 0.3652 - val_loss: 1.5808 - val_accuracy: 0.4382\n",
      "Epoch 4/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 1.4334 - accuracy: 0.4929 - val_loss: 1.2357 - val_accuracy: 0.5564\n",
      "Epoch 5/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 1.1345 - accuracy: 0.6058 - val_loss: 0.9781 - val_accuracy: 0.6675\n",
      "Epoch 6/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.8986 - accuracy: 0.6990 - val_loss: 0.7989 - val_accuracy: 0.7384\n",
      "Epoch 7/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.7386 - accuracy: 0.7558 - val_loss: 0.6419 - val_accuracy: 0.7886\n",
      "Epoch 8/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.6220 - accuracy: 0.7967 - val_loss: 0.5685 - val_accuracy: 0.8178\n",
      "Epoch 9/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.5501 - accuracy: 0.8231 - val_loss: 0.4937 - val_accuracy: 0.8407\n",
      "Epoch 10/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.4931 - accuracy: 0.8432 - val_loss: 0.4581 - val_accuracy: 0.8521\n",
      "Epoch 11/300\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.4486 - accuracy: 0.8589 - val_loss: 0.4115 - val_accuracy: 0.8688\n",
      "Epoch 12/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.4131 - accuracy: 0.8699 - val_loss: 0.3781 - val_accuracy: 0.8808\n",
      "Epoch 13/300\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.3826 - accuracy: 0.8808 - val_loss: 0.3545 - val_accuracy: 0.8846\n",
      "Epoch 14/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.3582 - accuracy: 0.8882 - val_loss: 0.3349 - val_accuracy: 0.8929\n",
      "Epoch 15/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.3418 - accuracy: 0.8932 - val_loss: 0.3221 - val_accuracy: 0.8975\n",
      "Epoch 16/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.3277 - accuracy: 0.8965 - val_loss: 0.3109 - val_accuracy: 0.8995\n",
      "Epoch 17/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.3098 - accuracy: 0.9029 - val_loss: 0.2949 - val_accuracy: 0.9056\n",
      "Epoch 18/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2954 - accuracy: 0.9078 - val_loss: 0.2795 - val_accuracy: 0.9118\n",
      "Epoch 19/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2836 - accuracy: 0.9117 - val_loss: 0.2759 - val_accuracy: 0.9126\n",
      "Epoch 20/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2774 - accuracy: 0.9129 - val_loss: 0.2715 - val_accuracy: 0.9150\n",
      "Epoch 21/300\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.2686 - accuracy: 0.9161 - val_loss: 0.2661 - val_accuracy: 0.9137\n",
      "Epoch 22/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2608 - accuracy: 0.9187 - val_loss: 0.2502 - val_accuracy: 0.9194\n",
      "Epoch 23/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2487 - accuracy: 0.9230 - val_loss: 0.2476 - val_accuracy: 0.9202\n",
      "Epoch 24/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2412 - accuracy: 0.9252 - val_loss: 0.2398 - val_accuracy: 0.9232\n",
      "Epoch 25/300\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.2375 - accuracy: 0.9258 - val_loss: 0.2370 - val_accuracy: 0.9239\n",
      "Epoch 26/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2325 - accuracy: 0.9286 - val_loss: 0.2237 - val_accuracy: 0.9283\n",
      "Epoch 27/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2254 - accuracy: 0.9298 - val_loss: 0.2237 - val_accuracy: 0.9287\n",
      "Epoch 28/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2270 - accuracy: 0.9294 - val_loss: 0.2154 - val_accuracy: 0.9310\n",
      "Epoch 29/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.2182 - accuracy: 0.9326 - val_loss: 0.2144 - val_accuracy: 0.9309\n",
      "Epoch 30/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.2070 - accuracy: 0.9363 - val_loss: 0.2041 - val_accuracy: 0.9350\n",
      "Epoch 31/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.2024 - accuracy: 0.9379 - val_loss: 0.2187 - val_accuracy: 0.9289\n",
      "Epoch 32/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1996 - accuracy: 0.9385 - val_loss: 0.2023 - val_accuracy: 0.9334\n",
      "Epoch 33/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1962 - accuracy: 0.9392 - val_loss: 0.2017 - val_accuracy: 0.9340\n",
      "Epoch 34/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1909 - accuracy: 0.9409 - val_loss: 0.1991 - val_accuracy: 0.9372\n",
      "Epoch 35/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1876 - accuracy: 0.9417 - val_loss: 0.1904 - val_accuracy: 0.9387\n",
      "Epoch 36/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1836 - accuracy: 0.9431 - val_loss: 0.1960 - val_accuracy: 0.9368\n",
      "Epoch 37/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1810 - accuracy: 0.9433 - val_loss: 0.1845 - val_accuracy: 0.9422\n",
      "Epoch 38/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1768 - accuracy: 0.9454 - val_loss: 0.1812 - val_accuracy: 0.9423\n",
      "Epoch 39/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1746 - accuracy: 0.9467 - val_loss: 0.1926 - val_accuracy: 0.9376\n",
      "Epoch 40/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1721 - accuracy: 0.9458 - val_loss: 0.1779 - val_accuracy: 0.9428\n",
      "Epoch 41/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1714 - accuracy: 0.9463 - val_loss: 0.1737 - val_accuracy: 0.9465\n",
      "Epoch 42/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1649 - accuracy: 0.9495 - val_loss: 0.1751 - val_accuracy: 0.9456\n",
      "Epoch 43/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1615 - accuracy: 0.9502 - val_loss: 0.1686 - val_accuracy: 0.9460\n",
      "Epoch 44/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1579 - accuracy: 0.9510 - val_loss: 0.1688 - val_accuracy: 0.9457\n",
      "Epoch 45/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1555 - accuracy: 0.9520 - val_loss: 0.1760 - val_accuracy: 0.9447\n",
      "Epoch 46/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1549 - accuracy: 0.9521 - val_loss: 0.1725 - val_accuracy: 0.9441\n",
      "Epoch 47/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1526 - accuracy: 0.9528 - val_loss: 0.1641 - val_accuracy: 0.9491\n",
      "Epoch 48/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1486 - accuracy: 0.9543 - val_loss: 0.1679 - val_accuracy: 0.9469\n",
      "Epoch 49/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1488 - accuracy: 0.9536 - val_loss: 0.1675 - val_accuracy: 0.9472\n",
      "Epoch 50/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1472 - accuracy: 0.9543 - val_loss: 0.1556 - val_accuracy: 0.9496\n",
      "Epoch 51/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1405 - accuracy: 0.9564 - val_loss: 0.1531 - val_accuracy: 0.9523\n",
      "Epoch 52/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1397 - accuracy: 0.9567 - val_loss: 0.1613 - val_accuracy: 0.9474\n",
      "Epoch 53/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1391 - accuracy: 0.9570 - val_loss: 0.1508 - val_accuracy: 0.9521\n",
      "Epoch 54/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1360 - accuracy: 0.9578 - val_loss: 0.1490 - val_accuracy: 0.9536\n",
      "Epoch 55/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1324 - accuracy: 0.9584 - val_loss: 0.1495 - val_accuracy: 0.9520\n",
      "Epoch 56/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1312 - accuracy: 0.9598 - val_loss: 0.1497 - val_accuracy: 0.9522\n",
      "Epoch 57/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.1276 - accuracy: 0.9607 - val_loss: 0.1429 - val_accuracy: 0.9540\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1289 - accuracy: 0.9605 - val_loss: 0.1512 - val_accuracy: 0.9530\n",
      "Epoch 59/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1312 - accuracy: 0.9587 - val_loss: 0.1491 - val_accuracy: 0.9526\n",
      "Epoch 60/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1278 - accuracy: 0.9604 - val_loss: 0.1417 - val_accuracy: 0.9542\n",
      "Epoch 61/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1246 - accuracy: 0.9613 - val_loss: 0.1426 - val_accuracy: 0.9537\n",
      "Epoch 62/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1226 - accuracy: 0.9621 - val_loss: 0.1369 - val_accuracy: 0.9553\n",
      "Epoch 63/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1194 - accuracy: 0.9631 - val_loss: 0.1407 - val_accuracy: 0.9542\n",
      "Epoch 64/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1257 - accuracy: 0.9604 - val_loss: 0.1390 - val_accuracy: 0.9558\n",
      "Epoch 65/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1236 - accuracy: 0.9616 - val_loss: 0.1439 - val_accuracy: 0.9530\n",
      "Epoch 66/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1207 - accuracy: 0.9623 - val_loss: 0.1339 - val_accuracy: 0.9579\n",
      "Epoch 67/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1175 - accuracy: 0.9627 - val_loss: 0.1351 - val_accuracy: 0.9558\n",
      "Epoch 68/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1152 - accuracy: 0.9639 - val_loss: 0.1311 - val_accuracy: 0.9588\n",
      "Epoch 69/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1117 - accuracy: 0.9649 - val_loss: 0.1299 - val_accuracy: 0.9586\n",
      "Epoch 70/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1091 - accuracy: 0.9668 - val_loss: 0.1266 - val_accuracy: 0.9591\n",
      "Epoch 71/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1089 - accuracy: 0.9668 - val_loss: 0.1283 - val_accuracy: 0.9593\n",
      "Epoch 72/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1087 - accuracy: 0.9664 - val_loss: 0.1378 - val_accuracy: 0.9574\n",
      "Epoch 73/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1073 - accuracy: 0.9664 - val_loss: 0.1262 - val_accuracy: 0.9588\n",
      "Epoch 74/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1063 - accuracy: 0.9671 - val_loss: 0.1270 - val_accuracy: 0.9590\n",
      "Epoch 75/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1055 - accuracy: 0.9683 - val_loss: 0.1317 - val_accuracy: 0.9580\n",
      "Epoch 76/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1092 - accuracy: 0.9660 - val_loss: 0.1330 - val_accuracy: 0.9594\n",
      "Epoch 77/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1052 - accuracy: 0.9674 - val_loss: 0.1276 - val_accuracy: 0.9602\n",
      "Epoch 78/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.1108 - accuracy: 0.9654 - val_loss: 0.1317 - val_accuracy: 0.9583\n",
      "Epoch 79/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.1040 - accuracy: 0.9675 - val_loss: 0.1249 - val_accuracy: 0.9610\n",
      "Epoch 80/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.1010 - accuracy: 0.9693 - val_loss: 0.1255 - val_accuracy: 0.9618\n",
      "Epoch 81/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0985 - accuracy: 0.9698 - val_loss: 0.1275 - val_accuracy: 0.9609\n",
      "Epoch 82/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0976 - accuracy: 0.9702 - val_loss: 0.1231 - val_accuracy: 0.9613\n",
      "Epoch 83/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0992 - accuracy: 0.9690 - val_loss: 0.1285 - val_accuracy: 0.9585\n",
      "Epoch 84/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0959 - accuracy: 0.9705 - val_loss: 0.1297 - val_accuracy: 0.9609\n",
      "Epoch 85/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0971 - accuracy: 0.9697 - val_loss: 0.1367 - val_accuracy: 0.9570\n",
      "Epoch 86/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0987 - accuracy: 0.9688 - val_loss: 0.1267 - val_accuracy: 0.9615\n",
      "Epoch 87/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0965 - accuracy: 0.9697 - val_loss: 0.1204 - val_accuracy: 0.9630\n",
      "Epoch 88/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0929 - accuracy: 0.9713 - val_loss: 0.1223 - val_accuracy: 0.9630\n",
      "Epoch 89/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0912 - accuracy: 0.9716 - val_loss: 0.1233 - val_accuracy: 0.9616\n",
      "Epoch 90/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0909 - accuracy: 0.9725 - val_loss: 0.1175 - val_accuracy: 0.9639\n",
      "Epoch 91/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0900 - accuracy: 0.9717 - val_loss: 0.1165 - val_accuracy: 0.9634\n",
      "Epoch 92/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0896 - accuracy: 0.9725 - val_loss: 0.1137 - val_accuracy: 0.9641\n",
      "Epoch 93/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0903 - accuracy: 0.9720 - val_loss: 0.1204 - val_accuracy: 0.9628\n",
      "Epoch 94/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0893 - accuracy: 0.9725 - val_loss: 0.1128 - val_accuracy: 0.9645\n",
      "Epoch 95/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0849 - accuracy: 0.9736 - val_loss: 0.1205 - val_accuracy: 0.9627\n",
      "Epoch 96/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0837 - accuracy: 0.9743 - val_loss: 0.1131 - val_accuracy: 0.9648\n",
      "Epoch 97/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0823 - accuracy: 0.9748 - val_loss: 0.1234 - val_accuracy: 0.9620\n",
      "Epoch 98/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0877 - accuracy: 0.9721 - val_loss: 0.1122 - val_accuracy: 0.9650\n",
      "Epoch 99/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0828 - accuracy: 0.9741 - val_loss: 0.1122 - val_accuracy: 0.9658\n",
      "Epoch 100/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0817 - accuracy: 0.9752 - val_loss: 0.1140 - val_accuracy: 0.9652\n",
      "Epoch 101/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0829 - accuracy: 0.9742 - val_loss: 0.1192 - val_accuracy: 0.9646\n",
      "Epoch 102/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0818 - accuracy: 0.9747 - val_loss: 0.1115 - val_accuracy: 0.9654\n",
      "Epoch 103/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0815 - accuracy: 0.9750 - val_loss: 0.1169 - val_accuracy: 0.9637\n",
      "Epoch 104/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0805 - accuracy: 0.9751 - val_loss: 0.1104 - val_accuracy: 0.9661\n",
      "Epoch 105/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0775 - accuracy: 0.9764 - val_loss: 0.1101 - val_accuracy: 0.9662\n",
      "Epoch 106/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0796 - accuracy: 0.9751 - val_loss: 0.1155 - val_accuracy: 0.9645\n",
      "Epoch 107/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0863 - accuracy: 0.9726 - val_loss: 0.1159 - val_accuracy: 0.9643\n",
      "Epoch 108/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0845 - accuracy: 0.9732 - val_loss: 0.1107 - val_accuracy: 0.9650\n",
      "Epoch 109/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0814 - accuracy: 0.9746 - val_loss: 0.1079 - val_accuracy: 0.9678\n",
      "Epoch 110/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0782 - accuracy: 0.9755 - val_loss: 0.1200 - val_accuracy: 0.9653\n",
      "Epoch 111/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0772 - accuracy: 0.9762 - val_loss: 0.1166 - val_accuracy: 0.9657\n",
      "Epoch 112/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.1096 - val_accuracy: 0.9677\n",
      "Epoch 113/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0791 - accuracy: 0.9757 - val_loss: 0.1116 - val_accuracy: 0.9656\n",
      "Epoch 114/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0772 - accuracy: 0.9759 - val_loss: 0.1047 - val_accuracy: 0.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0732 - accuracy: 0.9778 - val_loss: 0.1099 - val_accuracy: 0.9671\n",
      "Epoch 116/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0721 - accuracy: 0.9780 - val_loss: 0.1074 - val_accuracy: 0.9668\n",
      "Epoch 117/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0715 - accuracy: 0.9781 - val_loss: 0.1074 - val_accuracy: 0.9667\n",
      "Epoch 118/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0745 - accuracy: 0.9769 - val_loss: 0.1067 - val_accuracy: 0.9669\n",
      "Epoch 119/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0733 - accuracy: 0.9766 - val_loss: 0.1047 - val_accuracy: 0.9674\n",
      "Epoch 120/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0703 - accuracy: 0.9785 - val_loss: 0.1046 - val_accuracy: 0.9680\n",
      "Epoch 121/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0696 - accuracy: 0.9789 - val_loss: 0.1136 - val_accuracy: 0.9656\n",
      "Epoch 122/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 0.1152 - val_accuracy: 0.9652\n",
      "Epoch 123/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0718 - accuracy: 0.9777 - val_loss: 0.1107 - val_accuracy: 0.9663\n",
      "Epoch 124/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0691 - accuracy: 0.9790 - val_loss: 0.1083 - val_accuracy: 0.9684\n",
      "Epoch 125/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.0691 - accuracy: 0.9789 - val_loss: 0.1080 - val_accuracy: 0.9679\n",
      "Epoch 126/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.1025 - val_accuracy: 0.9682\n",
      "Epoch 127/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.1040 - val_accuracy: 0.9683\n",
      "Epoch 128/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 0.1049 - val_accuracy: 0.9687\n",
      "Epoch 129/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0690 - accuracy: 0.9787 - val_loss: 0.1050 - val_accuracy: 0.9685\n",
      "Epoch 130/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.1090 - val_accuracy: 0.9663\n",
      "Epoch 131/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0656 - accuracy: 0.9793 - val_loss: 0.1159 - val_accuracy: 0.9670\n",
      "Epoch 132/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0647 - accuracy: 0.9797 - val_loss: 0.1036 - val_accuracy: 0.9678\n",
      "Epoch 133/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0704 - accuracy: 0.9779 - val_loss: 0.1199 - val_accuracy: 0.9636\n",
      "Epoch 134/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0709 - accuracy: 0.9779 - val_loss: 0.1058 - val_accuracy: 0.9671\n",
      "Epoch 135/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.1027 - val_accuracy: 0.9697\n",
      "Epoch 136/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0643 - accuracy: 0.9800 - val_loss: 0.1033 - val_accuracy: 0.9687\n",
      "Epoch 137/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0622 - accuracy: 0.9808 - val_loss: 0.1000 - val_accuracy: 0.9695\n",
      "Epoch 138/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0603 - accuracy: 0.9818 - val_loss: 0.1027 - val_accuracy: 0.9692\n",
      "Epoch 139/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0989 - val_accuracy: 0.9695\n",
      "Epoch 140/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0631 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9672\n",
      "Epoch 141/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.1039 - val_accuracy: 0.9690\n",
      "Epoch 142/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.1042 - val_accuracy: 0.9695\n",
      "Epoch 143/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0617 - accuracy: 0.9807 - val_loss: 0.0983 - val_accuracy: 0.9699\n",
      "Epoch 144/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0608 - accuracy: 0.9808 - val_loss: 0.1067 - val_accuracy: 0.9666\n",
      "Epoch 145/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0590 - accuracy: 0.9820 - val_loss: 0.0987 - val_accuracy: 0.9712\n",
      "Epoch 146/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0574 - accuracy: 0.9826 - val_loss: 0.1011 - val_accuracy: 0.9693\n",
      "Epoch 147/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0606 - accuracy: 0.9812 - val_loss: 0.0963 - val_accuracy: 0.9710\n",
      "Epoch 148/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.0973 - val_accuracy: 0.9701\n",
      "Epoch 149/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0557 - accuracy: 0.9826 - val_loss: 0.1019 - val_accuracy: 0.9701\n",
      "Epoch 150/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0554 - accuracy: 0.9831 - val_loss: 0.1012 - val_accuracy: 0.9696\n",
      "Epoch 151/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0543 - accuracy: 0.9835 - val_loss: 0.1020 - val_accuracy: 0.9692\n",
      "Epoch 152/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.0974 - val_accuracy: 0.9703\n",
      "Epoch 153/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0564 - accuracy: 0.9823 - val_loss: 0.1007 - val_accuracy: 0.9703\n",
      "Epoch 154/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0558 - accuracy: 0.9830 - val_loss: 0.1101 - val_accuracy: 0.9660\n",
      "Epoch 155/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0744 - accuracy: 0.9750 - val_loss: 0.1250 - val_accuracy: 0.9622\n",
      "Epoch 156/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0664 - accuracy: 0.9781 - val_loss: 0.1069 - val_accuracy: 0.9685\n",
      "Epoch 157/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0575 - accuracy: 0.9818 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
      "Epoch 158/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0538 - accuracy: 0.9837 - val_loss: 0.0959 - val_accuracy: 0.9712\n",
      "Epoch 159/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0527 - accuracy: 0.9840 - val_loss: 0.0956 - val_accuracy: 0.9715\n",
      "Epoch 160/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.0969 - val_accuracy: 0.9708\n",
      "Epoch 161/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0563 - accuracy: 0.9819 - val_loss: 0.1099 - val_accuracy: 0.9669\n",
      "Epoch 162/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0979 - val_accuracy: 0.9713\n",
      "Epoch 163/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0527 - accuracy: 0.9839 - val_loss: 0.0997 - val_accuracy: 0.9714\n",
      "Epoch 164/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.0935 - val_accuracy: 0.9733\n",
      "Epoch 165/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0552 - accuracy: 0.9822 - val_loss: 0.0961 - val_accuracy: 0.9700\n",
      "Epoch 166/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0541 - accuracy: 0.9829 - val_loss: 0.0960 - val_accuracy: 0.9723\n",
      "Epoch 167/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0519 - accuracy: 0.9833 - val_loss: 0.0926 - val_accuracy: 0.9718\n",
      "Epoch 168/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0500 - accuracy: 0.9850 - val_loss: 0.0968 - val_accuracy: 0.9711\n",
      "Epoch 169/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.0941 - val_accuracy: 0.9713\n",
      "Epoch 170/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0512 - accuracy: 0.9842 - val_loss: 0.1026 - val_accuracy: 0.9687\n",
      "Epoch 171/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.0928 - val_accuracy: 0.9736\n",
      "Epoch 172/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0553 - accuracy: 0.9821 - val_loss: 0.1013 - val_accuracy: 0.9707\n",
      "Epoch 173/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
      "Epoch 174/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.0936 - val_accuracy: 0.9729\n",
      "Epoch 175/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0493 - accuracy: 0.9847 - val_loss: 0.0965 - val_accuracy: 0.9723\n",
      "Epoch 176/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0985 - val_accuracy: 0.9720\n",
      "Epoch 177/300\n",
      "15/15 [==============================] - 4s 263ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0955 - val_accuracy: 0.9714\n",
      "Epoch 178/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 0.0942 - val_accuracy: 0.9718\n",
      "Epoch 179/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.0921 - val_accuracy: 0.9728\n",
      "Epoch 180/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0952 - val_accuracy: 0.9713\n",
      "Epoch 181/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0514 - accuracy: 0.9839 - val_loss: 0.0940 - val_accuracy: 0.9727\n",
      "Epoch 182/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0945 - val_accuracy: 0.9719\n",
      "Epoch 183/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0511 - accuracy: 0.9837 - val_loss: 0.0957 - val_accuracy: 0.9705\n",
      "Epoch 184/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0483 - accuracy: 0.9849 - val_loss: 0.0908 - val_accuracy: 0.9736\n",
      "Epoch 185/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0463 - accuracy: 0.9860 - val_loss: 0.1003 - val_accuracy: 0.9699\n",
      "Epoch 186/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0537 - accuracy: 0.9825 - val_loss: 0.0950 - val_accuracy: 0.9728\n",
      "Epoch 187/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0481 - accuracy: 0.9849 - val_loss: 0.0966 - val_accuracy: 0.9714\n",
      "Epoch 188/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0933 - val_accuracy: 0.9725\n",
      "Epoch 189/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.0901 - val_accuracy: 0.9736\n",
      "Epoch 190/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0418 - accuracy: 0.9881 - val_loss: 0.0927 - val_accuracy: 0.9723\n",
      "Epoch 191/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0423 - accuracy: 0.9870 - val_loss: 0.0928 - val_accuracy: 0.9730\n",
      "Epoch 192/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0443 - accuracy: 0.9859 - val_loss: 0.0951 - val_accuracy: 0.9723\n",
      "Epoch 193/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0450 - accuracy: 0.9859 - val_loss: 0.0913 - val_accuracy: 0.9736\n",
      "Epoch 194/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0434 - accuracy: 0.9865 - val_loss: 0.0977 - val_accuracy: 0.9724\n",
      "Epoch 195/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.0927 - val_accuracy: 0.9738\n",
      "Epoch 196/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.0955 - val_accuracy: 0.9732\n",
      "Epoch 197/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0946 - val_accuracy: 0.9729\n",
      "Epoch 198/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.0944 - val_accuracy: 0.9735\n",
      "Epoch 199/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0432 - accuracy: 0.9866 - val_loss: 0.0953 - val_accuracy: 0.9727\n",
      "Epoch 200/300\n",
      "15/15 [==============================] - 4s 271ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0919 - val_accuracy: 0.9741\n",
      "Epoch 201/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.0482 - accuracy: 0.9845 - val_loss: 0.0968 - val_accuracy: 0.9720\n",
      "Epoch 202/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0450 - accuracy: 0.9857 - val_loss: 0.0949 - val_accuracy: 0.9731\n",
      "Epoch 203/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0406 - accuracy: 0.9876 - val_loss: 0.0940 - val_accuracy: 0.9721\n",
      "Epoch 204/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0423 - accuracy: 0.9869 - val_loss: 0.0978 - val_accuracy: 0.9708\n",
      "Epoch 205/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0472 - accuracy: 0.9848 - val_loss: 0.0966 - val_accuracy: 0.9721\n",
      "Epoch 206/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.0958 - val_accuracy: 0.9721\n",
      "Epoch 207/300\n",
      "15/15 [==============================] - 4s 277ms/step - loss: 0.0436 - accuracy: 0.9862 - val_loss: 0.0935 - val_accuracy: 0.9729\n",
      "Epoch 208/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.0903 - val_accuracy: 0.9740\n",
      "Epoch 209/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0918 - val_accuracy: 0.9736\n",
      "Epoch 210/300\n",
      "15/15 [==============================] - 4s 270ms/step - loss: 0.0395 - accuracy: 0.9875 - val_loss: 0.0959 - val_accuracy: 0.9728\n",
      "Epoch 211/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 0.0942 - val_accuracy: 0.9730\n",
      "Epoch 212/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0420 - accuracy: 0.9869 - val_loss: 0.0978 - val_accuracy: 0.9723\n",
      "Epoch 213/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0410 - accuracy: 0.9869 - val_loss: 0.0925 - val_accuracy: 0.9737\n",
      "Epoch 214/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 0.0917 - val_accuracy: 0.9749\n",
      "Epoch 215/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 0.0942 - val_accuracy: 0.9735\n",
      "Epoch 216/300\n",
      "15/15 [==============================] - 4s 276ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.0915 - val_accuracy: 0.9739\n",
      "Epoch 217/300\n",
      "15/15 [==============================] - 4s 272ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.0983 - val_accuracy: 0.9715\n",
      "Epoch 218/300\n",
      "15/15 [==============================] - 4s 277ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.0939 - val_accuracy: 0.9741\n",
      "Epoch 219/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0916 - val_accuracy: 0.9754\n",
      "Epoch 220/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0411 - accuracy: 0.9872 - val_loss: 0.0907 - val_accuracy: 0.9748\n",
      "Epoch 221/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.0996 - val_accuracy: 0.9721\n",
      "Epoch 222/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0402 - accuracy: 0.9876 - val_loss: 0.0948 - val_accuracy: 0.9731\n",
      "Epoch 223/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.0976 - val_accuracy: 0.9721\n",
      "Epoch 224/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
      "Epoch 225/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.0909 - val_accuracy: 0.9751\n",
      "Epoch 226/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0370 - accuracy: 0.9890 - val_loss: 0.0930 - val_accuracy: 0.9736\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0385 - accuracy: 0.9881 - val_loss: 0.0918 - val_accuracy: 0.9735\n",
      "Epoch 228/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.0940 - val_accuracy: 0.9732\n",
      "Epoch 229/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.0889 - val_accuracy: 0.9759\n",
      "Epoch 230/300\n",
      "15/15 [==============================] - 4s 266ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0927 - val_accuracy: 0.9745\n",
      "Epoch 231/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
      "Epoch 232/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0411 - accuracy: 0.9865 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 233/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.0945 - val_accuracy: 0.9743\n",
      "Epoch 234/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.1039 - val_accuracy: 0.9700\n",
      "Epoch 235/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0973 - val_accuracy: 0.9731\n",
      "Epoch 236/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0390 - accuracy: 0.9879 - val_loss: 0.0905 - val_accuracy: 0.9743\n",
      "Epoch 237/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.0996 - val_accuracy: 0.9725\n",
      "Epoch 238/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0409 - accuracy: 0.9862 - val_loss: 0.1202 - val_accuracy: 0.9651\n",
      "Epoch 239/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0512 - accuracy: 0.9829 - val_loss: 0.1022 - val_accuracy: 0.9698\n",
      "Epoch 240/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0416 - accuracy: 0.9863 - val_loss: 0.0917 - val_accuracy: 0.9735\n",
      "Epoch 241/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0382 - accuracy: 0.9883 - val_loss: 0.0934 - val_accuracy: 0.9747\n",
      "Epoch 242/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.0891 - val_accuracy: 0.9763\n",
      "Epoch 243/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 0.0912 - val_accuracy: 0.9757\n",
      "Epoch 244/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.0889 - val_accuracy: 0.9770\n",
      "Epoch 245/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0336 - accuracy: 0.9898 - val_loss: 0.0869 - val_accuracy: 0.9764\n",
      "Epoch 246/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.0938 - val_accuracy: 0.9747\n",
      "Epoch 247/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 0.0939 - val_accuracy: 0.9753\n",
      "Epoch 248/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0941 - val_accuracy: 0.9756\n",
      "Epoch 249/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0918 - val_accuracy: 0.9749\n",
      "Epoch 250/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.1034 - val_accuracy: 0.9709\n",
      "Epoch 251/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0402 - accuracy: 0.9871 - val_loss: 0.0902 - val_accuracy: 0.9760\n",
      "Epoch 252/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0908 - val_accuracy: 0.9745\n",
      "Epoch 253/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0913 - val_accuracy: 0.9749\n",
      "Epoch 254/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0941 - val_accuracy: 0.9751\n",
      "Epoch 255/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0935 - val_accuracy: 0.9742\n",
      "Epoch 256/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.0920 - val_accuracy: 0.9756\n",
      "Epoch 257/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.0900 - val_accuracy: 0.9762\n",
      "Epoch 258/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.0924 - val_accuracy: 0.9750\n",
      "Epoch 259/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0904 - val_accuracy: 0.9753\n",
      "Epoch 260/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0916 - val_accuracy: 0.9750\n",
      "Epoch 261/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 0.0920 - val_accuracy: 0.9759\n",
      "Epoch 262/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0374 - accuracy: 0.9877 - val_loss: 0.0885 - val_accuracy: 0.9757\n",
      "Epoch 263/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 0.0863 - val_accuracy: 0.9765\n",
      "Epoch 264/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.0939 - val_accuracy: 0.9749\n",
      "Epoch 265/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0912 - val_accuracy: 0.9758\n",
      "Epoch 266/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 0.0958 - val_accuracy: 0.9752\n",
      "Epoch 267/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0900 - val_accuracy: 0.9759\n",
      "Epoch 268/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.0922 - val_accuracy: 0.9750\n",
      "Epoch 269/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0919 - val_accuracy: 0.9755\n",
      "Epoch 270/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0910 - val_accuracy: 0.9752\n",
      "Epoch 271/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 0.1030 - val_accuracy: 0.9722\n",
      "Epoch 272/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.0955 - val_accuracy: 0.9742\n",
      "Epoch 273/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.0883 - val_accuracy: 0.9761\n",
      "Epoch 274/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0925 - val_accuracy: 0.9756\n",
      "Epoch 275/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0913 - val_accuracy: 0.9761\n",
      "Epoch 276/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0947 - val_accuracy: 0.9731\n",
      "Epoch 277/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.0893 - val_accuracy: 0.9767\n",
      "Epoch 278/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.0867 - val_accuracy: 0.9771\n",
      "Epoch 279/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.0893 - val_accuracy: 0.9768\n",
      "Epoch 280/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.0920 - val_accuracy: 0.9763\n",
      "Epoch 281/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.0895 - val_accuracy: 0.9762\n",
      "Epoch 282/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0968 - val_accuracy: 0.9747\n",
      "Epoch 283/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.0905 - val_accuracy: 0.9761\n",
      "Epoch 284/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0299 - accuracy: 0.9910 - val_loss: 0.0896 - val_accuracy: 0.9772\n",
      "Epoch 285/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0910 - val_accuracy: 0.9770\n",
      "Epoch 286/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.0896 - val_accuracy: 0.9768\n",
      "Epoch 287/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0282 - accuracy: 0.9918 - val_loss: 0.0961 - val_accuracy: 0.9749\n",
      "Epoch 288/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.0963 - val_accuracy: 0.9740\n",
      "Epoch 289/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.0985 - val_accuracy: 0.9745\n",
      "Epoch 290/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.0884 - val_accuracy: 0.9779\n",
      "Epoch 291/300\n",
      "15/15 [==============================] - 4s 269ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 0.0927 - val_accuracy: 0.9758\n",
      "Epoch 292/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 0.0967 - val_accuracy: 0.9740\n",
      "Epoch 293/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0326 - accuracy: 0.9893 - val_loss: 0.0960 - val_accuracy: 0.9743\n",
      "Epoch 294/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0919 - val_accuracy: 0.9756\n",
      "Epoch 295/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0314 - accuracy: 0.9899 - val_loss: 0.0895 - val_accuracy: 0.9770\n",
      "Epoch 296/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0930 - val_accuracy: 0.9759\n",
      "Epoch 297/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0952 - val_accuracy: 0.9749\n",
      "Epoch 298/300\n",
      "15/15 [==============================] - 4s 268ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0952 - val_accuracy: 0.9745\n",
      "Epoch 299/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0986 - val_accuracy: 0.9732\n",
      "Epoch 300/300\n",
      "15/15 [==============================] - 4s 267ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0931 - val_accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "logdir = \"logs\"\n",
    "image_size = 28\n",
    "patch_size = 4\n",
    "num_layers = 4\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "mlp_dim = 128\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 4096\n",
    "epochs = 300\n",
    "\n",
    "ds = tfds.load(\"mnist\", as_supervised=True)\n",
    "\n",
    "ds_train = (\n",
    "    ds[\"train\"]\n",
    "    .cache()\n",
    "    .shuffle(5 * batch_size)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "ds_test = (\n",
    "    ds[\"test\"]\n",
    "    .cache()\n",
    "    .batch(batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=10,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        mlp_dim=mlp_dim,\n",
    "        channels=1,\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=weight_decay),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_test,\n",
    "    epochs=epochs,\n",
    "    callbacks=[TensorBoard(log_dir=logdir, profile_batch=0),],\n",
    ")\n",
    "model.save_weights(os.path.join(logdir, \"weights\", \"vit\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0931 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0930701419711113, 0.9764000177383423]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_layers=num_layers,\n",
    "        num_classes=10,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        mlp_dim=mlp_dim,\n",
    "        channels=1,\n",
    "    )\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=tfa.optimizers.AdamW(learning_rate=lr, weight_decay=weight_decay),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    model.load_weights(os.path.join(logdir, \"weights\", \"vit\"))\n",
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0931 - accuracy: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0930701419711113, 0.9764000177383423]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}